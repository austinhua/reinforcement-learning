('dKnown', 0.01, 'epsilonA', 0.001, 'epsilonB', 0.1, 'normOrder', 2, 'regularizer', array([  1.,   1.,  10.,  50.]), 'maxStepsPerEpisode:', 200, 'episodeStepsRemaining:', 200, 'maxNumberOfEpisodes:', 128)
('episode:', 1, 'number of steps:', 6, 'accumulatedReward:', 4.7679672852937269, 'accumulatedDiscountedReward:', 4.5883694884532504)
('number of approximation units:', 7, 'number of samples:', 6)
('episode:', 2, 'number of steps:', 11, 'accumulatedReward:', 9.7491884323277418, 'accumulatedDiscountedReward:', 8.9336022348641819)
('number of approximation units:', 18, 'number of samples:', 17)
('episode:', 3, 'number of steps:', 6, 'accumulatedReward:', 4.8088754852986382, 'accumulatedDiscountedReward:', 4.6259558349028502)
('number of approximation units:', 24, 'number of samples:', 23)
('episode:', 4, 'number of steps:', 8, 'accumulatedReward:', 6.630523579124465, 'accumulatedDiscountedReward:', 6.2609678011767524)
('number of approximation units:', 32, 'number of samples:', 31)
('episode:', 5, 'number of steps:', 9, 'accumulatedReward:', 7.5903756387028904, 'accumulatedDiscountedReward:', 7.0988121215620978)
('number of approximation units:', 41, 'number of samples:', 40)
('episode:', 6, 'number of steps:', 10, 'accumulatedReward:', 8.4376577201609777, 'accumulatedDiscountedReward:', 7.8216291881274991)
('number of approximation units:', 51, 'number of samples:', 50)
('episode:', 7, 'number of steps:', 10, 'accumulatedReward:', 8.5243080589615925, 'accumulatedDiscountedReward:', 7.8996347756416583)
('number of approximation units:', 61, 'number of samples:', 60)
('episode:', 8, 'number of steps:', 8, 'accumulatedReward:', 6.6159753803521557, 'accumulatedDiscountedReward:', 6.2470646329414663)
('number of approximation units:', 69, 'number of samples:', 68)
('episode:', 9, 'number of steps:', 7, 'accumulatedReward:', 5.6897152678308132, 'accumulatedDiscountedReward:', 5.4236267605825672)
('number of approximation units:', 76, 'number of samples:', 75)
('episode:', 10, 'number of steps:', 7, 'accumulatedReward:', 5.7412410883911393, 'accumulatedDiscountedReward:', 5.4691405316124015)
('number of approximation units:', 83, 'number of samples:', 82)
('episode:', 11, 'number of steps:', 8, 'accumulatedReward:', 6.6289730329601477, 'accumulatedDiscountedReward:', 6.2565384609017345)
('number of approximation units:', 91, 'number of samples:', 90)
('episode:', 12, 'number of steps:', 9, 'accumulatedReward:', 7.6884836730304009, 'accumulatedDiscountedReward:', 7.1859579177175625)
('number of approximation units:', 100, 'number of samples:', 99)
('episode:', 13, 'number of steps:', 9, 'accumulatedReward:', 7.5707336551251352, 'accumulatedDiscountedReward:', 7.082388487913537)
('number of approximation units:', 109, 'number of samples:', 108)
('episode:', 14, 'number of steps:', 10, 'accumulatedReward:', 8.6962535078107219, 'accumulatedDiscountedReward:', 8.048818243631386)
('number of approximation units:', 119, 'number of samples:', 118)
('episode:', 15, 'number of steps:', 15, 'accumulatedReward:', 13.490016336286896, 'accumulatedDiscountedReward:', 11.908370199937515)
('number of approximation units:', 134, 'number of samples:', 133)
('episode:', 16, 'number of steps:', 11, 'accumulatedReward:', 9.7208163483448651, 'accumulatedDiscountedReward:', 8.909548655186363)
('number of approximation units:', 145, 'number of samples:', 144)
('episode:', 17, 'number of steps:', 9, 'accumulatedReward:', 7.6490812175515028, 'accumulatedDiscountedReward:', 7.1520290916453995)
('number of approximation units:', 153, 'number of samples:', 153)
('episode:', 18, 'number of steps:', 16, 'accumulatedReward:', 14.482491285885388, 'accumulatedDiscountedReward:', 12.659096468846798)
('number of approximation units:', 169, 'number of samples:', 169)
('episode:', 19, 'number of steps:', 10, 'accumulatedReward:', 8.5880859925709938, 'accumulatedDiscountedReward:', 7.9525372787512527)
('number of approximation units:', 178, 'number of samples:', 179)
('episode:', 20, 'number of steps:', 13, 'accumulatedReward:', 11.723257460825787, 'accumulatedDiscountedReward:', 10.538232804962689)
('number of approximation units:', 190, 'number of samples:', 192)
('episode:', 21, 'number of steps:', 11, 'accumulatedReward:', 9.6313806123233938, 'accumulatedDiscountedReward:', 8.832878184847166)
('number of approximation units:', 201, 'number of samples:', 203)
('episode:', 22, 'number of steps:', 8, 'accumulatedReward:', 6.5636354233158514, 'accumulatedDiscountedReward:', 6.1975382071072236)
('number of approximation units:', 209, 'number of samples:', 211)
('episode:', 23, 'number of steps:', 7, 'accumulatedReward:', 5.7058108941988053, 'accumulatedDiscountedReward:', 5.4366212182209113)
('number of approximation units:', 216, 'number of samples:', 218)
('episode:', 24, 'number of steps:', 12, 'accumulatedReward:', 10.460640318134143, 'accumulatedDiscountedReward:', 9.510566488761441)
('number of approximation units:', 227, 'number of samples:', 230)
('episode:', 25, 'number of steps:', 14, 'accumulatedReward:', 12.5830750363299, 'accumulatedDiscountedReward:', 11.212236416110331)
('number of approximation units:', 241, 'number of samples:', 244)
('episode:', 26, 'number of steps:', 8, 'accumulatedReward:', 6.6340011110977271, 'accumulatedDiscountedReward:', 6.2634819374501269)
('number of approximation units:', 249, 'number of samples:', 252)
('episode:', 27, 'number of steps:', 12, 'accumulatedReward:', 10.600250838134796, 'accumulatedDiscountedReward:', 9.6187365720426143)
('number of approximation units:', 261, 'number of samples:', 264)
('episode:', 28, 'number of steps:', 10, 'accumulatedReward:', 8.7040983327102062, 'accumulatedDiscountedReward:', 8.0540903071952492)
('number of approximation units:', 271, 'number of samples:', 274)
('episode:', 29, 'number of steps:', 10, 'accumulatedReward:', 8.7078156149113113, 'accumulatedDiscountedReward:', 8.0593808267299387)
('number of approximation units:', 281, 'number of samples:', 284)
('episode:', 30, 'number of steps:', 13, 'accumulatedReward:', 11.614993569796614, 'accumulatedDiscountedReward:', 10.443847350138112)
('number of approximation units:', 292, 'number of samples:', 297)
('episode:', 31, 'number of steps:', 9, 'accumulatedReward:', 7.5690164268638389, 'accumulatedDiscountedReward:', 7.0815683934562292)
('number of approximation units:', 301, 'number of samples:', 306)
('episode:', 32, 'number of steps:', 11, 'accumulatedReward:', 9.507035652402692, 'accumulatedDiscountedReward:', 8.722045470435706)
('number of approximation units:', 312, 'number of samples:', 317)
('episode:', 33, 'number of steps:', 12, 'accumulatedReward:', 10.678472146452092, 'accumulatedDiscountedReward:', 9.6951666038859177)
('number of approximation units:', 323, 'number of samples:', 329)
('episode:', 34, 'number of steps:', 7, 'accumulatedReward:', 5.5399408309891633, 'accumulatedDiscountedReward:', 5.284649567582318)
('number of approximation units:', 330, 'number of samples:', 336)
('episode:', 35, 'number of steps:', 8, 'accumulatedReward:', 6.7571739489208626, 'accumulatedDiscountedReward:', 6.3728576983696454)
('number of approximation units:', 338, 'number of samples:', 344)
('episode:', 36, 'number of steps:', 14, 'accumulatedReward:', 12.512884498248122, 'accumulatedDiscountedReward:', 11.155661130367593)
('number of approximation units:', 350, 'number of samples:', 358)
('episode:', 37, 'number of steps:', 17, 'accumulatedReward:', 15.299191319253394, 'accumulatedDiscountedReward:', 13.249493842233614)
('number of approximation units:', 367, 'number of samples:', 375)
('episode:', 38, 'number of steps:', 16, 'accumulatedReward:', 14.364560178428137, 'accumulatedDiscountedReward:', 12.567109939202648)
('number of approximation units:', 383, 'number of samples:', 391)
('episode:', 39, 'number of steps:', 12, 'accumulatedReward:', 10.617133551145448, 'accumulatedDiscountedReward:', 9.6454285095420857)
('number of approximation units:', 395, 'number of samples:', 403)
('episode:', 40, 'number of steps:', 11, 'accumulatedReward:', 9.6608798165010725, 'accumulatedDiscountedReward:', 8.8567826700050709)
('number of approximation units:', 406, 'number of samples:', 414)
('episode:', 41, 'number of steps:', 12, 'accumulatedReward:', 10.5884559295804, 'accumulatedDiscountedReward:', 9.614703487220984)
('number of approximation units:', 418, 'number of samples:', 426)
('episode:', 42, 'number of steps:', 37, 'accumulatedReward:', 35.41345043716386, 'accumulatedDiscountedReward:', 25.518835756994196)
('number of approximation units:', 454, 'number of samples:', 463)
('episode:', 43, 'number of steps:', 13, 'accumulatedReward:', 11.472995345747664, 'accumulatedDiscountedReward:', 10.323436584742998)
('number of approximation units:', 466, 'number of samples:', 476)
('episode:', 44, 'number of steps:', 18, 'accumulatedReward:', 16.545033186503893, 'accumulatedDiscountedReward:', 14.188627470360231)
('number of approximation units:', 484, 'number of samples:', 494)
('episode:', 45, 'number of steps:', 17, 'accumulatedReward:', 15.654407610277936, 'accumulatedDiscountedReward:', 13.543660907384876)
('number of approximation units:', 500, 'number of samples:', 511)
('episode:', 46, 'number of steps:', 10, 'accumulatedReward:', 8.4889584882145748, 'accumulatedDiscountedReward:', 7.864357115687068)
('number of approximation units:', 510, 'number of samples:', 521)
('episode:', 47, 'number of steps:', 15, 'accumulatedReward:', 13.414693268973714, 'accumulatedDiscountedReward:', 11.850473259737846)
('number of approximation units:', 525, 'number of samples:', 536)
('episode:', 48, 'number of steps:', 16, 'accumulatedReward:', 14.404260980164574, 'accumulatedDiscountedReward:', 12.605208511355849)
('number of approximation units:', 540, 'number of samples:', 552)
('episode:', 49, 'number of steps:', 11, 'accumulatedReward:', 9.406734678957168, 'accumulatedDiscountedReward:', 8.6358790510123473)
('number of approximation units:', 551, 'number of samples:', 563)
('episode:', 50, 'number of steps:', 23, 'accumulatedReward:', 21.504253587148494, 'accumulatedDiscountedReward:', 17.595935483452063)
('number of approximation units:', 573, 'number of samples:', 586)
('episode:', 51, 'number of steps:', 16, 'accumulatedReward:', 14.601853057197657, 'accumulatedDiscountedReward:', 12.759023842985597)
('number of approximation units:', 589, 'number of samples:', 602)
('episode:', 52, 'number of steps:', 15, 'accumulatedReward:', 13.585355785970709, 'accumulatedDiscountedReward:', 11.985121925629082)
('number of approximation units:', 603, 'number of samples:', 617)
('episode:', 53, 'number of steps:', 14, 'accumulatedReward:', 12.478086886345475, 'accumulatedDiscountedReward:', 11.122665977172167)
('number of approximation units:', 617, 'number of samples:', 631)
('episode:', 54, 'number of steps:', 8, 'accumulatedReward:', 6.5927743364643794, 'accumulatedDiscountedReward:', 6.2242607036890956)
('number of approximation units:', 625, 'number of samples:', 639)
('episode:', 55, 'number of steps:', 14, 'accumulatedReward:', 12.390856243093223, 'accumulatedDiscountedReward:', 11.050838761610384)
('number of approximation units:', 638, 'number of samples:', 653)
('episode:', 56, 'number of steps:', 17, 'accumulatedReward:', 15.437028027790555, 'accumulatedDiscountedReward:', 13.37497062928378)
('number of approximation units:', 654, 'number of samples:', 670)
('episode:', 57, 'number of steps:', 32, 'accumulatedReward:', 30.409195089210705, 'accumulatedDiscountedReward:', 22.91585577981418)
('number of approximation units:', 685, 'number of samples:', 702)
('episode:', 58, 'number of steps:', 15, 'accumulatedReward:', 13.668888188351938, 'accumulatedDiscountedReward:', 12.053463337059121)
('number of approximation units:', 700, 'number of samples:', 717)
('episode:', 59, 'number of steps:', 13, 'accumulatedReward:', 11.528174084263416, 'accumulatedDiscountedReward:', 10.377091705524506)
('number of approximation units:', 712, 'number of samples:', 730)
('episode:', 60, 'number of steps:', 20, 'accumulatedReward:', 18.41654009673486, 'accumulatedDiscountedReward:', 15.51450052915146)
('number of approximation units:', 731, 'number of samples:', 750)
('episode:', 61, 'number of steps:', 22, 'accumulatedReward:', 20.548724301046384, 'accumulatedDiscountedReward:', 16.966339300005838)
('number of approximation units:', 751, 'number of samples:', 772)
('episode:', 62, 'number of steps:', 37, 'accumulatedReward:', 35.187836799758344, 'accumulatedDiscountedReward:', 25.380902922953922)
('number of approximation units:', 786, 'number of samples:', 809)
('episode:', 63, 'number of steps:', 19, 'accumulatedReward:', 17.419517524343906, 'accumulatedDiscountedReward:', 14.811053725507406)
('number of approximation units:', 801, 'number of samples:', 828)
('episode:', 64, 'number of steps:', 14, 'accumulatedReward:', 12.489556488430205, 'accumulatedDiscountedReward:', 11.129242022061078)
('number of approximation units:', 814, 'number of samples:', 842)
('episode:', 65, 'number of steps:', 11, 'accumulatedReward:', 9.5972678509469418, 'accumulatedDiscountedReward:', 8.7999732592942745)
('number of approximation units:', 825, 'number of samples:', 853)
('episode:', 66, 'number of steps:', 16, 'accumulatedReward:', 14.345133525906446, 'accumulatedDiscountedReward:', 12.553625609643291)
('number of approximation units:', 840, 'number of samples:', 869)
('episode:', 67, 'number of steps:', 13, 'accumulatedReward:', 11.378860674428317, 'accumulatedDiscountedReward:', 10.243042290632644)
('number of approximation units:', 852, 'number of samples:', 882)
('episode:', 68, 'number of steps:', 24, 'accumulatedReward:', 22.53772580212862, 'accumulatedDiscountedReward:', 18.253200324583471)
('number of approximation units:', 876, 'number of samples:', 906)
('episode:', 69, 'number of steps:', 14, 'accumulatedReward:', 12.622719210901286, 'accumulatedDiscountedReward:', 11.242671962008428)
('number of approximation units:', 888, 'number of samples:', 920)
('episode:', 70, 'number of steps:', 10, 'accumulatedReward:', 8.6822518400872966, 'accumulatedDiscountedReward:', 8.038561692080421)
('number of approximation units:', 898, 'number of samples:', 930)
('episode:', 71, 'number of steps:', 8, 'accumulatedReward:', 6.6799638562671033, 'accumulatedDiscountedReward:', 6.3029697617116174)
('number of approximation units:', 906, 'number of samples:', 938)
('episode:', 72, 'number of steps:', 62, 'accumulatedReward:', 60.099570424517232, 'accumulatedDiscountedReward:', 35.038193818663679)
('number of approximation units:', 963, 'number of samples:', 1000)
('episode:', 73, 'number of steps:', 21, 'accumulatedReward:', 19.382346998237647, 'accumulatedDiscountedReward:', 16.152978105604859)
('number of approximation units:', 982, 'number of samples:', 1021)
('episode:', 74, 'number of steps:', 20, 'accumulatedReward:', 18.404942941014419, 'accumulatedDiscountedReward:', 15.4920701066515)
('number of approximation units:', 1001, 'number of samples:', 1041)
('episode:', 75, 'number of steps:', 8, 'accumulatedReward:', 6.5902671282683922, 'accumulatedDiscountedReward:', 6.2237214800107479)
('number of approximation units:', 1009, 'number of samples:', 1049)
('episode:', 76, 'number of steps:', 21, 'accumulatedReward:', 19.320943566859928, 'accumulatedDiscountedReward:', 16.1200208074386)
('number of approximation units:', 1026, 'number of samples:', 1070)
('episode:', 77, 'number of steps:', 8, 'accumulatedReward:', 6.6580210346601287, 'accumulatedDiscountedReward:', 6.2846589918684952)
('number of approximation units:', 1034, 'number of samples:', 1078)
('episode:', 78, 'number of steps:', 21, 'accumulatedReward:', 19.477196304355481, 'accumulatedDiscountedReward:', 16.237690020906719)
('number of approximation units:', 1052, 'number of samples:', 1099)
('episode:', 79, 'number of steps:', 12, 'accumulatedReward:', 10.609294000447047, 'accumulatedDiscountedReward:', 9.6367398675436231)
('number of approximation units:', 1063, 'number of samples:', 1111)
('episode:', 80, 'number of steps:', 25, 'accumulatedReward:', 23.505870349339059, 'accumulatedDiscountedReward:', 18.869392251811718)
('number of approximation units:', 1086, 'number of samples:', 1136)
('episode:', 81, 'number of steps:', 13, 'accumulatedReward:', 11.497823240129957, 'accumulatedDiscountedReward:', 10.35304710123401)
('number of approximation units:', 1099, 'number of samples:', 1149)
('episode:', 82, 'number of steps:', 15, 'accumulatedReward:', 13.423296369671631, 'accumulatedDiscountedReward:', 11.854108095440825)
('number of approximation units:', 1112, 'number of samples:', 1164)
('episode:', 83, 'number of steps:', 12, 'accumulatedReward:', 10.731210150447902, 'accumulatedDiscountedReward:', 9.7390301612658554)
('number of approximation units:', 1124, 'number of samples:', 1176)
('episode:', 84, 'number of steps:', 15, 'accumulatedReward:', 13.489395326994259, 'accumulatedDiscountedReward:', 11.908136571067645)
('number of approximation units:', 1138, 'number of samples:', 1191)
('episode:', 85, 'number of steps:', 13, 'accumulatedReward:', 11.493142384867873, 'accumulatedDiscountedReward:', 10.344696938805784)
('number of approximation units:', 1150, 'number of samples:', 1204)
('episode:', 86, 'number of steps:', 8, 'accumulatedReward:', 6.5847055583426801, 'accumulatedDiscountedReward:', 6.2194880730735713)
('number of approximation units:', 1157, 'number of samples:', 1212)
('episode:', 87, 'number of steps:', 11, 'accumulatedReward:', 9.6152261546720901, 'accumulatedDiscountedReward:', 8.8151062387587604)
('number of approximation units:', 1166, 'number of samples:', 1223)
('episode:', 88, 'number of steps:', 12, 'accumulatedReward:', 10.484047875725512, 'accumulatedDiscountedReward:', 9.5282390280460785)
('number of approximation units:', 1175, 'number of samples:', 1235)
('episode:', 89, 'number of steps:', 15, 'accumulatedReward:', 13.540931071901017, 'accumulatedDiscountedReward:', 11.949543086822043)
('number of approximation units:', 1188, 'number of samples:', 1250)
('episode:', 90, 'number of steps:', 14, 'accumulatedReward:', 12.705544130672859, 'accumulatedDiscountedReward:', 11.310134634097118)
('number of approximation units:', 1197, 'number of samples:', 1264)
('episode:', 91, 'number of steps:', 14, 'accumulatedReward:', 12.634962428027981, 'accumulatedDiscountedReward:', 11.253266993710538)
('number of approximation units:', 1210, 'number of samples:', 1278)
('episode:', 92, 'number of steps:', 9, 'accumulatedReward:', 7.7339080806529816, 'accumulatedDiscountedReward:', 7.2270614120102872)
('number of approximation units:', 1219, 'number of samples:', 1287)
('episode:', 93, 'number of steps:', 21, 'accumulatedReward:', 19.404965348218187, 'accumulatedDiscountedReward:', 16.185208250527026)
('number of approximation units:', 1237, 'number of samples:', 1308)
('episode:', 94, 'number of steps:', 21, 'accumulatedReward:', 19.409152128460772, 'accumulatedDiscountedReward:', 16.192875886643016)
('number of approximation units:', 1254, 'number of samples:', 1329)
('episode:', 95, 'number of steps:', 13, 'accumulatedReward:', 11.521928690872862, 'accumulatedDiscountedReward:', 10.362672677440958)
('number of approximation units:', 1265, 'number of samples:', 1342)
('episode:', 96, 'number of steps:', 20, 'accumulatedReward:', 18.421547379018005, 'accumulatedDiscountedReward:', 15.521423010820294)
('number of approximation units:', 1284, 'number of samples:', 1362)
('episode:', 97, 'number of steps:', 27, 'accumulatedReward:', 25.512619315417954, 'accumulatedDiscountedReward:', 20.104514804083152)
('number of approximation units:', 1304, 'number of samples:', 1389)
('episode:', 98, 'number of steps:', 17, 'accumulatedReward:', 15.367364987473202, 'accumulatedDiscountedReward:', 13.321317614681234)
('number of approximation units:', 1318, 'number of samples:', 1406)
('episode:', 99, 'number of steps:', 20, 'accumulatedReward:', 18.409318140967414, 'accumulatedDiscountedReward:', 15.502873838504392)
('number of approximation units:', 1335, 'number of samples:', 1426)
('episode:', 100, 'number of steps:', 13, 'accumulatedReward:', 11.461563826911192, 'accumulatedDiscountedReward:', 10.316865213434836)
('number of approximation units:', 1346, 'number of samples:', 1439)
('episode:', 101, 'number of steps:', 26, 'accumulatedReward:', 24.167806136380445, 'accumulatedDiscountedReward:', 19.246033735035716)
('number of approximation units:', 1369, 'number of samples:', 1465)
('episode:', 102, 'number of steps:', 18, 'accumulatedReward:', 16.418061331174069, 'accumulatedDiscountedReward:', 14.084200393819444)
('number of approximation units:', 1383, 'number of samples:', 1483)
('episode:', 103, 'number of steps:', 23, 'accumulatedReward:', 21.441195547671878, 'accumulatedDiscountedReward:', 17.549319323787941)
('number of approximation units:', 1401, 'number of samples:', 1506)
('episode:', 104, 'number of steps:', 38, 'accumulatedReward:', 36.074777992756822, 'accumulatedDiscountedReward:', 25.758653564188322)
('number of approximation units:', 1429, 'number of samples:', 1544)
('episode:', 105, 'number of steps:', 21, 'accumulatedReward:', 19.547559574339012, 'accumulatedDiscountedReward:', 16.297297249322355)
('number of approximation units:', 1448, 'number of samples:', 1565)
('episode:', 106, 'number of steps:', 26, 'accumulatedReward:', 24.286469233739517, 'accumulatedDiscountedReward:', 19.35005663309861)
('number of approximation units:', 1469, 'number of samples:', 1591)
('episode:', 107, 'number of steps:', 42, 'accumulatedReward:', 40.21143074915377, 'accumulatedDiscountedReward:', 27.741764109165267)
('number of approximation units:', 1500, 'number of samples:', 1633)
('episode:', 108, 'number of steps:', 38, 'accumulatedReward:', 36.473062195963585, 'accumulatedDiscountedReward:', 26.031154732890332)
('number of approximation units:', 1528, 'number of samples:', 1671)
('episode:', 109, 'number of steps:', 57, 'accumulatedReward:', 55.233285481411677, 'accumulatedDiscountedReward:', 33.51118312896665)
('number of approximation units:', 1574, 'number of samples:', 1728)
('episode:', 110, 'number of steps:', 13, 'accumulatedReward:', 11.588710977138408, 'accumulatedDiscountedReward:', 10.419642475536957)
('number of approximation units:', 1585, 'number of samples:', 1741)
('episode:', 111, 'number of steps:', 37, 'accumulatedReward:', 35.373808661468615, 'accumulatedDiscountedReward:', 25.475520298887186)
('number of approximation units:', 1612, 'number of samples:', 1778)
('episode:', 112, 'number of steps:', 44, 'accumulatedReward:', 42.27470772610635, 'accumulatedDiscountedReward:', 28.643071691848483)
('number of approximation units:', 1644, 'number of samples:', 1822)
('episode:', 113, 'number of steps:', 11, 'accumulatedReward:', 9.5503301747957998, 'accumulatedDiscountedReward:', 8.7620555699692986)
('number of approximation units:', 1654, 'number of samples:', 1833)
('episode:', 114, 'number of steps:', 16, 'accumulatedReward:', 14.479234144683032, 'accumulatedDiscountedReward:', 12.667346877705899)
('number of approximation units:', 1668, 'number of samples:', 1849)
('episode:', 115, 'number of steps:', 20, 'accumulatedReward:', 18.314119002017225, 'accumulatedDiscountedReward:', 15.434204252182665)
('number of approximation units:', 1684, 'number of samples:', 1869)
('episode:', 116, 'number of steps:', 45, 'accumulatedReward:', 43.235087519221487, 'accumulatedDiscountedReward:', 29.04642292691782)
('number of approximation units:', 1716, 'number of samples:', 1914)
('episode:', 117, 'number of steps:', 6, 'accumulatedReward:', 4.713665829043415, 'accumulatedDiscountedReward:', 4.5369604547774021)
('number of approximation units:', 1722, 'number of samples:', 1920)
('episode:', 118, 'number of steps:', 135, 'accumulatedReward:', 132.69738061894398, 'accumulatedDiscountedReward:', 46.415459944921366)
('number of approximation units:', 1810, 'number of samples:', 2055)
('episode:', 119, 'number of steps:', 45, 'accumulatedReward:', 43.306903019110884, 'accumulatedDiscountedReward:', 29.104157479717511)
('number of approximation units:', 1842, 'number of samples:', 2100)
('episode:', 120, 'number of steps:', 49, 'accumulatedReward:', 47.338262479105396, 'accumulatedDiscountedReward:', 30.704078494870579)
('number of approximation units:', 1870, 'number of samples:', 2149)
('episode:', 121, 'number of steps:', 30, 'accumulatedReward:', 28.382021251995674, 'accumulatedDiscountedReward:', 21.793345055498609)
('number of approximation units:', 1895, 'number of samples:', 2179)
('episode:', 122, 'number of steps:', 8, 'accumulatedReward:', 6.7247414451338487, 'accumulatedDiscountedReward:', 6.3444593232279889)
('number of approximation units:', 1903, 'number of samples:', 2187)
('episode:', 123, 'number of steps:', 8, 'accumulatedReward:', 6.678479558747032, 'accumulatedDiscountedReward:', 6.3035883435211542)
('number of approximation units:', 1909, 'number of samples:', 2195)
('episode:', 124, 'number of steps:', 68, 'accumulatedReward:', 66.000976725190881, 'accumulatedDiscountedReward:', 36.65488622169552)
('number of approximation units:', 1954, 'number of samples:', 2263)
('episode:', 125, 'number of steps:', 19, 'accumulatedReward:', 17.338279932518724, 'accumulatedDiscountedReward:', 14.751052615853474)
('number of approximation units:', 1965, 'number of samples:', 2282)
('episode:', 126, 'number of steps:', 20, 'accumulatedReward:', 18.301995863250664, 'accumulatedDiscountedReward:', 15.423856202379643)
('number of approximation units:', 1981, 'number of samples:', 2302)
('episode:', 127, 'number of steps:', 23, 'accumulatedReward:', 21.301210075515655, 'accumulatedDiscountedReward:', 17.450558571232168)
('number of approximation units:', 2002, 'number of samples:', 2325)
('episode:', 128, 'number of steps:', 16, 'accumulatedReward:', 14.644068113775656, 'accumulatedDiscountedReward:', 12.793451875141024)
('number of approximation units:', 2013, 'number of samples:', 2341)
('episode:', 129, 'number of steps:', 27, 'accumulatedReward:', 25.490842342716363, 'accumulatedDiscountedReward:', 20.097548471620001)
('number of approximation units:', 2031, 'number of samples:', 2368)
('episode:', 130, 'number of steps:', 13, 'accumulatedReward:', 11.559156447971951, 'accumulatedDiscountedReward:', 10.396947432735088)
('number of approximation units:', 2039, 'number of samples:', 2381)
('episode:', 131, 'number of steps:', 76, 'accumulatedReward:', 74.3302052846674, 'accumulatedDiscountedReward:', 38.764724728929657)
('number of approximation units:', 2082, 'number of samples:', 2457)
('episode:', 132, 'number of steps:', 17, 'accumulatedReward:', 15.634275421938982, 'accumulatedDiscountedReward:', 13.53035397034747)
('number of approximation units:', 2095, 'number of samples:', 2474)
('episode:', 133, 'number of steps:', 27, 'accumulatedReward:', 25.271893961094904, 'accumulatedDiscountedReward:', 19.928181371336024)
('number of approximation units:', 2115, 'number of samples:', 2501)
('episode:', 134, 'number of steps:', 48, 'accumulatedReward:', 46.372254107146702, 'accumulatedDiscountedReward:', 30.337200941206895)
('number of approximation units:', 2150, 'number of samples:', 2549)
('episode:', 135, 'number of steps:', 21, 'accumulatedReward:', 19.428332905189979, 'accumulatedDiscountedReward:', 16.213673436042633)
('number of approximation units:', 2165, 'number of samples:', 2570)
('episode:', 136, 'number of steps:', 13, 'accumulatedReward:', 11.621762075506821, 'accumulatedDiscountedReward:', 10.451884151925512)
('number of approximation units:', 2176, 'number of samples:', 2583)
('episode:', 137, 'number of steps:', 43, 'accumulatedReward:', 41.199553955303593, 'accumulatedDiscountedReward:', 28.133552679058027)
('number of approximation units:', 2199, 'number of samples:', 2626)
('episode:', 138, 'number of steps:', 45, 'accumulatedReward:', 43.033455552395175, 'accumulatedDiscountedReward:', 28.927528421286144)
('number of approximation units:', 2229, 'number of samples:', 2671)
('episode:', 139, 'number of steps:', 16, 'accumulatedReward:', 14.392606183280773, 'accumulatedDiscountedReward:', 12.594073567598233)
('number of approximation units:', 2241, 'number of samples:', 2686)
('episode:', 140, 'number of steps:', 22, 'accumulatedReward:', 20.394502437570043, 'accumulatedDiscountedReward:', 16.847991430785804)
('number of approximation units:', 2255, 'number of samples:', 2708)
('episode:', 141, 'number of steps:', 22, 'accumulatedReward:', 20.440586060632896, 'accumulatedDiscountedReward:', 16.889210178094118)
('number of approximation units:', 2275, 'number of samples:', 2730)
('episode:', 142, 'number of steps:', 20, 'accumulatedReward:', 18.510440652898481, 'accumulatedDiscountedReward:', 15.578807319734167)
('number of approximation units:', 2288, 'number of samples:', 2750)
('episode:', 143, 'number of steps:', 24, 'accumulatedReward:', 22.385947697623784, 'accumulatedDiscountedReward:', 18.144012710299815)
('number of approximation units:', 2299, 'number of samples:', 2774)
('episode:', 144, 'number of steps:', 49, 'accumulatedReward:', 47.196333577027424, 'accumulatedDiscountedReward:', 30.660194802823696)
('number of approximation units:', 2332, 'number of samples:', 2823)
('episode:', 145, 'number of steps:', 24, 'accumulatedReward:', 22.585288240309794, 'accumulatedDiscountedReward:', 18.301964601699535)
('number of approximation units:', 2344, 'number of samples:', 2847)
('episode:', 146, 'number of steps:', 40, 'accumulatedReward:', 38.422197043149659, 'accumulatedDiscountedReward:', 26.94407677669831)
('number of approximation units:', 2372, 'number of samples:', 2886)
('episode:', 147, 'number of steps:', 12, 'accumulatedReward:', 10.530008350040076, 'accumulatedDiscountedReward:', 9.5665135856679981)
('number of approximation units:', 2381, 'number of samples:', 2898)
('episode:', 148, 'number of steps:', 11, 'accumulatedReward:', 9.4654612423418527, 'accumulatedDiscountedReward:', 8.6868914704145919)
('number of approximation units:', 2390, 'number of samples:', 2909)
('episode:', 149, 'number of steps:', 23, 'accumulatedReward:', 21.535361364444466, 'accumulatedDiscountedReward:', 17.618505835926857)
('number of approximation units:', 2404, 'number of samples:', 2932)
('episode:', 150, 'number of steps:', 22, 'accumulatedReward:', 20.275956811175984, 'accumulatedDiscountedReward:', 16.774506666609106)
('number of approximation units:', 2424, 'number of samples:', 2954)
('episode:', 151, 'number of steps:', 15, 'accumulatedReward:', 13.50773647652413, 'accumulatedDiscountedReward:', 11.918877694240509)
('number of approximation units:', 2436, 'number of samples:', 2969)
('episode:', 152, 'number of steps:', 34, 'accumulatedReward:', 32.399917976194061, 'accumulatedDiscountedReward:', 23.977109288374059)
('number of approximation units:', 2455, 'number of samples:', 3003)
('episode:', 153, 'number of steps:', 20, 'accumulatedReward:', 18.450531868000677, 'accumulatedDiscountedReward:', 15.542641088862887)
('number of approximation units:', 2469, 'number of samples:', 3023)
('episode:', 154, 'number of steps:', 43, 'accumulatedReward:', 41.434950514242573, 'accumulatedDiscountedReward:', 28.296548870148818)
('number of approximation units:', 2499, 'number of samples:', 3066)
('episode:', 155, 'number of steps:', 91, 'accumulatedReward:', 89.009499548392327, 'accumulatedDiscountedReward:', 41.493800391948689)
('number of approximation units:', 2557, 'number of samples:', 3157)
('episode:', 156, 'number of steps:', 38, 'accumulatedReward:', 36.550716324704858, 'accumulatedDiscountedReward:', 26.069464214869615)
('number of approximation units:', 2581, 'number of samples:', 3195)
('episode:', 157, 'number of steps:', 200, 'accumulatedReward:', 199.14559578733031, 'accumulatedDiscountedReward:', 48.868697744754833)
('number of approximation units:', 2708, 'number of samples:', 3395)
('episode:', 158, 'number of steps:', 14, 'accumulatedReward:', 12.599029566790389, 'accumulatedDiscountedReward:', 11.222856866495901)
('number of approximation units:', 2717, 'number of samples:', 3408)
('episode:', 159, 'number of steps:', 10, 'accumulatedReward:', 8.5703220697676894, 'accumulatedDiscountedReward:', 7.9350768267463891)
('number of approximation units:', 2725, 'number of samples:', 3418)
('episode:', 160, 'number of steps:', 83, 'accumulatedReward:', 81.079260381327259, 'accumulatedDiscountedReward:', 40.134634955832013)
('number of approximation units:', 2773, 'number of samples:', 3499)
('episode:', 161, 'number of steps:', 10, 'accumulatedReward:', 8.6679867122185943, 'accumulatedDiscountedReward:', 8.0238992704556402)
('number of approximation units:', 2780, 'number of samples:', 3509)
('episode:', 162, 'number of steps:', 60, 'accumulatedReward:', 58.294391997043988, 'accumulatedDiscountedReward:', 34.536350748370822)
('number of approximation units:', 2814, 'number of samples:', 3565)
('episode:', 163, 'number of steps:', 27, 'accumulatedReward:', 25.372818637912822, 'accumulatedDiscountedReward:', 20.02559262306476)
('number of approximation units:', 2833, 'number of samples:', 3591)
('episode:', 164, 'number of steps:', 14, 'accumulatedReward:', 12.365461206157317, 'accumulatedDiscountedReward:', 11.0291332466126)
('number of approximation units:', 2842, 'number of samples:', 3605)
('episode:', 165, 'number of steps:', 20, 'accumulatedReward:', 18.634056993685093, 'accumulatedDiscountedReward:', 15.66751884171839)
('number of approximation units:', 2854, 'number of samples:', 3625)
('episode:', 166, 'number of steps:', 52, 'accumulatedReward:', 50.193638397372027, 'accumulatedDiscountedReward:', 31.813824719367901)
('number of approximation units:', 2879, 'number of samples:', 3677)
('episode:', 167, 'number of steps:', 29, 'accumulatedReward:', 27.467002080071637, 'accumulatedDiscountedReward:', 21.235013639870129)
('number of approximation units:', 2893, 'number of samples:', 3705)
('episode:', 168, 'number of steps:', 19, 'accumulatedReward:', 17.39260700848147, 'accumulatedDiscountedReward:', 14.791693457125039)
('number of approximation units:', 2908, 'number of samples:', 3724)
('episode:', 169, 'number of steps:', 36, 'accumulatedReward:', 34.294330486771692, 'accumulatedDiscountedReward:', 24.958331502269676)
('number of approximation units:', 2933, 'number of samples:', 3760)
('episode:', 170, 'number of steps:', 24, 'accumulatedReward:', 22.220469921906464, 'accumulatedDiscountedReward:', 18.042723755079791)
('number of approximation units:', 2948, 'number of samples:', 3783)
('episode:', 171, 'number of steps:', 12, 'accumulatedReward:', 10.668500514726723, 'accumulatedDiscountedReward:', 9.6849122211195731)
('number of approximation units:', 2958, 'number of samples:', 3795)
('episode:', 172, 'number of steps:', 45, 'accumulatedReward:', 43.250392917441545, 'accumulatedDiscountedReward:', 29.084593955329268)
('number of approximation units:', 2984, 'number of samples:', 3839)
('episode:', 173, 'number of steps:', 49, 'accumulatedReward:', 47.379130154443921, 'accumulatedDiscountedReward:', 30.750714973105826)
('number of approximation units:', 3015, 'number of samples:', 3888)
('episode:', 174, 'number of steps:', 200, 'accumulatedReward:', 199.11759118567304, 'accumulatedDiscountedReward:', 48.89339997731647)
('number of approximation units:', 3107, 'number of samples:', 4084)
('episode:', 175, 'number of steps:', 87, 'accumulatedReward:', 85.328044528387579, 'accumulatedDiscountedReward:', 41.035536688744457)
('number of approximation units:', 3151, 'number of samples:', 4169)
('episode:', 176, 'number of steps:', 63, 'accumulatedReward:', 61.391693867156143, 'accumulatedDiscountedReward:', 35.44957656218142)
('number of approximation units:', 3175, 'number of samples:', 4232)
('episode:', 177, 'number of steps:', 21, 'accumulatedReward:', 19.359428909102572, 'accumulatedDiscountedReward:', 16.147846213787979)
('number of approximation units:', 3190, 'number of samples:', 4253)
('episode:', 178, 'number of steps:', 52, 'accumulatedReward:', 50.287859238391782, 'accumulatedDiscountedReward:', 31.854990612707034)
('number of approximation units:', 3219, 'number of samples:', 4305)
('episode:', 179, 'number of steps:', 53, 'accumulatedReward:', 51.381376828461441, 'accumulatedDiscountedReward:', 32.249792277667723)
('number of approximation units:', 3249, 'number of samples:', 4358)
('episode:', 180, 'number of steps:', 47, 'accumulatedReward:', 45.429615519911678, 'accumulatedDiscountedReward:', 30.000320155309485)
('number of approximation units:', 3274, 'number of samples:', 4405)
('episode:', 181, 'number of steps:', 10, 'accumulatedReward:', 8.7196463874081847, 'accumulatedDiscountedReward:', 8.0693122373832313)
('number of approximation units:', 3283, 'number of samples:', 4415)
('episode:', 182, 'number of steps:', 113, 'accumulatedReward:', 111.08774395957698, 'accumulatedDiscountedReward:', 44.562966128930945)
('number of approximation units:', 3329, 'number of samples:', 4525)
('episode:', 183, 'number of steps:', 92, 'accumulatedReward:', 90.061086481174357, 'accumulatedDiscountedReward:', 41.796285201807585)
('number of approximation units:', 3375, 'number of samples:', 4614)
('episode:', 184, 'number of steps:', 36, 'accumulatedReward:', 34.387683264578413, 'accumulatedDiscountedReward:', 25.006711506904448)
('number of approximation units:', 3393, 'number of samples:', 4648)
('episode:', 185, 'number of steps:', 116, 'accumulatedReward:', 114.35879284351074, 'accumulatedDiscountedReward:', 44.958901457618431)
('number of approximation units:', 3451, 'number of samples:', 4758)
('episode:', 186, 'number of steps:', 96, 'accumulatedReward:', 94.182219802913423, 'accumulatedDiscountedReward:', 42.45689317559259)
('number of approximation units:', 3488, 'number of samples:', 4852)
('episode:', 187, 'number of steps:', 77, 'accumulatedReward:', 75.27414096774676, 'accumulatedDiscountedReward:', 39.008835786692231)
('number of approximation units:', 3531, 'number of samples:', 4927)
('episode:', 188, 'number of steps:', 200, 'accumulatedReward:', 199.41591121714231, 'accumulatedDiscountedReward:', 49.001420082536065)
('number of approximation units:', 3620, 'number of samples:', 5116)
('episode:', 189, 'number of steps:', 34, 'accumulatedReward:', 32.477103472661454, 'accumulatedDiscountedReward:', 24.027501130092613)
('number of approximation units:', 3639, 'number of samples:', 5148)
('episode:', 190, 'number of steps:', 64, 'accumulatedReward:', 62.256232016973918, 'accumulatedDiscountedReward:', 35.734458615932247)
('number of approximation units:', 3672, 'number of samples:', 5209)
('episode:', 191, 'number of steps:', 10, 'accumulatedReward:', 8.5881568498720533, 'accumulatedDiscountedReward:', 7.9524136269943995)
('number of approximation units:', 3682, 'number of samples:', 5219)
('episode:', 192, 'number of steps:', 42, 'accumulatedReward:', 40.363622807270424, 'accumulatedDiscountedReward:', 27.839124885988753)
('number of approximation units:', 3694, 'number of samples:', 5260)
('episode:', 193, 'number of steps:', 58, 'accumulatedReward:', 56.417736406170164, 'accumulatedDiscountedReward:', 33.963810099894722)
('number of approximation units:', 3721, 'number of samples:', 5316)
('episode:', 194, 'number of steps:', 39, 'accumulatedReward:', 37.507514662794399, 'accumulatedDiscountedReward:', 26.539066465195472)
('number of approximation units:', 3736, 'number of samples:', 5349)
('episode:', 195, 'number of steps:', 129, 'accumulatedReward:', 126.75093128837044, 'accumulatedDiscountedReward:', 45.963064424006028)
('number of approximation units:', 3795, 'number of samples:', 5473)
('episode:', 196, 'number of steps:', 56, 'accumulatedReward:', 54.326016516435253, 'accumulatedDiscountedReward:', 33.267994118945658)
('number of approximation units:', 3818, 'number of samples:', 5524)
('episode:', 197, 'number of steps:', 13, 'accumulatedReward:', 11.533940445839054, 'accumulatedDiscountedReward:', 10.38231832451897)
('number of approximation units:', 3830, 'number of samples:', 5537)
('episode:', 198, 'number of steps:', 22, 'accumulatedReward:', 20.381956633709017, 'accumulatedDiscountedReward:', 16.831200528212229)
('number of approximation units:', 3846, 'number of samples:', 5559)
('episode:', 199, 'number of steps:', 91, 'accumulatedReward:', 89.188555193155665, 'accumulatedDiscountedReward:', 41.628556226082033)
('number of approximation units:', 3883, 'number of samples:', 5644)
('episode:', 200, 'number of steps:', 165, 'accumulatedReward:', 162.54456474158377, 'accumulatedDiscountedReward:', 47.813850219442806)
('number of approximation units:', 3946, 'number of samples:', 5793)
('episode:', 201, 'number of steps:', 12, 'accumulatedReward:', 10.601395408253902, 'accumulatedDiscountedReward:', 9.6290742747469587)
('number of approximation units:', 3952, 'number of samples:', 5805)
('episode:', 202, 'number of steps:', 24, 'accumulatedReward:', 22.605985197170479, 'accumulatedDiscountedReward:', 18.317607849589994)
('number of approximation units:', 3965, 'number of samples:', 5828)
('episode:', 203, 'number of steps:', 126, 'accumulatedReward:', 123.87425668417127, 'accumulatedDiscountedReward:', 45.723393687851448)
('number of approximation units:', 4018, 'number of samples:', 5944)
('episode:', 204, 'number of steps:', 72, 'accumulatedReward:', 70.443255619773211, 'accumulatedDiscountedReward:', 37.904920119341391)
('number of approximation units:', 4047, 'number of samples:', 6013)
('episode:', 205, 'number of steps:', 48, 'accumulatedReward:', 46.465383018262727, 'accumulatedDiscountedReward:', 30.403609220191314)
('number of approximation units:', 4065, 'number of samples:', 6055)
('episode:', 206, 'number of steps:', 64, 'accumulatedReward:', 62.245662005513118, 'accumulatedDiscountedReward:', 35.686475602178305)
('number of approximation units:', 4086, 'number of samples:', 6115)
('episode:', 207, 'number of steps:', 82, 'accumulatedReward:', 80.441699901755811, 'accumulatedDiscountedReward:', 40.09679159698819)
('number of approximation units:', 4118, 'number of samples:', 6194)
('episode:', 208, 'number of steps:', 53, 'accumulatedReward:', 51.518983047510737, 'accumulatedDiscountedReward:', 32.298184513447126)
('number of approximation units:', 4143, 'number of samples:', 6243)
('episode:', 209, 'number of steps:', 26, 'accumulatedReward:', 24.544314119525605, 'accumulatedDiscountedReward:', 19.535191513661673)
('number of approximation units:', 4156, 'number of samples:', 6268)
('episode:', 210, 'number of steps:', 140, 'accumulatedReward:', 137.94979215775427, 'accumulatedDiscountedReward:', 46.784462576239861)
('number of approximation units:', 4197, 'number of samples:', 6395)
('episode:', 211, 'number of steps:', 57, 'accumulatedReward:', 55.245984026699148, 'accumulatedDiscountedReward:', 33.574719483729098)
('number of approximation units:', 4212, 'number of samples:', 6448)
('episode:', 212, 'number of steps:', 37, 'accumulatedReward:', 35.497710368509999, 'accumulatedDiscountedReward:', 25.566668766895337)
('number of approximation units:', 4226, 'number of samples:', 6479)
('episode:', 213, 'number of steps:', 31, 'accumulatedReward:', 29.433125122216463, 'accumulatedDiscountedReward:', 22.377496599069904)
('number of approximation units:', 4239, 'number of samples:', 6506)
('episode:', 214, 'number of steps:', 45, 'accumulatedReward:', 43.45859350460934, 'accumulatedDiscountedReward:', 29.174450398649753)
('number of approximation units:', 4260, 'number of samples:', 6547)
('episode:', 215, 'number of steps:', 53, 'accumulatedReward:', 51.212357754956869, 'accumulatedDiscountedReward:', 32.162732612394606)
('number of approximation units:', 4277, 'number of samples:', 6598)
('episode:', 216, 'number of steps:', 138, 'accumulatedReward:', 135.95619473660616, 'accumulatedDiscountedReward:', 46.679518615086351)
('number of approximation units:', 4323, 'number of samples:', 6717)
('episode:', 217, 'number of steps:', 74, 'accumulatedReward:', 72.193006394438981, 'accumulatedDiscountedReward:', 38.267396613903365)
('number of approximation units:', 4349, 'number of samples:', 6786)
('episode:', 218, 'number of steps:', 200, 'accumulatedReward:', 199.17420647871964, 'accumulatedDiscountedReward:', 48.91371833887203)
('number of approximation units:', 4406, 'number of samples:', 6964)
('episode:', 219, 'number of steps:', 119, 'accumulatedReward:', 117.11322907246564, 'accumulatedDiscountedReward:', 45.083303630561296)
('number of approximation units:', 4445, 'number of samples:', 7071)
('episode:', 220, 'number of steps:', 91, 'accumulatedReward:', 89.320138450267009, 'accumulatedDiscountedReward:', 41.692074631779612)
('number of approximation units:', 4483, 'number of samples:', 7156)
('episode:', 221, 'number of steps:', 58, 'accumulatedReward:', 56.480665360345995, 'accumulatedDiscountedReward:', 33.990049443485887)
('number of approximation units:', 4506, 'number of samples:', 7209)
('episode:', 222, 'number of steps:', 79, 'accumulatedReward:', 77.368699076616281, 'accumulatedDiscountedReward:', 39.465627865960897)
('number of approximation units:', 4530, 'number of samples:', 7278)
('episode:', 223, 'number of steps:', 66, 'accumulatedReward:', 64.289778867317878, 'accumulatedDiscountedReward:', 36.314873225769958)
('number of approximation units:', 4547, 'number of samples:', 7333)
('episode:', 224, 'number of steps:', 97, 'accumulatedReward:', 95.399080556748984, 'accumulatedDiscountedReward:', 42.662779074561151)
('number of approximation units:', 4572, 'number of samples:', 7413)
('episode:', 225, 'number of steps:', 200, 'accumulatedReward:', 199.49210381188743, 'accumulatedDiscountedReward:', 48.979997675954955)
('number of approximation units:', 4632, 'number of samples:', 7586)
('episode:', 226, 'number of steps:', 56, 'accumulatedReward:', 54.398349386720497, 'accumulatedDiscountedReward:', 33.30470356975345)
('number of approximation units:', 4653, 'number of samples:', 7634)
('episode:', 227, 'number of steps:', 76, 'accumulatedReward:', 74.267796524248851, 'accumulatedDiscountedReward:', 38.761920835198758)
('number of approximation units:', 4670, 'number of samples:', 7692)
('episode:', 228, 'number of steps:', 44, 'accumulatedReward:', 42.427829702303804, 'accumulatedDiscountedReward:', 28.751289997792515)
('number of approximation units:', 4682, 'number of samples:', 7723)
('episode:', 229, 'number of steps:', 200, 'accumulatedReward:', 199.59686184817861, 'accumulatedDiscountedReward:', 49.01972392599771)
('number of approximation units:', 4737, 'number of samples:', 7888)
('episode:', 230, 'number of steps:', 200, 'accumulatedReward:', 199.51045203129084, 'accumulatedDiscountedReward:', 48.974084194817095)
('number of approximation units:', 4776, 'number of samples:', 8049)
('episode:', 231, 'number of steps:', 112, 'accumulatedReward:', 110.08694391117189, 'accumulatedDiscountedReward:', 44.515129932481699)
('number of approximation units:', 4816, 'number of samples:', 8145)
('episode:', 232, 'number of steps:', 80, 'accumulatedReward:', 78.201864222879465, 'accumulatedDiscountedReward:', 39.624520078861217)
('number of approximation units:', 4843, 'number of samples:', 8211)
('episode:', 233, 'number of steps:', 200, 'accumulatedReward:', 199.54450694243934, 'accumulatedDiscountedReward:', 48.988060425022063)
('number of approximation units:', 4884, 'number of samples:', 8351)
('episode:', 234, 'number of steps:', 200, 'accumulatedReward:', 199.68945427893181, 'accumulatedDiscountedReward:', 49.043328762745041)
('number of approximation units:', 4925, 'number of samples:', 8494)
('episode:', 235, 'number of steps:', 30, 'accumulatedReward:', 28.542421660721388, 'accumulatedDiscountedReward:', 21.894864068354146)
('number of approximation units:', 4937, 'number of samples:', 8516)
('episode:', 236, 'number of steps:', 171, 'accumulatedReward:', 168.86650222174134, 'accumulatedDiscountedReward:', 48.245919528467738)
('number of approximation units:', 4986, 'number of samples:', 8638)
('episode:', 237, 'number of steps:', 200, 'accumulatedReward:', 199.57826167935681, 'accumulatedDiscountedReward:', 49.007421076068646)
('number of approximation units:', 5022, 'number of samples:', 8776)
('episode:', 238, 'number of steps:', 19, 'accumulatedReward:', 17.462078731288738, 'accumulatedDiscountedReward:', 14.832057552300707)
('number of approximation units:', 5033, 'number of samples:', 8795)
('episode:', 239, 'number of steps:', 54, 'accumulatedReward:', 52.440913737464996, 'accumulatedDiscountedReward:', 32.63797717734387)
('number of approximation units:', 5050, 'number of samples:', 8832)
('episode:', 240, 'number of steps:', 29, 'accumulatedReward:', 27.49122668025079, 'accumulatedDiscountedReward:', 21.281303446374707)
('number of approximation units:', 5061, 'number of samples:', 8855)
('episode:', 241, 'number of steps:', 18, 'accumulatedReward:', 16.277330042511885, 'accumulatedDiscountedReward:', 13.982591661517166)
('number of approximation units:', 5071, 'number of samples:', 8873)
('episode:', 242, 'number of steps:', 119, 'accumulatedReward:', 117.36334982211073, 'accumulatedDiscountedReward:', 45.261740855093166)
('number of approximation units:', 5088, 'number of samples:', 8943)
('episode:', 243, 'number of steps:', 200, 'accumulatedReward:', 199.41728136595418, 'accumulatedDiscountedReward:', 48.969520102412829)
('number of approximation units:', 5116, 'number of samples:', 9066)
('episode:', 244, 'number of steps:', 14, 'accumulatedReward:', 12.475067496668844, 'accumulatedDiscountedReward:', 11.117939724305357)
('number of approximation units:', 5125, 'number of samples:', 9080)
('episode:', 245, 'number of steps:', 63, 'accumulatedReward:', 61.528507357788229, 'accumulatedDiscountedReward:', 35.542019450275994)
('number of approximation units:', 5142, 'number of samples:', 9128)
('episode:', 246, 'number of steps:', 49, 'accumulatedReward:', 47.406975624804012, 'accumulatedDiscountedReward:', 30.77367514504369)
('number of approximation units:', 5162, 'number of samples:', 9161)
('episode:', 247, 'number of steps:', 157, 'accumulatedReward:', 154.99179076820565, 'accumulatedDiscountedReward:', 47.705454102391641)
('number of approximation units:', 5187, 'number of samples:', 9259)
('episode:', 248, 'number of steps:', 9, 'accumulatedReward:', 7.494454510072047, 'accumulatedDiscountedReward:', 7.0123998476689069)
('number of approximation units:', 5194, 'number of samples:', 9267)
('episode:', 249, 'number of steps:', 38, 'accumulatedReward:', 36.510910109683302, 'accumulatedDiscountedReward:', 26.05465973860229)
('number of approximation units:', 5203, 'number of samples:', 9291)
('episode:', 250, 'number of steps:', 193, 'accumulatedReward:', 191.0878809103304, 'accumulatedDiscountedReward:', 48.856590325798798)
('number of approximation units:', 5240, 'number of samples:', 9426)
('episode:', 251, 'number of steps:', 163, 'accumulatedReward:', 161.23411146086974, 'accumulatedDiscountedReward:', 47.991376507254394)
('number of approximation units:', 5270, 'number of samples:', 9518)
('episode:', 252, 'number of steps:', 134, 'accumulatedReward:', 132.28913805114928, 'accumulatedDiscountedReward:', 46.44822184163926)
('number of approximation units:', 5295, 'number of samples:', 9585)
('episode:', 253, 'number of steps:', 116, 'accumulatedReward:', 114.14832225419265, 'accumulatedDiscountedReward:', 44.904885421541643)
('number of approximation units:', 5320, 'number of samples:', 9665)
('episode:', 254, 'number of steps:', 133, 'accumulatedReward:', 131.29664422209308, 'accumulatedDiscountedReward:', 46.400615410504422)
('number of approximation units:', 5348, 'number of samples:', 9743)
('episode:', 255, 'number of steps:', 73, 'accumulatedReward:', 71.394885481152187, 'accumulatedDiscountedReward:', 38.140096716798823)
('number of approximation units:', 5372, 'number of samples:', 9794)
('episode:', 256, 'number of steps:', 200, 'accumulatedReward:', 199.32410571801441, 'accumulatedDiscountedReward:', 49.00179730531552)
('number of approximation units:', 5411, 'number of samples:', 9922)
('episode:', 257, 'number of steps:', 12, 'accumulatedReward:', 10.510804042411893, 'accumulatedDiscountedReward:', 9.5500575159668113)
('number of approximation units:', 5420, 'number of samples:', 9934)
('episode:', 258, 'number of steps:', 12, 'accumulatedReward:', 10.494669974210233, 'accumulatedDiscountedReward:', 9.5395481271158307)
('number of approximation units:', 5428, 'number of samples:', 9946)
('episode:', 259, 'number of steps:', 106, 'accumulatedReward:', 104.0853788966914, 'accumulatedDiscountedReward:', 43.819456158322744)
('number of approximation units:', 5460, 'number of samples:', 10034)
('episode:', 260, 'number of steps:', 200, 'accumulatedReward:', 199.48022409772858, 'accumulatedDiscountedReward:', 48.975078762942694)
('number of approximation units:', 5488, 'number of samples:', 10139)
('episode:', 261, 'number of steps:', 56, 'accumulatedReward:', 54.332676754461552, 'accumulatedDiscountedReward:', 33.254573839816267)
('number of approximation units:', 5500, 'number of samples:', 10170)
('episode:', 262, 'number of steps:', 36, 'accumulatedReward:', 34.128187275419933, 'accumulatedDiscountedReward:', 24.85609110076124)
('number of approximation units:', 5513, 'number of samples:', 10201)
('episode:', 263, 'number of steps:', 200, 'accumulatedReward:', 199.29408311753994, 'accumulatedDiscountedReward:', 48.971800951304196)
('number of approximation units:', 5554, 'number of samples:', 10317)
('episode:', 264, 'number of steps:', 200, 'accumulatedReward:', 199.47047412825168, 'accumulatedDiscountedReward:', 48.996910146122026)
('number of approximation units:', 5582, 'number of samples:', 10429)
('episode:', 265, 'number of steps:', 22, 'accumulatedReward:', 20.371344156774789, 'accumulatedDiscountedReward:', 16.820732169646107)
('number of approximation units:', 5596, 'number of samples:', 10450)
('episode:', 266, 'number of steps:', 17, 'accumulatedReward:', 15.55798184108672, 'accumulatedDiscountedReward:', 13.463752749010172)
('number of approximation units:', 5605, 'number of samples:', 10466)
('episode:', 267, 'number of steps:', 108, 'accumulatedReward:', 106.28770122673394, 'accumulatedDiscountedReward:', 44.055283706658528)
('number of approximation units:', 5623, 'number of samples:', 10531)
('episode:', 268, 'number of steps:', 200, 'accumulatedReward:', 199.57672745215771, 'accumulatedDiscountedReward:', 49.033519004937972)
('number of approximation units:', 5643, 'number of samples:', 10626)
('episode:', 269, 'number of steps:', 69, 'accumulatedReward:', 67.039075698077269, 'accumulatedDiscountedReward:', 36.954689709925056)
('number of approximation units:', 5659, 'number of samples:', 10666)
('episode:', 270, 'number of steps:', 175, 'accumulatedReward:', 172.87204671123419, 'accumulatedDiscountedReward:', 48.305240495770903)
('number of approximation units:', 5685, 'number of samples:', 10775)
('episode:', 271, 'number of steps:', 17, 'accumulatedReward:', 15.501207283745925, 'accumulatedDiscountedReward:', 13.43174145180561)
('number of approximation units:', 5693, 'number of samples:', 10785)
('episode:', 272, 'number of steps:', 96, 'accumulatedReward:', 94.105227759944029, 'accumulatedDiscountedReward:', 42.409383610496931)
('number of approximation units:', 5713, 'number of samples:', 10845)
('episode:', 273, 'number of steps:', 136, 'accumulatedReward:', 134.09956617610132, 'accumulatedDiscountedReward:', 46.553711301591413)
('number of approximation units:', 5737, 'number of samples:', 10929)
('episode:', 274, 'number of steps:', 59, 'accumulatedReward:', 57.400424097608763, 'accumulatedDiscountedReward:', 34.286269963561075)
('number of approximation units:', 5752, 'number of samples:', 10968)
('episode:', 275, 'number of steps:', 12, 'accumulatedReward:', 10.705376659548957, 'accumulatedDiscountedReward:', 9.718054789268761)
('number of approximation units:', 5757, 'number of samples:', 10975)
('episode:', 276, 'number of steps:', 200, 'accumulatedReward:', 199.50627927521751, 'accumulatedDiscountedReward:', 49.00061899636389)
('number of approximation units:', 5777, 'number of samples:', 11072)
('episode:', 277, 'number of steps:', 10, 'accumulatedReward:', 8.5424423344802154, 'accumulatedDiscountedReward:', 7.9139080067235428)
('number of approximation units:', 5786, 'number of samples:', 11082)
('episode:', 278, 'number of steps:', 85, 'accumulatedReward:', 83.450058654873146, 'accumulatedDiscountedReward:', 40.664085911604268)
('number of approximation units:', 5794, 'number of samples:', 11120)
('episode:', 279, 'number of steps:', 27, 'accumulatedReward:', 25.427916422455951, 'accumulatedDiscountedReward:', 20.068728440174191)
('number of approximation units:', 5804, 'number of samples:', 11140)
('episode:', 280, 'number of steps:', 200, 'accumulatedReward:', 199.38440021246453, 'accumulatedDiscountedReward:', 48.954838668314345)
('number of approximation units:', 5826, 'number of samples:', 11227)
('episode:', 281, 'number of steps:', 32, 'accumulatedReward:', 30.27852295797431, 'accumulatedDiscountedReward:', 22.796143501868436)
('number of approximation units:', 5839, 'number of samples:', 11259)
('episode:', 282, 'number of steps:', 41, 'accumulatedReward:', 39.34801584168423, 'accumulatedDiscountedReward:', 27.384687169360205)
('number of approximation units:', 5849, 'number of samples:', 11285)
('episode:', 283, 'number of steps:', 106, 'accumulatedReward:', 104.25657366603689, 'accumulatedDiscountedReward:', 43.831433093188195)
('number of approximation units:', 5864, 'number of samples:', 11336)
('episode:', 284, 'number of steps:', 100, 'accumulatedReward:', 98.42929820047496, 'accumulatedDiscountedReward:', 43.08880907225965)
('number of approximation units:', 5879, 'number of samples:', 11387)
('episode:', 285, 'number of steps:', 200, 'accumulatedReward:', 199.3648544888699, 'accumulatedDiscountedReward:', 48.949972393136591)
('number of approximation units:', 5910, 'number of samples:', 11478)
('episode:', 286, 'number of steps:', 36, 'accumulatedReward:', 34.466772141415952, 'accumulatedDiscountedReward:', 25.040994426778777)
('number of approximation units:', 5921, 'number of samples:', 11504)
('episode:', 287, 'number of steps:', 15, 'accumulatedReward:', 13.581351623354132, 'accumulatedDiscountedReward:', 11.986541106466918)
('number of approximation units:', 5927, 'number of samples:', 11518)
('episode:', 288, 'number of steps:', 200, 'accumulatedReward:', 199.45378755465779, 'accumulatedDiscountedReward:', 48.999198332527392)
('number of approximation units:', 5948, 'number of samples:', 11612)
('episode:', 289, 'number of steps:', 157, 'accumulatedReward:', 154.67995618932412, 'accumulatedDiscountedReward:', 47.698313327336486)
('number of approximation units:', 5982, 'number of samples:', 11699)
('episode:', 290, 'number of steps:', 200, 'accumulatedReward:', 199.52092732413217, 'accumulatedDiscountedReward:', 49.006979606649423)
('number of approximation units:', 5997, 'number of samples:', 11776)
('episode:', 291, 'number of steps:', 91, 'accumulatedReward:', 89.268951443505273, 'accumulatedDiscountedReward:', 41.708342094634467)
('number of approximation units:', 6013, 'number of samples:', 11830)
('episode:', 292, 'number of steps:', 187, 'accumulatedReward:', 184.91554158811539, 'accumulatedDiscountedReward:', 48.671429354882996)
('number of approximation units:', 6038, 'number of samples:', 11904)
('episode:', 293, 'number of steps:', 12, 'accumulatedReward:', 10.703938909720867, 'accumulatedDiscountedReward:', 9.7141030625690767)
('number of approximation units:', 6048, 'number of samples:', 11916)
('episode:', 294, 'number of steps:', 78, 'accumulatedReward:', 76.160183814494857, 'accumulatedDiscountedReward:', 39.189876879858318)
('number of approximation units:', 6062, 'number of samples:', 11957)
('episode:', 295, 'number of steps:', 69, 'accumulatedReward:', 67.261524552455271, 'accumulatedDiscountedReward:', 37.103997688956113)
('number of approximation units:', 6077, 'number of samples:', 11990)
('episode:', 296, 'number of steps:', 77, 'accumulatedReward:', 75.378629117089915, 'accumulatedDiscountedReward:', 39.039084283398068)
('number of approximation units:', 6092, 'number of samples:', 12024)
('episode:', 297, 'number of steps:', 200, 'accumulatedReward:', 199.48118717064111, 'accumulatedDiscountedReward:', 49.010972222774782)
('number of approximation units:', 6104, 'number of samples:', 12093)
('episode:', 298, 'number of steps:', 34, 'accumulatedReward:', 32.423260404857807, 'accumulatedDiscountedReward:', 23.976744375527019)
('number of approximation units:', 6114, 'number of samples:', 12119)
('episode:', 299, 'number of steps:', 184, 'accumulatedReward:', 182.12462189667488, 'accumulatedDiscountedReward:', 48.542883217551683)
('number of approximation units:', 6142, 'number of samples:', 12215)
('episode:', 300, 'number of steps:', 200, 'accumulatedReward:', 199.43873559629208, 'accumulatedDiscountedReward:', 48.985571438427918)
('number of approximation units:', 6159, 'number of samples:', 12281)
('episode:', 301, 'number of steps:', 200, 'accumulatedReward:', 199.45204524937697, 'accumulatedDiscountedReward:', 49.017482831786403)
('number of approximation units:', 6173, 'number of samples:', 12338)
('episode:', 302, 'number of steps:', 118, 'accumulatedReward:', 116.11229672610979, 'accumulatedDiscountedReward:', 45.135485412788739)
('number of approximation units:', 6192, 'number of samples:', 12395)
('episode:', 303, 'number of steps:', 80, 'accumulatedReward:', 78.228411828325662, 'accumulatedDiscountedReward:', 39.621432907183184)
('number of approximation units:', 6208, 'number of samples:', 12442)
('episode:', 304, 'number of steps:', 200, 'accumulatedReward:', 199.31603135341501, 'accumulatedDiscountedReward:', 48.982337252613405)
('number of approximation units:', 6230, 'number of samples:', 12538)
('episode:', 305, 'number of steps:', 74, 'accumulatedReward:', 72.390138230040449, 'accumulatedDiscountedReward:', 38.348279593883504)
('number of approximation units:', 6238, 'number of samples:', 12566)
('episode:', 306, 'number of steps:', 93, 'accumulatedReward:', 91.345672554976971, 'accumulatedDiscountedReward:', 42.054286433288361)
('number of approximation units:', 6254, 'number of samples:', 12601)
('episode:', 307, 'number of steps:', 200, 'accumulatedReward:', 199.60825831184201, 'accumulatedDiscountedReward:', 49.033996599518346)
('number of approximation units:', 6262, 'number of samples:', 12657)
('episode:', 308, 'number of steps:', 127, 'accumulatedReward:', 125.05709924602409, 'accumulatedDiscountedReward:', 45.919126037628772)
('number of approximation units:', 6275, 'number of samples:', 12711)
('episode:', 309, 'number of steps:', 59, 'accumulatedReward:', 57.455229517896612, 'accumulatedDiscountedReward:', 34.295867106924945)
('number of approximation units:', 6284, 'number of samples:', 12738)
('episode:', 310, 'number of steps:', 200, 'accumulatedReward:', 199.54195371684122, 'accumulatedDiscountedReward:', 48.987855025784206)
('number of approximation units:', 6292, 'number of samples:', 12802)
('episode:', 311, 'number of steps:', 200, 'accumulatedReward:', 199.44838212716803, 'accumulatedDiscountedReward:', 48.98756934848214)
('number of approximation units:', 6311, 'number of samples:', 12881)
('episode:', 312, 'number of steps:', 98, 'accumulatedReward:', 96.279401628350854, 'accumulatedDiscountedReward:', 42.782006010905327)
('number of approximation units:', 6327, 'number of samples:', 12932)
('episode:', 313, 'number of steps:', 140, 'accumulatedReward:', 138.21377393680609, 'accumulatedDiscountedReward:', 46.849026190582187)
('number of approximation units:', 6341, 'number of samples:', 12978)
('episode:', 314, 'number of steps:', 11, 'accumulatedReward:', 9.656206313567246, 'accumulatedDiscountedReward:', 8.8515755524014565)
('number of approximation units:', 6345, 'number of samples:', 12985)
('episode:', 315, 'number of steps:', 72, 'accumulatedReward:', 70.227488556826358, 'accumulatedDiscountedReward:', 37.810261818454677)
('number of approximation units:', 6359, 'number of samples:', 13017)
('episode:', 316, 'number of steps:', 40, 'accumulatedReward:', 38.581253629426122, 'accumulatedDiscountedReward:', 27.038228439472345)
('number of approximation units:', 6365, 'number of samples:', 13034)
('episode:', 317, 'number of steps:', 10, 'accumulatedReward:', 8.6845935253750959, 'accumulatedDiscountedReward:', 8.0373161455087558)
('number of approximation units:', 6372, 'number of samples:', 13044)
('episode:', 318, 'number of steps:', 10, 'accumulatedReward:', 8.6260774256847714, 'accumulatedDiscountedReward:', 7.987138109981168)
('number of approximation units:', 6380, 'number of samples:', 13054)
('episode:', 319, 'number of steps:', 119, 'accumulatedReward:', 117.2110919413042, 'accumulatedDiscountedReward:', 45.227435548148051)
('number of approximation units:', 6398, 'number of samples:', 13105)
('episode:', 320, 'number of steps:', 146, 'accumulatedReward:', 143.97754319049614, 'accumulatedDiscountedReward:', 47.167724144154974)
('number of approximation units:', 6415, 'number of samples:', 13161)
('episode:', 321, 'number of steps:', 9, 'accumulatedReward:', 7.629304454950713, 'accumulatedDiscountedReward:', 7.1325055722670365)
('number of approximation units:', 6422, 'number of samples:', 13170)
('episode:', 322, 'number of steps:', 139, 'accumulatedReward:', 137.13716082860236, 'accumulatedDiscountedReward:', 46.736685532098647)
('number of approximation units:', 6440, 'number of samples:', 13211)
('episode:', 323, 'number of steps:', 80, 'accumulatedReward:', 78.147195163344321, 'accumulatedDiscountedReward:', 39.61963729891837)
('number of approximation units:', 6452, 'number of samples:', 13254)
('episode:', 324, 'number of steps:', 109, 'accumulatedReward:', 107.35837581116212, 'accumulatedDiscountedReward:', 44.21208968697114)
('number of approximation units:', 6467, 'number of samples:', 13295)
('episode:', 325, 'number of steps:', 136, 'accumulatedReward:', 134.31316727970594, 'accumulatedDiscountedReward:', 46.611813609192154)
('number of approximation units:', 6482, 'number of samples:', 13338)
('episode:', 326, 'number of steps:', 200, 'accumulatedReward:', 199.51511987948203, 'accumulatedDiscountedReward:', 48.971364111318145)
('number of approximation units:', 6492, 'number of samples:', 13396)
('episode:', 327, 'number of steps:', 200, 'accumulatedReward:', 199.32927566195471, 'accumulatedDiscountedReward:', 48.945617438190745)
('number of approximation units:', 6511, 'number of samples:', 13470)
('episode:', 328, 'number of steps:', 41, 'accumulatedReward:', 39.479722874454303, 'accumulatedDiscountedReward:', 27.455987261487071)
('number of approximation units:', 6516, 'number of samples:', 13487)
('episode:', 329, 'number of steps:', 200, 'accumulatedReward:', 199.43454011718353, 'accumulatedDiscountedReward:', 48.978895555799951)
('number of approximation units:', 6530, 'number of samples:', 13540)
('episode:', 330, 'number of steps:', 160, 'accumulatedReward:', 158.10047643921567, 'accumulatedDiscountedReward:', 47.849520977662777)
('number of approximation units:', 6549, 'number of samples:', 13602)
('episode:', 331, 'number of steps:', 200, 'accumulatedReward:', 199.47461865408371, 'accumulatedDiscountedReward:', 49.00734039628837)
('number of approximation units:', 6573, 'number of samples:', 13652)
('episode:', 332, 'number of steps:', 10, 'accumulatedReward:', 8.6165652083653619, 'accumulatedDiscountedReward:', 7.9741349912151183)
('number of approximation units:', 6578, 'number of samples:', 13662)
('episode:', 333, 'number of steps:', 200, 'accumulatedReward:', 199.48544512290033, 'accumulatedDiscountedReward:', 49.006923990429719)
('number of approximation units:', 6593, 'number of samples:', 13732)
('episode:', 334, 'number of steps:', 88, 'accumulatedReward:', 86.380658490656472, 'accumulatedDiscountedReward:', 41.212615561617362)
('number of approximation units:', 6605, 'number of samples:', 13760)
('episode:', 335, 'number of steps:', 75, 'accumulatedReward:', 73.198512049246304, 'accumulatedDiscountedReward:', 38.553643087781772)
('number of approximation units:', 6616, 'number of samples:', 13788)
('episode:', 336, 'number of steps:', 16, 'accumulatedReward:', 14.57530903185032, 'accumulatedDiscountedReward:', 12.738068372931586)
('number of approximation units:', 6625, 'number of samples:', 13803)
('episode:', 337, 'number of steps:', 200, 'accumulatedReward:', 199.57715040343254, 'accumulatedDiscountedReward:', 49.017648323425)
('number of approximation units:', 6630, 'number of samples:', 13852)
('episode:', 338, 'number of steps:', 43, 'accumulatedReward:', 41.470992780526373, 'accumulatedDiscountedReward:', 28.342022382049329)
('number of approximation units:', 6637, 'number of samples:', 13871)
('episode:', 339, 'number of steps:', 126, 'accumulatedReward:', 124.16290583450234, 'accumulatedDiscountedReward:', 45.862056306924941)
('number of approximation units:', 6649, 'number of samples:', 13910)
('episode:', 340, 'number of steps:', 41, 'accumulatedReward:', 39.42401202690975, 'accumulatedDiscountedReward:', 27.429332946260061)
('number of approximation units:', 6658, 'number of samples:', 13933)
('episode:', 341, 'number of steps:', 13, 'accumulatedReward:', 11.641804728583626, 'accumulatedDiscountedReward:', 10.466137053635634)
('number of approximation units:', 6665, 'number of samples:', 13946)
('episode:', 342, 'number of steps:', 46, 'accumulatedReward:', 44.646857408780399, 'accumulatedDiscountedReward:', 29.698183420021767)
('number of approximation units:', 6677, 'number of samples:', 13971)
('episode:', 343, 'number of steps:', 149, 'accumulatedReward:', 147.00794373527265, 'accumulatedDiscountedReward:', 47.337259945113047)
('number of approximation units:', 6688, 'number of samples:', 14010)
('episode:', 344, 'number of steps:', 74, 'accumulatedReward:', 72.0531002153988, 'accumulatedDiscountedReward:', 38.248710997058517)
('number of approximation units:', 6703, 'number of samples:', 14053)
('episode:', 345, 'number of steps:', 62, 'accumulatedReward:', 60.321297594608396, 'accumulatedDiscountedReward:', 35.173215240310078)
('number of approximation units:', 6713, 'number of samples:', 14078)
('episode:', 346, 'number of steps:', 45, 'accumulatedReward:', 43.447659498506169, 'accumulatedDiscountedReward:', 29.183598037796752)
('number of approximation units:', 6727, 'number of samples:', 14100)
('episode:', 347, 'number of steps:', 200, 'accumulatedReward:', 199.35068032242219, 'accumulatedDiscountedReward:', 48.952829008202166)
('number of approximation units:', 6738, 'number of samples:', 14152)
('episode:', 348, 'number of steps:', 200, 'accumulatedReward:', 199.53612000297076, 'accumulatedDiscountedReward:', 49.016919601046411)
('number of approximation units:', 6752, 'number of samples:', 14197)
('episode:', 349, 'number of steps:', 151, 'accumulatedReward:', 149.19383112123438, 'accumulatedDiscountedReward:', 47.451414613744767)
('number of approximation units:', 6761, 'number of samples:', 14247)
('episode:', 350, 'number of steps:', 200, 'accumulatedReward:', 199.59014519074691, 'accumulatedDiscountedReward:', 49.019550555194655)
('number of approximation units:', 6773, 'number of samples:', 14299)
('episode:', 351, 'number of steps:', 59, 'accumulatedReward:', 57.353916271380726, 'accumulatedDiscountedReward:', 34.236528777765606)
('number of approximation units:', 6784, 'number of samples:', 14322)
('episode:', 352, 'number of steps:', 71, 'accumulatedReward:', 69.133043317093723, 'accumulatedDiscountedReward:', 37.570599084705293)
('number of approximation units:', 6794, 'number of samples:', 14356)
('episode:', 353, 'number of steps:', 200, 'accumulatedReward:', 199.34402875214695, 'accumulatedDiscountedReward:', 48.975235630873883)
('number of approximation units:', 6803, 'number of samples:', 14404)
('episode:', 354, 'number of steps:', 200, 'accumulatedReward:', 199.53278627092993, 'accumulatedDiscountedReward:', 49.002838071596514)
('number of approximation units:', 6817, 'number of samples:', 14460)
('episode:', 355, 'number of steps:', 200, 'accumulatedReward:', 199.37427715028838, 'accumulatedDiscountedReward:', 48.967118362960839)
('number of approximation units:', 6823, 'number of samples:', 14502)
('episode:', 356, 'number of steps:', 200, 'accumulatedReward:', 199.14647825165608, 'accumulatedDiscountedReward:', 49.001766096553595)
('number of approximation units:', 6840, 'number of samples:', 14578)
('episode:', 357, 'number of steps:', 10, 'accumulatedReward:', 8.5205852469767169, 'accumulatedDiscountedReward:', 7.8945080821391471)
('number of approximation units:', 6846, 'number of samples:', 14588)
('episode:', 358, 'number of steps:', 200, 'accumulatedReward:', 199.56917483760995, 'accumulatedDiscountedReward:', 49.021168870725504)
('number of approximation units:', 6861, 'number of samples:', 14631)
('episode:', 359, 'number of steps:', 200, 'accumulatedReward:', 199.44530848854055, 'accumulatedDiscountedReward:', 48.941643864549718)
('number of approximation units:', 6872, 'number of samples:', 14684)
('episode:', 360, 'number of steps:', 200, 'accumulatedReward:', 199.25513504769734, 'accumulatedDiscountedReward:', 48.950891583983378)
('number of approximation units:', 6885, 'number of samples:', 14746)
('episode:', 361, 'number of steps:', 131, 'accumulatedReward:', 129.08876964726892, 'accumulatedDiscountedReward:', 46.218913467550649)
('number of approximation units:', 6892, 'number of samples:', 14783)
('episode:', 362, 'number of steps:', 200, 'accumulatedReward:', 199.47305597043055, 'accumulatedDiscountedReward:', 49.029359369144935)
('number of approximation units:', 6901, 'number of samples:', 14823)
('episode:', 363, 'number of steps:', 200, 'accumulatedReward:', 199.396218459012, 'accumulatedDiscountedReward:', 48.940875770794676)
('number of approximation units:', 6921, 'number of samples:', 14879)
('episode:', 364, 'number of steps:', 200, 'accumulatedReward:', 199.55000359342935, 'accumulatedDiscountedReward:', 49.012501497906555)
('number of approximation units:', 6927, 'number of samples:', 14926)
('episode:', 365, 'number of steps:', 200, 'accumulatedReward:', 199.52753161564641, 'accumulatedDiscountedReward:', 48.974299902424413)
('number of approximation units:', 6930, 'number of samples:', 14955)
('episode:', 366, 'number of steps:', 200, 'accumulatedReward:', 199.52488597139947, 'accumulatedDiscountedReward:', 48.997237716156917)
('number of approximation units:', 6938, 'number of samples:', 14986)
('episode:', 367, 'number of steps:', 99, 'accumulatedReward:', 97.106280490414221, 'accumulatedDiscountedReward:', 42.880634465964491)
('number of approximation units:', 6947, 'number of samples:', 15007)
('episode:', 368, 'number of steps:', 169, 'accumulatedReward:', 167.02431055915739, 'accumulatedDiscountedReward:', 48.168859152328558)
('number of approximation units:', 6969, 'number of samples:', 15078)
('episode:', 369, 'number of steps:', 200, 'accumulatedReward:', 198.90380031324835, 'accumulatedDiscountedReward:', 49.002308534970723)
('number of approximation units:', 6988, 'number of samples:', 15143)
('episode:', 370, 'number of steps:', 82, 'accumulatedReward:', 80.285365128931929, 'accumulatedDiscountedReward:', 40.065430139321585)
('number of approximation units:', 6998, 'number of samples:', 15160)
('episode:', 371, 'number of steps:', 200, 'accumulatedReward:', 199.55200434609259, 'accumulatedDiscountedReward:', 48.994099993911405)
('number of approximation units:', 7014, 'number of samples:', 15213)
('episode:', 372, 'number of steps:', 168, 'accumulatedReward:', 166.2767842111345, 'accumulatedDiscountedReward:', 48.170870507212562)
('number of approximation units:', 7026, 'number of samples:', 15256)
('episode:', 373, 'number of steps:', 11, 'accumulatedReward:', 9.4624582210413699, 'accumulatedDiscountedReward:', 8.6868839863091871)
('number of approximation units:', 7033, 'number of samples:', 15267)
('episode:', 374, 'number of steps:', 200, 'accumulatedReward:', 199.47784686354399, 'accumulatedDiscountedReward:', 49.029620668273218)
('number of approximation units:', 7043, 'number of samples:', 15328)
('episode:', 375, 'number of steps:', 139, 'accumulatedReward:', 136.9670900475582, 'accumulatedDiscountedReward:', 46.760438629308112)
('number of approximation units:', 7057, 'number of samples:', 15361)
('episode:', 376, 'number of steps:', 52, 'accumulatedReward:', 50.337019551260603, 'accumulatedDiscountedReward:', 31.883154135601131)
('number of approximation units:', 7062, 'number of samples:', 15381)
('episode:', 377, 'number of steps:', 60, 'accumulatedReward:', 58.316704012389067, 'accumulatedDiscountedReward:', 34.56656961207733)
('number of approximation units:', 7073, 'number of samples:', 15406)
('episode:', 378, 'number of steps:', 56, 'accumulatedReward:', 54.41747752226177, 'accumulatedDiscountedReward:', 33.285890734213552)
('number of approximation units:', 7087, 'number of samples:', 15435)
('episode:', 379, 'number of steps:', 187, 'accumulatedReward:', 184.84769517314649, 'accumulatedDiscountedReward:', 48.660189269482842)
('number of approximation units:', 7111, 'number of samples:', 15501)
('episode:', 380, 'number of steps:', 200, 'accumulatedReward:', 199.1742408854156, 'accumulatedDiscountedReward:', 48.921654117420644)
('number of approximation units:', 7125, 'number of samples:', 15563)
('episode:', 381, 'number of steps:', 200, 'accumulatedReward:', 199.35033110169405, 'accumulatedDiscountedReward:', 48.966015632513297)
('number of approximation units:', 7139, 'number of samples:', 15619)
('episode:', 382, 'number of steps:', 200, 'accumulatedReward:', 199.51245611138214, 'accumulatedDiscountedReward:', 49.010767414067324)
('number of approximation units:', 7147, 'number of samples:', 15678)
('episode:', 383, 'number of steps:', 102, 'accumulatedReward:', 100.399737080745, 'accumulatedDiscountedReward:', 43.350256747162518)
('number of approximation units:', 7157, 'number of samples:', 15708)
('episode:', 384, 'number of steps:', 200, 'accumulatedReward:', 199.53421162869921, 'accumulatedDiscountedReward:', 48.981077845431145)
('number of approximation units:', 7166, 'number of samples:', 15751)
('episode:', 385, 'number of steps:', 200, 'accumulatedReward:', 199.64432599498031, 'accumulatedDiscountedReward:', 49.047784429936939)
('number of approximation units:', 7182, 'number of samples:', 15810)
('episode:', 386, 'number of steps:', 200, 'accumulatedReward:', 199.2493173169006, 'accumulatedDiscountedReward:', 48.973604677895722)
('number of approximation units:', 7196, 'number of samples:', 15861)
('episode:', 387, 'number of steps:', 200, 'accumulatedReward:', 199.28904510533962, 'accumulatedDiscountedReward:', 48.949267576078348)
('number of approximation units:', 7210, 'number of samples:', 15914)
('episode:', 388, 'number of steps:', 200, 'accumulatedReward:', 199.44174456220554, 'accumulatedDiscountedReward:', 48.982619048601435)
('number of approximation units:', 7218, 'number of samples:', 15954)
('episode:', 389, 'number of steps:', 151, 'accumulatedReward:', 148.89714647948608, 'accumulatedDiscountedReward:', 47.411246952742573)
('number of approximation units:', 7235, 'number of samples:', 16000)
('episode:', 390, 'number of steps:', 200, 'accumulatedReward:', 199.42941954245347, 'accumulatedDiscountedReward:', 48.993072523590541)
('number of approximation units:', 7240, 'number of samples:', 16030)
('episode:', 391, 'number of steps:', 163, 'accumulatedReward:', 161.06608689016119, 'accumulatedDiscountedReward:', 47.964360817717633)
('number of approximation units:', 7252, 'number of samples:', 16071)
('episode:', 392, 'number of steps:', 111, 'accumulatedReward:', 109.03115433473785, 'accumulatedDiscountedReward:', 44.357397392841946)
('number of approximation units:', 7261, 'number of samples:', 16102)
('episode:', 393, 'number of steps:', 174, 'accumulatedReward:', 171.96211251396872, 'accumulatedDiscountedReward:', 48.335339747845623)
('number of approximation units:', 7273, 'number of samples:', 16140)
('episode:', 394, 'number of steps:', 200, 'accumulatedReward:', 199.40313103241218, 'accumulatedDiscountedReward:', 48.991771538036552)
('number of approximation units:', 7289, 'number of samples:', 16190)
('episode:', 395, 'number of steps:', 200, 'accumulatedReward:', 199.53278798426933, 'accumulatedDiscountedReward:', 48.997551768826156)
('number of approximation units:', 7294, 'number of samples:', 16214)
('episode:', 396, 'number of steps:', 200, 'accumulatedReward:', 199.57801060893564, 'accumulatedDiscountedReward:', 49.020443012106114)
('number of approximation units:', 7298, 'number of samples:', 16245)
('episode:', 397, 'number of steps:', 200, 'accumulatedReward:', 199.51368916392414, 'accumulatedDiscountedReward:', 48.996212741695878)
('number of approximation units:', 7308, 'number of samples:', 16278)
('episode:', 398, 'number of steps:', 200, 'accumulatedReward:', 199.53550196288845, 'accumulatedDiscountedReward:', 49.044044909377575)
('number of approximation units:', 7316, 'number of samples:', 16314)
('episode:', 399, 'number of steps:', 121, 'accumulatedReward:', 119.31677725569672, 'accumulatedDiscountedReward:', 45.439891591954563)
('number of approximation units:', 7332, 'number of samples:', 16354)
('episode:', 400, 'number of steps:', 81, 'accumulatedReward:', 79.471841289655572, 'accumulatedDiscountedReward:', 39.912059555883502)
('number of approximation units:', 7338, 'number of samples:', 16370)
('episode:', 401, 'number of steps:', 66, 'accumulatedReward:', 64.475713209165306, 'accumulatedDiscountedReward:', 36.378332459019163)
('number of approximation units:', 7345, 'number of samples:', 16387)
('episode:', 402, 'number of steps:', 78, 'accumulatedReward:', 76.241347615228591, 'accumulatedDiscountedReward:', 39.194199596608271)
('number of approximation units:', 7353, 'number of samples:', 16411)
('episode:', 403, 'number of steps:', 158, 'accumulatedReward:', 156.03046973109318, 'accumulatedDiscountedReward:', 47.765119773189554)
('number of approximation units:', 7369, 'number of samples:', 16448)
('episode:', 404, 'number of steps:', 22, 'accumulatedReward:', 20.420615483530796, 'accumulatedDiscountedReward:', 16.864471043321942)
('number of approximation units:', 7382, 'number of samples:', 16468)
('episode:', 405, 'number of steps:', 200, 'accumulatedReward:', 199.55309498561087, 'accumulatedDiscountedReward:', 48.991640244069728)
('number of approximation units:', 7388, 'number of samples:', 16503)
('episode:', 406, 'number of steps:', 200, 'accumulatedReward:', 199.51618373589727, 'accumulatedDiscountedReward:', 49.035131078383188)
('number of approximation units:', 7396, 'number of samples:', 16545)
('episode:', 407, 'number of steps:', 65, 'accumulatedReward:', 63.520170051552157, 'accumulatedDiscountedReward:', 36.082210614356654)
('number of approximation units:', 7404, 'number of samples:', 16565)
('episode:', 408, 'number of steps:', 43, 'accumulatedReward:', 41.346793933159709, 'accumulatedDiscountedReward:', 28.293023473158289)
('number of approximation units:', 7415, 'number of samples:', 16586)
('episode:', 409, 'number of steps:', 200, 'accumulatedReward:', 199.57903112959045, 'accumulatedDiscountedReward:', 48.9997662791774)
('number of approximation units:', 7423, 'number of samples:', 16624)
('episode:', 410, 'number of steps:', 200, 'accumulatedReward:', 199.47426455595158, 'accumulatedDiscountedReward:', 49.030889177497492)
('number of approximation units:', 7433, 'number of samples:', 16667)
('episode:', 411, 'number of steps:', 200, 'accumulatedReward:', 199.46199485432325, 'accumulatedDiscountedReward:', 49.024184746400238)
('number of approximation units:', 7441, 'number of samples:', 16705)
('episode:', 412, 'number of steps:', 11, 'accumulatedReward:', 9.6079053982915443, 'accumulatedDiscountedReward:', 8.8103873994015984)
('number of approximation units:', 7446, 'number of samples:', 16716)
('episode:', 413, 'number of steps:', 184, 'accumulatedReward:', 182.0905650677164, 'accumulatedDiscountedReward:', 48.646723907714531)
('number of approximation units:', 7464, 'number of samples:', 16753)
('episode:', 414, 'number of steps:', 200, 'accumulatedReward:', 199.46599712204193, 'accumulatedDiscountedReward:', 49.016455022504459)
('number of approximation units:', 7468, 'number of samples:', 16779)
('episode:', 415, 'number of steps:', 86, 'accumulatedReward:', 84.336616810144577, 'accumulatedDiscountedReward:', 40.851885767078826)
('number of approximation units:', 7479, 'number of samples:', 16810)
('episode:', 416, 'number of steps:', 200, 'accumulatedReward:', 199.5200657325903, 'accumulatedDiscountedReward:', 48.985091457975408)
('number of approximation units:', 7486, 'number of samples:', 16850)
('episode:', 417, 'number of steps:', 87, 'accumulatedReward:', 85.340953486475627, 'accumulatedDiscountedReward:', 40.997573484798572)
('number of approximation units:', 7493, 'number of samples:', 16874)
('episode:', 418, 'number of steps:', 43, 'accumulatedReward:', 41.166921526968736, 'accumulatedDiscountedReward:', 28.184401739089552)
('number of approximation units:', 7501, 'number of samples:', 16892)
('episode:', 419, 'number of steps:', 200, 'accumulatedReward:', 199.42435619172863, 'accumulatedDiscountedReward:', 48.98044679707025)
('number of approximation units:', 7515, 'number of samples:', 16932)
('episode:', 420, 'number of steps:', 200, 'accumulatedReward:', 199.49536737603978, 'accumulatedDiscountedReward:', 49.017992002637854)
('number of approximation units:', 7523, 'number of samples:', 16969)
('episode:', 421, 'number of steps:', 110, 'accumulatedReward:', 107.98518052606263, 'accumulatedDiscountedReward:', 44.242813324826628)
('number of approximation units:', 7531, 'number of samples:', 17011)
('episode:', 422, 'number of steps:', 91, 'accumulatedReward:', 89.299804159617665, 'accumulatedDiscountedReward:', 41.724689704052601)
('number of approximation units:', 7542, 'number of samples:', 17039)
('episode:', 423, 'number of steps:', 52, 'accumulatedReward:', 50.322154799102336, 'accumulatedDiscountedReward:', 31.876041622821603)
('number of approximation units:', 7550, 'number of samples:', 17055)
('episode:', 424, 'number of steps:', 19, 'accumulatedReward:', 17.501487572128422, 'accumulatedDiscountedReward:', 14.87136180260061)
('number of approximation units:', 7555, 'number of samples:', 17066)
('episode:', 425, 'number of steps:', 200, 'accumulatedReward:', 199.46752124740942, 'accumulatedDiscountedReward:', 49.018242283978566)
('number of approximation units:', 7563, 'number of samples:', 17097)
('episode:', 426, 'number of steps:', 17, 'accumulatedReward:', 15.463681421017046, 'accumulatedDiscountedReward:', 13.399960720749412)
('number of approximation units:', 7571, 'number of samples:', 17110)
('episode:', 427, 'number of steps:', 107, 'accumulatedReward:', 105.13163900836001, 'accumulatedDiscountedReward:', 43.933763792755563)
('number of approximation units:', 7583, 'number of samples:', 17140)
('episode:', 428, 'number of steps:', 200, 'accumulatedReward:', 199.36506138285159, 'accumulatedDiscountedReward:', 48.959680663560967)
('number of approximation units:', 7592, 'number of samples:', 17179)
('episode:', 429, 'number of steps:', 200, 'accumulatedReward:', 199.5442522769111, 'accumulatedDiscountedReward:', 48.997733575863215)
('number of approximation units:', 7606, 'number of samples:', 17228)
('episode:', 430, 'number of steps:', 13, 'accumulatedReward:', 11.489423330570153, 'accumulatedDiscountedReward:', 10.33787753294463)
('number of approximation units:', 7616, 'number of samples:', 17239)
('episode:', 431, 'number of steps:', 30, 'accumulatedReward:', 28.342610592049617, 'accumulatedDiscountedReward:', 21.776316130469411)
('number of approximation units:', 7621, 'number of samples:', 17251)
('episode:', 432, 'number of steps:', 38, 'accumulatedReward:', 36.570976587550625, 'accumulatedDiscountedReward:', 26.094591951872541)
('number of approximation units:', 7627, 'number of samples:', 17261)
('episode:', 433, 'number of steps:', 200, 'accumulatedReward:', 199.58534237698976, 'accumulatedDiscountedReward:', 49.028785958961329)
('number of approximation units:', 7637, 'number of samples:', 17295)
('episode:', 434, 'number of steps:', 173, 'accumulatedReward:', 170.99460036633968, 'accumulatedDiscountedReward:', 48.334428412851977)
('number of approximation units:', 7644, 'number of samples:', 17334)
('episode:', 435, 'number of steps:', 126, 'accumulatedReward:', 124.11319012788097, 'accumulatedDiscountedReward:', 45.840712368499581)
('number of approximation units:', 7652, 'number of samples:', 17357)
('episode:', 436, 'number of steps:', 200, 'accumulatedReward:', 199.46826096889299, 'accumulatedDiscountedReward:', 48.996866279132938)
('number of approximation units:', 7660, 'number of samples:', 17399)
('episode:', 437, 'number of steps:', 200, 'accumulatedReward:', 199.44274808631405, 'accumulatedDiscountedReward:', 48.990122462098867)
('number of approximation units:', 7665, 'number of samples:', 17418)
('episode:', 438, 'number of steps:', 200, 'accumulatedReward:', 198.92766259099702, 'accumulatedDiscountedReward:', 48.746696082473854)
('number of approximation units:', 7685, 'number of samples:', 17472)
('episode:', 439, 'number of steps:', 183, 'accumulatedReward:', 181.04073002878212, 'accumulatedDiscountedReward:', 48.612685560850984)
('number of approximation units:', 7701, 'number of samples:', 17512)
('episode:', 440, 'number of steps:', 147, 'accumulatedReward:', 145.08493271437123, 'accumulatedDiscountedReward:', 47.227386981104274)
('number of approximation units:', 7708, 'number of samples:', 17533)
('episode:', 441, 'number of steps:', 54, 'accumulatedReward:', 52.413257071548202, 'accumulatedDiscountedReward:', 32.624464863727425)
('number of approximation units:', 7715, 'number of samples:', 17555)
('episode:', 442, 'number of steps:', 200, 'accumulatedReward:', 199.50024052298642, 'accumulatedDiscountedReward:', 49.023839901912808)
('number of approximation units:', 7725, 'number of samples:', 17590)
('episode:', 443, 'number of steps:', 200, 'accumulatedReward:', 199.22272359342972, 'accumulatedDiscountedReward:', 48.937550251615754)
('number of approximation units:', 7739, 'number of samples:', 17624)
('episode:', 444, 'number of steps:', 76, 'accumulatedReward:', 74.274860227806826, 'accumulatedDiscountedReward:', 38.798372845787405)
('number of approximation units:', 7750, 'number of samples:', 17653)
('episode:', 445, 'number of steps:', 200, 'accumulatedReward:', 199.56779232173429, 'accumulatedDiscountedReward:', 49.03428210639855)
('number of approximation units:', 7753, 'number of samples:', 17673)
('episode:', 446, 'number of steps:', 200, 'accumulatedReward:', 199.47168020067218, 'accumulatedDiscountedReward:', 49.019845019999487)
('number of approximation units:', 7759, 'number of samples:', 17698)
('episode:', 447, 'number of steps:', 167, 'accumulatedReward:', 165.05804387830011, 'accumulatedDiscountedReward:', 48.075241605230396)
('number of approximation units:', 7775, 'number of samples:', 17746)
('episode:', 448, 'number of steps:', 200, 'accumulatedReward:', 199.50624311752443, 'accumulatedDiscountedReward:', 48.993511528911974)
('number of approximation units:', 7778, 'number of samples:', 17765)
('episode:', 449, 'number of steps:', 47, 'accumulatedReward:', 45.543731849607262, 'accumulatedDiscountedReward:', 30.052834319708303)
('number of approximation units:', 7783, 'number of samples:', 17785)
('episode:', 450, 'number of steps:', 18, 'accumulatedReward:', 16.46549644130479, 'accumulatedDiscountedReward:', 14.115194705176368)
('number of approximation units:', 7793, 'number of samples:', 17801)
('episode:', 451, 'number of steps:', 200, 'accumulatedReward:', 199.39164746008151, 'accumulatedDiscountedReward:', 48.975680882563779)
('number of approximation units:', 7795, 'number of samples:', 17823)
('episode:', 452, 'number of steps:', 115, 'accumulatedReward:', 113.37396284216513, 'accumulatedDiscountedReward:', 44.866913684335309)
('number of approximation units:', 7801, 'number of samples:', 17849)
('episode:', 453, 'number of steps:', 9, 'accumulatedReward:', 7.596480175974154, 'accumulatedDiscountedReward:', 7.104842384423093)
('number of approximation units:', 7808, 'number of samples:', 17858)
('episode:', 454, 'number of steps:', 175, 'accumulatedReward:', 173.04245139615253, 'accumulatedDiscountedReward:', 48.397910062340394)
('number of approximation units:', 7822, 'number of samples:', 17896)
('episode:', 455, 'number of steps:', 46, 'accumulatedReward:', 44.593430156991133, 'accumulatedDiscountedReward:', 29.667156495698237)
('number of approximation units:', 7828, 'number of samples:', 17907)
('episode:', 456, 'number of steps:', 200, 'accumulatedReward:', 199.38375437643779, 'accumulatedDiscountedReward:', 48.996785390011269)
('number of approximation units:', 7837, 'number of samples:', 17934)
('episode:', 457, 'number of steps:', 200, 'accumulatedReward:', 199.47037387657454, 'accumulatedDiscountedReward:', 49.012381251014773)
('number of approximation units:', 7845, 'number of samples:', 17968)
('episode:', 458, 'number of steps:', 12, 'accumulatedReward:', 10.589265894960088, 'accumulatedDiscountedReward:', 9.6186330081243572)
('number of approximation units:', 7851, 'number of samples:', 17978)
('episode:', 459, 'number of steps:', 11, 'accumulatedReward:', 9.5682057826116704, 'accumulatedDiscountedReward:', 8.7756740280482877)
('number of approximation units:', 7859, 'number of samples:', 17989)
('episode:', 460, 'number of steps:', 200, 'accumulatedReward:', 199.58955882495533, 'accumulatedDiscountedReward:', 49.013274262651741)
('number of approximation units:', 7869, 'number of samples:', 18018)
('episode:', 461, 'number of steps:', 86, 'accumulatedReward:', 84.364103465030581, 'accumulatedDiscountedReward:', 40.838924559044216)
('number of approximation units:', 7883, 'number of samples:', 18050)
('episode:', 462, 'number of steps:', 15, 'accumulatedReward:', 13.429270790331634, 'accumulatedDiscountedReward:', 11.861767477257082)
('number of approximation units:', 7890, 'number of samples:', 18065)
('episode:', 463, 'number of steps:', 142, 'accumulatedReward:', 140.23378808204839, 'accumulatedDiscountedReward:', 46.962674236867336)
('number of approximation units:', 7895, 'number of samples:', 18084)
('episode:', 464, 'number of steps:', 200, 'accumulatedReward:', 199.32512377082585, 'accumulatedDiscountedReward:', 48.987091739188465)
('number of approximation units:', 7910, 'number of samples:', 18123)
('episode:', 465, 'number of steps:', 200, 'accumulatedReward:', 199.517710763747, 'accumulatedDiscountedReward:', 48.953113964232386)
('number of approximation units:', 7919, 'number of samples:', 18152)
('episode:', 466, 'number of steps:', 113, 'accumulatedReward:', 111.14322400070914, 'accumulatedDiscountedReward:', 44.604315903548702)
('number of approximation units:', 7925, 'number of samples:', 18179)
('episode:', 467, 'number of steps:', 31, 'accumulatedReward:', 29.591957389801994, 'accumulatedDiscountedReward:', 22.485254420274504)
('number of approximation units:', 7933, 'number of samples:', 18188)
('episode:', 468, 'number of steps:', 200, 'accumulatedReward:', 199.44358369789637, 'accumulatedDiscountedReward:', 48.991170286949668)
('number of approximation units:', 7940, 'number of samples:', 18217)
('episode:', 469, 'number of steps:', 200, 'accumulatedReward:', 199.50306997200454, 'accumulatedDiscountedReward:', 48.979702984889705)
('number of approximation units:', 7948, 'number of samples:', 18254)
('episode:', 470, 'number of steps:', 34, 'accumulatedReward:', 32.42041574682446, 'accumulatedDiscountedReward:', 24.004023378756742)
('number of approximation units:', 7956, 'number of samples:', 18268)
('episode:', 471, 'number of steps:', 200, 'accumulatedReward:', 199.64068244174581, 'accumulatedDiscountedReward:', 49.054930612911519)
('number of approximation units:', 7963, 'number of samples:', 18298)
('episode:', 472, 'number of steps:', 200, 'accumulatedReward:', 199.55656676957329, 'accumulatedDiscountedReward:', 49.03558863737728)
('number of approximation units:', 7974, 'number of samples:', 18322)
('episode:', 473, 'number of steps:', 200, 'accumulatedReward:', 199.38238563528441, 'accumulatedDiscountedReward:', 49.027994789278303)
('number of approximation units:', 7980, 'number of samples:', 18355)
('episode:', 474, 'number of steps:', 13, 'accumulatedReward:', 11.393534526871795, 'accumulatedDiscountedReward:', 10.257318051522155)
('number of approximation units:', 7986, 'number of samples:', 18365)
('episode:', 475, 'number of steps:', 200, 'accumulatedReward:', 199.24836399465946, 'accumulatedDiscountedReward:', 48.822469975961489)
('number of approximation units:', 8002, 'number of samples:', 18414)
('episode:', 476, 'number of steps:', 176, 'accumulatedReward:', 173.9665688788011, 'accumulatedDiscountedReward:', 48.457241720653393)
('number of approximation units:', 8014, 'number of samples:', 18449)
('episode:', 477, 'number of steps:', 200, 'accumulatedReward:', 199.37288355564999, 'accumulatedDiscountedReward:', 48.998958997013524)
('number of approximation units:', 8020, 'number of samples:', 18468)
('episode:', 478, 'number of steps:', 45, 'accumulatedReward:', 43.589953886342478, 'accumulatedDiscountedReward:', 29.250978487380468)
('number of approximation units:', 8029, 'number of samples:', 18485)
('episode:', 479, 'number of steps:', 89, 'accumulatedReward:', 87.20126259426597, 'accumulatedDiscountedReward:', 41.335229356032393)
('number of approximation units:', 8037, 'number of samples:', 18508)
('episode:', 480, 'number of steps:', 53, 'accumulatedReward:', 51.311047699078273, 'accumulatedDiscountedReward:', 32.225935316376777)
('number of approximation units:', 8042, 'number of samples:', 18522)
('episode:', 481, 'number of steps:', 32, 'accumulatedReward:', 30.46561645839742, 'accumulatedDiscountedReward:', 22.94711878568306)
('number of approximation units:', 8048, 'number of samples:', 18533)
('episode:', 482, 'number of steps:', 123, 'accumulatedReward:', 121.16586891115129, 'accumulatedDiscountedReward:', 45.590223497218183)
('number of approximation units:', 8055, 'number of samples:', 18551)
('episode:', 483, 'number of steps:', 140, 'accumulatedReward:', 138.16535283277724, 'accumulatedDiscountedReward:', 46.827326014616041)
('number of approximation units:', 8062, 'number of samples:', 18572)
('episode:', 484, 'number of steps:', 200, 'accumulatedReward:', 199.43943037948063, 'accumulatedDiscountedReward:', 48.987602340638318)
('number of approximation units:', 8072, 'number of samples:', 18599)
('episode:', 485, 'number of steps:', 66, 'accumulatedReward:', 64.499953344186295, 'accumulatedDiscountedReward:', 36.372200073532944)
('number of approximation units:', 8081, 'number of samples:', 18616)
('episode:', 486, 'number of steps:', 21, 'accumulatedReward:', 19.422584746948282, 'accumulatedDiscountedReward:', 16.206165284107435)
('number of approximation units:', 8088, 'number of samples:', 18631)
('episode:', 487, 'number of steps:', 44, 'accumulatedReward:', 42.507821750666416, 'accumulatedDiscountedReward:', 28.791416699108328)
('number of approximation units:', 8093, 'number of samples:', 18649)
('episode:', 488, 'number of steps:', 9, 'accumulatedReward:', 7.5826253919738118, 'accumulatedDiscountedReward:', 7.0926900903914731)
('number of approximation units:', 8100, 'number of samples:', 18658)
('episode:', 489, 'number of steps:', 200, 'accumulatedReward:', 199.61427761774146, 'accumulatedDiscountedReward:', 49.027151449520673)
('number of approximation units:', 8104, 'number of samples:', 18678)
('episode:', 490, 'number of steps:', 200, 'accumulatedReward:', 199.54177396258518, 'accumulatedDiscountedReward:', 48.986409665352795)
('number of approximation units:', 8106, 'number of samples:', 18696)
('episode:', 491, 'number of steps:', 200, 'accumulatedReward:', 199.51203371306312, 'accumulatedDiscountedReward:', 48.989999688891032)
('number of approximation units:', 8109, 'number of samples:', 18718)
('episode:', 492, 'number of steps:', 200, 'accumulatedReward:', 199.45378273858759, 'accumulatedDiscountedReward:', 49.000994828803947)
('number of approximation units:', 8118, 'number of samples:', 18748)
('episode:', 493, 'number of steps:', 200, 'accumulatedReward:', 199.39703086448668, 'accumulatedDiscountedReward:', 48.984909448789928)
('number of approximation units:', 8122, 'number of samples:', 18773)
('episode:', 494, 'number of steps:', 200, 'accumulatedReward:', 199.48607197821607, 'accumulatedDiscountedReward:', 49.008122017356072)
('number of approximation units:', 8131, 'number of samples:', 18808)
('episode:', 495, 'number of steps:', 200, 'accumulatedReward:', 199.54106707700154, 'accumulatedDiscountedReward:', 49.029061587318488)
('number of approximation units:', 8140, 'number of samples:', 18833)
('episode:', 496, 'number of steps:', 200, 'accumulatedReward:', 199.55483602544746, 'accumulatedDiscountedReward:', 49.031533744323703)
('number of approximation units:', 8141, 'number of samples:', 18844)
('episode:', 497, 'number of steps:', 200, 'accumulatedReward:', 199.51207273944419, 'accumulatedDiscountedReward:', 48.970037394395476)
('number of approximation units:', 8152, 'number of samples:', 18871)
('episode:', 498, 'number of steps:', 161, 'accumulatedReward:', 158.70792430580715, 'accumulatedDiscountedReward:', 47.872211526882289)
('number of approximation units:', 8168, 'number of samples:', 18908)
('episode:', 499, 'number of steps:', 78, 'accumulatedReward:', 76.358530852279102, 'accumulatedDiscountedReward:', 39.255168706964369)
('number of approximation units:', 8176, 'number of samples:', 18934)
('episode:', 500, 'number of steps:', 146, 'accumulatedReward:', 144.02203826570621, 'accumulatedDiscountedReward:', 47.191625036850631)
('number of approximation units:', 8185, 'number of samples:', 18966)
('episode:', 501, 'number of steps:', 70, 'accumulatedReward:', 68.544003719479775, 'accumulatedDiscountedReward:', 37.435690741147852)
('number of approximation units:', 8191, 'number of samples:', 18973)
('episode:', 502, 'number of steps:', 164, 'accumulatedReward:', 161.97865486193621, 'accumulatedDiscountedReward:', 47.966092001020826)
('number of approximation units:', 8205, 'number of samples:', 19008)
('episode:', 503, 'number of steps:', 106, 'accumulatedReward:', 104.40275246970135, 'accumulatedDiscountedReward:', 43.827062135237803)
('number of approximation units:', 8213, 'number of samples:', 19028)
('episode:', 504, 'number of steps:', 200, 'accumulatedReward:', 199.38249038539772, 'accumulatedDiscountedReward:', 48.947048107898034)
('number of approximation units:', 8221, 'number of samples:', 19060)
('episode:', 505, 'number of steps:', 200, 'accumulatedReward:', 199.43290336464915, 'accumulatedDiscountedReward:', 48.978885759319773)
('number of approximation units:', 8224, 'number of samples:', 19082)
('episode:', 506, 'number of steps:', 170, 'accumulatedReward:', 167.91227889779606, 'accumulatedDiscountedReward:', 48.203312019184374)
('number of approximation units:', 8237, 'number of samples:', 19115)
('episode:', 507, 'number of steps:', 88, 'accumulatedReward:', 86.046369254853659, 'accumulatedDiscountedReward:', 41.122814398634311)
('number of approximation units:', 8252, 'number of samples:', 19145)
('episode:', 508, 'number of steps:', 117, 'accumulatedReward:', 115.18763748869797, 'accumulatedDiscountedReward:', 45.011353999748316)
('number of approximation units:', 8264, 'number of samples:', 19181)
('episode:', 509, 'number of steps:', 160, 'accumulatedReward:', 157.85380819620337, 'accumulatedDiscountedReward:', 47.833925417997158)
('number of approximation units:', 8280, 'number of samples:', 19229)
('episode:', 510, 'number of steps:', 27, 'accumulatedReward:', 25.439521144746621, 'accumulatedDiscountedReward:', 20.074651927692692)
('number of approximation units:', 8284, 'number of samples:', 19237)
('episode:', 511, 'number of steps:', 200, 'accumulatedReward:', 199.63111163927866, 'accumulatedDiscountedReward:', 49.017839279014375)
('number of approximation units:', 8285, 'number of samples:', 19256)
('episode:', 512, 'number of steps:', 83, 'accumulatedReward:', 81.40766797658388, 'accumulatedDiscountedReward:', 40.273605191984608)
('number of approximation units:', 8291, 'number of samples:', 19270)
('episode:', 513, 'number of steps:', 200, 'accumulatedReward:', 199.32517629030201, 'accumulatedDiscountedReward:', 48.927978659029392)
('number of approximation units:', 8296, 'number of samples:', 19288)
('episode:', 514, 'number of steps:', 200, 'accumulatedReward:', 199.47425483871959, 'accumulatedDiscountedReward:', 49.012822347588141)
('number of approximation units:', 8301, 'number of samples:', 19305)
('episode:', 515, 'number of steps:', 161, 'accumulatedReward:', 158.90140149710587, 'accumulatedDiscountedReward:', 47.848113825734693)
('number of approximation units:', 8312, 'number of samples:', 19335)
('episode:', 516, 'number of steps:', 200, 'accumulatedReward:', 199.55961462057849, 'accumulatedDiscountedReward:', 49.050990442769695)
('number of approximation units:', 8318, 'number of samples:', 19360)
('episode:', 517, 'number of steps:', 73, 'accumulatedReward:', 71.515509340234971, 'accumulatedDiscountedReward:', 38.168503057425262)
('number of approximation units:', 8324, 'number of samples:', 19377)
('episode:', 518, 'number of steps:', 200, 'accumulatedReward:', 199.40726246896128, 'accumulatedDiscountedReward:', 49.007715621713373)
('number of approximation units:', 8329, 'number of samples:', 19408)
('episode:', 519, 'number of steps:', 40, 'accumulatedReward:', 38.365198865307271, 'accumulatedDiscountedReward:', 26.948708799159508)
('number of approximation units:', 8339, 'number of samples:', 19425)
('episode:', 520, 'number of steps:', 200, 'accumulatedReward:', 199.48879255642549, 'accumulatedDiscountedReward:', 49.006915939508183)
('number of approximation units:', 8343, 'number of samples:', 19448)
('episode:', 521, 'number of steps:', 52, 'accumulatedReward:', 50.275715916926323, 'accumulatedDiscountedReward:', 31.855803003431557)
('number of approximation units:', 8348, 'number of samples:', 19459)
('episode:', 522, 'number of steps:', 200, 'accumulatedReward:', 199.55089035914085, 'accumulatedDiscountedReward:', 49.027811561973323)
('number of approximation units:', 8353, 'number of samples:', 19477)
('episode:', 523, 'number of steps:', 111, 'accumulatedReward:', 109.15806920363617, 'accumulatedDiscountedReward:', 44.388758904557825)
('number of approximation units:', 8361, 'number of samples:', 19503)
('episode:', 524, 'number of steps:', 10, 'accumulatedReward:', 8.4669099160204642, 'accumulatedDiscountedReward:', 7.8454355093903834)
('number of approximation units:', 8369, 'number of samples:', 19513)
('episode:', 525, 'number of steps:', 200, 'accumulatedReward:', 199.44662279386816, 'accumulatedDiscountedReward:', 49.008285893726928)
('number of approximation units:', 8376, 'number of samples:', 19549)
('episode:', 526, 'number of steps:', 200, 'accumulatedReward:', 199.54484459714345, 'accumulatedDiscountedReward:', 49.029676735674798)
('number of approximation units:', 8383, 'number of samples:', 19568)
('episode:', 527, 'number of steps:', 53, 'accumulatedReward:', 51.511022478747613, 'accumulatedDiscountedReward:', 32.312564129709209)
('number of approximation units:', 8387, 'number of samples:', 19581)
('episode:', 528, 'number of steps:', 64, 'accumulatedReward:', 62.289787460289389, 'accumulatedDiscountedReward:', 35.748674515652155)
('number of approximation units:', 8391, 'number of samples:', 19596)
('episode:', 529, 'number of steps:', 38, 'accumulatedReward:', 36.451909498227629, 'accumulatedDiscountedReward:', 26.039107140717153)
('number of approximation units:', 8397, 'number of samples:', 19604)
('episode:', 530, 'number of steps:', 200, 'accumulatedReward:', 199.4690934375092, 'accumulatedDiscountedReward:', 49.029945355217578)
('number of approximation units:', 8400, 'number of samples:', 19619)
('episode:', 531, 'number of steps:', 58, 'accumulatedReward:', 56.448820860663709, 'accumulatedDiscountedReward:', 33.979205804245701)
('number of approximation units:', 8404, 'number of samples:', 19630)
('episode:', 532, 'number of steps:', 49, 'accumulatedReward:', 47.637566627768869, 'accumulatedDiscountedReward:', 30.874025423569154)
('number of approximation units:', 8411, 'number of samples:', 19641)
('episode:', 533, 'number of steps:', 31, 'accumulatedReward:', 29.44922875255779, 'accumulatedDiscountedReward:', 22.399223902487858)
('number of approximation units:', 8424, 'number of samples:', 19661)
('episode:', 534, 'number of steps:', 192, 'accumulatedReward:', 190.12614238906158, 'accumulatedDiscountedReward:', 48.805573162110804)
('number of approximation units:', 8431, 'number of samples:', 19687)
('episode:', 535, 'number of steps:', 117, 'accumulatedReward:', 115.4045736015652, 'accumulatedDiscountedReward:', 45.079327583542614)
('number of approximation units:', 8435, 'number of samples:', 19704)
('episode:', 536, 'number of steps:', 200, 'accumulatedReward:', 199.55600390892141, 'accumulatedDiscountedReward:', 49.020716546406163)
('number of approximation units:', 8442, 'number of samples:', 19734)
('episode:', 537, 'number of steps:', 12, 'accumulatedReward:', 10.653351925538084, 'accumulatedDiscountedReward:', 9.6710514822481048)
('number of approximation units:', 8447, 'number of samples:', 19741)
('episode:', 538, 'number of steps:', 68, 'accumulatedReward:', 66.369329880501709, 'accumulatedDiscountedReward:', 36.855065638897813)
('number of approximation units:', 8453, 'number of samples:', 19759)
('episode:', 539, 'number of steps:', 200, 'accumulatedReward:', 199.51001170345168, 'accumulatedDiscountedReward:', 49.013896236828941)
('number of approximation units:', 8460, 'number of samples:', 19790)
('episode:', 540, 'number of steps:', 200, 'accumulatedReward:', 199.36557059639932, 'accumulatedDiscountedReward:', 48.987381131398699)
('number of approximation units:', 8467, 'number of samples:', 19818)
('episode:', 541, 'number of steps:', 200, 'accumulatedReward:', 199.59599580007193, 'accumulatedDiscountedReward:', 49.011382910672346)
('number of approximation units:', 8477, 'number of samples:', 19848)
('episode:', 542, 'number of steps:', 200, 'accumulatedReward:', 199.52012210285582, 'accumulatedDiscountedReward:', 49.013686799896014)
('number of approximation units:', 8489, 'number of samples:', 19884)
('episode:', 543, 'number of steps:', 13, 'accumulatedReward:', 11.58379703988086, 'accumulatedDiscountedReward:', 10.417128451500263)
('number of approximation units:', 8496, 'number of samples:', 19896)
('episode:', 544, 'number of steps:', 13, 'accumulatedReward:', 11.496828761140536, 'accumulatedDiscountedReward:', 10.347163811033422)
('number of approximation units:', 8503, 'number of samples:', 19907)
('episode:', 545, 'number of steps:', 200, 'accumulatedReward:', 199.51011944702228, 'accumulatedDiscountedReward:', 48.992596138036404)
('number of approximation units:', 8505, 'number of samples:', 19926)
('episode:', 546, 'number of steps:', 200, 'accumulatedReward:', 199.41678527870238, 'accumulatedDiscountedReward:', 48.98746102221731)
('number of approximation units:', 8506, 'number of samples:', 19947)
('episode:', 547, 'number of steps:', 200, 'accumulatedReward:', 199.53726878277561, 'accumulatedDiscountedReward:', 49.002525283929678)
('number of approximation units:', 8510, 'number of samples:', 19969)
('episode:', 548, 'number of steps:', 40, 'accumulatedReward:', 38.629116147841394, 'accumulatedDiscountedReward:', 27.059082374848398)
('number of approximation units:', 8516, 'number of samples:', 19980)
('episode:', 549, 'number of steps:', 32, 'accumulatedReward:', 30.64042686553476, 'accumulatedDiscountedReward:', 23.055712794714889)
('number of approximation units:', 8520, 'number of samples:', 19988)
('episode:', 550, 'number of steps:', 200, 'accumulatedReward:', 199.38337661743049, 'accumulatedDiscountedReward:', 49.020260022589163)
('number of approximation units:', 8527, 'number of samples:', 20013)
('episode:', 551, 'number of steps:', 200, 'accumulatedReward:', 199.44464248475867, 'accumulatedDiscountedReward:', 48.98334510244937)
('number of approximation units:', 8531, 'number of samples:', 20033)
('episode:', 552, 'number of steps:', 200, 'accumulatedReward:', 199.60148762933608, 'accumulatedDiscountedReward:', 49.039015414623066)
('number of approximation units:', 8541, 'number of samples:', 20062)
('episode:', 553, 'number of steps:', 152, 'accumulatedReward:', 150.12556896050592, 'accumulatedDiscountedReward:', 47.506623068241318)
('number of approximation units:', 8551, 'number of samples:', 20083)
('episode:', 554, 'number of steps:', 200, 'accumulatedReward:', 199.45948490952387, 'accumulatedDiscountedReward:', 49.003578166910636)
('number of approximation units:', 8557, 'number of samples:', 20107)
('episode:', 555, 'number of steps:', 74, 'accumulatedReward:', 72.276385008073717, 'accumulatedDiscountedReward:', 38.333863807797783)
('number of approximation units:', 8562, 'number of samples:', 20123)
('episode:', 556, 'number of steps:', 100, 'accumulatedReward:', 98.283721144720502, 'accumulatedDiscountedReward:', 43.069981654281655)
('number of approximation units:', 8572, 'number of samples:', 20144)
('episode:', 557, 'number of steps:', 200, 'accumulatedReward:', 199.5903287129222, 'accumulatedDiscountedReward:', 49.014472309427276)
('number of approximation units:', 8575, 'number of samples:', 20152)
('episode:', 558, 'number of steps:', 200, 'accumulatedReward:', 199.37071277902098, 'accumulatedDiscountedReward:', 48.974934933238316)
('number of approximation units:', 8584, 'number of samples:', 20183)
('episode:', 559, 'number of steps:', 200, 'accumulatedReward:', 199.5437820881827, 'accumulatedDiscountedReward:', 49.021565497843632)
('number of approximation units:', 8587, 'number of samples:', 20201)
('episode:', 560, 'number of steps:', 200, 'accumulatedReward:', 199.49448790995586, 'accumulatedDiscountedReward:', 49.013441855656289)
('number of approximation units:', 8590, 'number of samples:', 20215)
('episode:', 561, 'number of steps:', 200, 'accumulatedReward:', 199.41911005484198, 'accumulatedDiscountedReward:', 49.006320789800007)
('number of approximation units:', 8599, 'number of samples:', 20244)
('episode:', 562, 'number of steps:', 200, 'accumulatedReward:', 199.5379447468633, 'accumulatedDiscountedReward:', 48.989138183062032)
('number of approximation units:', 8601, 'number of samples:', 20256)
('episode:', 563, 'number of steps:', 109, 'accumulatedReward:', 107.03348856272635, 'accumulatedDiscountedReward:', 44.159450876087796)
('number of approximation units:', 8607, 'number of samples:', 20276)
('episode:', 564, 'number of steps:', 200, 'accumulatedReward:', 199.48617568418277, 'accumulatedDiscountedReward:', 48.963860864515254)
('number of approximation units:', 8614, 'number of samples:', 20298)
('episode:', 565, 'number of steps:', 64, 'accumulatedReward:', 62.531119190542704, 'accumulatedDiscountedReward:', 35.825613625015421)
('number of approximation units:', 8621, 'number of samples:', 20312)
('episode:', 566, 'number of steps:', 45, 'accumulatedReward:', 43.320362562935514, 'accumulatedDiscountedReward:', 29.134292217398706)
('number of approximation units:', 8627, 'number of samples:', 20326)
('episode:', 567, 'number of steps:', 200, 'accumulatedReward:', 199.5042669743554, 'accumulatedDiscountedReward:', 49.029682722279233)
('number of approximation units:', 8634, 'number of samples:', 20349)
('episode:', 568, 'number of steps:', 141, 'accumulatedReward:', 139.12039960604119, 'accumulatedDiscountedReward:', 46.91832951062441)
('number of approximation units:', 8642, 'number of samples:', 20369)
('episode:', 569, 'number of steps:', 53, 'accumulatedReward:', 51.475582061253775, 'accumulatedDiscountedReward:', 32.289666681538669)
('number of approximation units:', 8654, 'number of samples:', 20389)
('episode:', 570, 'number of steps:', 174, 'accumulatedReward:', 171.83571263529279, 'accumulatedDiscountedReward:', 48.326160844329031)
('number of approximation units:', 8665, 'number of samples:', 20421)
('episode:', 571, 'number of steps:', 200, 'accumulatedReward:', 199.58978767349404, 'accumulatedDiscountedReward:', 49.019709358717506)
('number of approximation units:', 8670, 'number of samples:', 20434)
('episode:', 572, 'number of steps:', 13, 'accumulatedReward:', 11.451889125454656, 'accumulatedDiscountedReward:', 10.308173789422417)
('number of approximation units:', 8675, 'number of samples:', 20447)
('episode:', 573, 'number of steps:', 200, 'accumulatedReward:', 199.47685435000221, 'accumulatedDiscountedReward:', 49.017824654933122)
('number of approximation units:', 8680, 'number of samples:', 20464)
('episode:', 574, 'number of steps:', 34, 'accumulatedReward:', 32.71586860275081, 'accumulatedDiscountedReward:', 24.174370816956294)
('number of approximation units:', 8688, 'number of samples:', 20475)
('episode:', 575, 'number of steps:', 200, 'accumulatedReward:', 199.70655329776011, 'accumulatedDiscountedReward:', 49.055517800015465)
('number of approximation units:', 8692, 'number of samples:', 20500)
('episode:', 576, 'number of steps:', 77, 'accumulatedReward:', 75.403643155136592, 'accumulatedDiscountedReward:', 39.058654853913495)
('number of approximation units:', 8696, 'number of samples:', 20514)
('episode:', 577, 'number of steps:', 200, 'accumulatedReward:', 199.5103748197497, 'accumulatedDiscountedReward:', 48.98159076455353)
('number of approximation units:', 8699, 'number of samples:', 20529)
('episode:', 578, 'number of steps:', 127, 'accumulatedReward:', 125.26089077259689, 'accumulatedDiscountedReward:', 45.946969807665909)
('number of approximation units:', 8703, 'number of samples:', 20542)
('episode:', 579, 'number of steps:', 155, 'accumulatedReward:', 153.20505428988301, 'accumulatedDiscountedReward:', 47.661682458688652)
('number of approximation units:', 8711, 'number of samples:', 20562)
('episode:', 580, 'number of steps:', 200, 'accumulatedReward:', 199.53869081041651, 'accumulatedDiscountedReward:', 49.028250392067392)
('number of approximation units:', 8712, 'number of samples:', 20572)
('episode:', 581, 'number of steps:', 200, 'accumulatedReward:', 199.59166096404854, 'accumulatedDiscountedReward:', 49.041198976241525)
('number of approximation units:', 8718, 'number of samples:', 20592)
('episode:', 582, 'number of steps:', 200, 'accumulatedReward:', 199.48978559101019, 'accumulatedDiscountedReward:', 49.016161061184256)
('number of approximation units:', 8722, 'number of samples:', 20619)
('episode:', 583, 'number of steps:', 17, 'accumulatedReward:', 15.675237014551838, 'accumulatedDiscountedReward:', 13.561472222019093)
('number of approximation units:', 8729, 'number of samples:', 20628)
('episode:', 584, 'number of steps:', 200, 'accumulatedReward:', 199.47583167585961, 'accumulatedDiscountedReward:', 48.980224958673787)
('number of approximation units:', 8737, 'number of samples:', 20653)
('episode:', 585, 'number of steps:', 200, 'accumulatedReward:', 199.63369925564194, 'accumulatedDiscountedReward:', 49.016082298753645)
('number of approximation units:', 8742, 'number of samples:', 20672)
('episode:', 586, 'number of steps:', 115, 'accumulatedReward:', 113.24770861896771, 'accumulatedDiscountedReward:', 44.855528893793014)
('number of approximation units:', 8751, 'number of samples:', 20693)
('episode:', 587, 'number of steps:', 200, 'accumulatedReward:', 199.52390693866698, 'accumulatedDiscountedReward:', 49.014476793220375)
('number of approximation units:', 8752, 'number of samples:', 20698)
('episode:', 588, 'number of steps:', 200, 'accumulatedReward:', 199.43494780381602, 'accumulatedDiscountedReward:', 48.976791229329663)
('number of approximation units:', 8758, 'number of samples:', 20725)
('episode:', 589, 'number of steps:', 157, 'accumulatedReward:', 155.17095411392606, 'accumulatedDiscountedReward:', 47.709441407114987)
('number of approximation units:', 8766, 'number of samples:', 20746)
('episode:', 590, 'number of steps:', 200, 'accumulatedReward:', 199.56987461105436, 'accumulatedDiscountedReward:', 49.004202822331266)
('number of approximation units:', 8776, 'number of samples:', 20775)
('episode:', 591, 'number of steps:', 112, 'accumulatedReward:', 110.2615774056582, 'accumulatedDiscountedReward:', 44.542331080154177)
('number of approximation units:', 8786, 'number of samples:', 20794)
('episode:', 592, 'number of steps:', 123, 'accumulatedReward:', 121.23727048129714, 'accumulatedDiscountedReward:', 45.590903056930237)
('number of approximation units:', 8790, 'number of samples:', 20810)
('episode:', 593, 'number of steps:', 101, 'accumulatedReward:', 99.126660911826178, 'accumulatedDiscountedReward:', 43.197676495611617)
('number of approximation units:', 8803, 'number of samples:', 20832)
('episode:', 594, 'number of steps:', 200, 'accumulatedReward:', 199.59277594991318, 'accumulatedDiscountedReward:', 49.026857271343331)
('number of approximation units:', 8805, 'number of samples:', 20842)
('episode:', 595, 'number of steps:', 200, 'accumulatedReward:', 199.48258361958673, 'accumulatedDiscountedReward:', 49.018167827178679)
('number of approximation units:', 8809, 'number of samples:', 20856)
('episode:', 596, 'number of steps:', 200, 'accumulatedReward:', 199.41306022464681, 'accumulatedDiscountedReward:', 49.027480736085948)
('number of approximation units:', 8819, 'number of samples:', 20881)
('episode:', 597, 'number of steps:', 48, 'accumulatedReward:', 46.501736645063545, 'accumulatedDiscountedReward:', 30.422620342312307)
('number of approximation units:', 8823, 'number of samples:', 20895)
('episode:', 598, 'number of steps:', 86, 'accumulatedReward:', 84.342097834513837, 'accumulatedDiscountedReward:', 40.84238927950868)
('number of approximation units:', 8828, 'number of samples:', 20908)
('episode:', 599, 'number of steps:', 194, 'accumulatedReward:', 192.00477495349455, 'accumulatedDiscountedReward:', 48.889199688525643)
('number of approximation units:', 8834, 'number of samples:', 20931)
('episode:', 600, 'number of steps:', 13, 'accumulatedReward:', 11.556526531593279, 'accumulatedDiscountedReward:', 10.394165607314013)
('number of approximation units:', 8840, 'number of samples:', 20943)
('episode:', 601, 'number of steps:', 34, 'accumulatedReward:', 32.51619623870647, 'accumulatedDiscountedReward:', 24.062819080330765)
('number of approximation units:', 8847, 'number of samples:', 20957)
('episode:', 602, 'number of steps:', 200, 'accumulatedReward:', 199.43480620444592, 'accumulatedDiscountedReward:', 49.001871198569972)
('number of approximation units:', 8851, 'number of samples:', 20978)
('episode:', 603, 'number of steps:', 136, 'accumulatedReward:', 134.34360535475037, 'accumulatedDiscountedReward:', 46.613885012093135)
('number of approximation units:', 8857, 'number of samples:', 20999)
('episode:', 604, 'number of steps:', 200, 'accumulatedReward:', 199.56851749237077, 'accumulatedDiscountedReward:', 49.014592827383701)
('number of approximation units:', 8859, 'number of samples:', 21010)
('episode:', 605, 'number of steps:', 137, 'accumulatedReward:', 135.32496797437142, 'accumulatedDiscountedReward:', 46.648015157894022)
('number of approximation units:', 8872, 'number of samples:', 21043)
('episode:', 606, 'number of steps:', 200, 'accumulatedReward:', 199.61785793752458, 'accumulatedDiscountedReward:', 49.03401246552648)
('number of approximation units:', 8876, 'number of samples:', 21055)
('episode:', 607, 'number of steps:', 12, 'accumulatedReward:', 10.437464322073101, 'accumulatedDiscountedReward:', 9.4887015303482798)
('number of approximation units:', 8880, 'number of samples:', 21064)
('episode:', 608, 'number of steps:', 200, 'accumulatedReward:', 199.54238521937489, 'accumulatedDiscountedReward:', 49.012423931021893)
('number of approximation units:', 8884, 'number of samples:', 21083)
('episode:', 609, 'number of steps:', 102, 'accumulatedReward:', 100.39874486293131, 'accumulatedDiscountedReward:', 43.338759820895604)
('number of approximation units:', 8891, 'number of samples:', 21104)
('episode:', 610, 'number of steps:', 200, 'accumulatedReward:', 199.41075341152046, 'accumulatedDiscountedReward:', 48.973256860121126)
('number of approximation units:', 8892, 'number of samples:', 21124)
('episode:', 611, 'number of steps:', 200, 'accumulatedReward:', 199.46138366902159, 'accumulatedDiscountedReward:', 49.009925326774336)
('number of approximation units:', 8895, 'number of samples:', 21145)
('episode:', 612, 'number of steps:', 161, 'accumulatedReward:', 159.17651489037874, 'accumulatedDiscountedReward:', 47.88740586104079)
('number of approximation units:', 8896, 'number of samples:', 21162)
('episode:', 613, 'number of steps:', 66, 'accumulatedReward:', 64.421405620821218, 'accumulatedDiscountedReward:', 36.354625876059352)
('number of approximation units:', 8904, 'number of samples:', 21178)
('episode:', 614, 'number of steps:', 200, 'accumulatedReward:', 199.49749437421227, 'accumulatedDiscountedReward:', 48.996789928830161)
('number of approximation units:', 8909, 'number of samples:', 21202)
('episode:', 615, 'number of steps:', 154, 'accumulatedReward:', 152.08721960675487, 'accumulatedDiscountedReward:', 47.570346232808078)
('number of approximation units:', 8917, 'number of samples:', 21225)
('episode:', 616, 'number of steps:', 200, 'accumulatedReward:', 199.30769678884278, 'accumulatedDiscountedReward:', 49.007668921892709)
('number of approximation units:', 8922, 'number of samples:', 21244)
('episode:', 617, 'number of steps:', 200, 'accumulatedReward:', 199.38962202034156, 'accumulatedDiscountedReward:', 48.957768576207464)
('number of approximation units:', 8931, 'number of samples:', 21275)
('episode:', 618, 'number of steps:', 200, 'accumulatedReward:', 199.41536517363031, 'accumulatedDiscountedReward:', 49.010106166943018)
('number of approximation units:', 8946, 'number of samples:', 21304)
('episode:', 619, 'number of steps:', 92, 'accumulatedReward:', 90.161228719865235, 'accumulatedDiscountedReward:', 41.845782808212242)
('number of approximation units:', 8952, 'number of samples:', 21325)
('episode:', 620, 'number of steps:', 200, 'accumulatedReward:', 199.56178834774227, 'accumulatedDiscountedReward:', 49.020773283842146)
('number of approximation units:', 8957, 'number of samples:', 21344)
('episode:', 621, 'number of steps:', 200, 'accumulatedReward:', 199.49855773508122, 'accumulatedDiscountedReward:', 49.022464413772674)
('number of approximation units:', 8960, 'number of samples:', 21354)
('episode:', 622, 'number of steps:', 19, 'accumulatedReward:', 17.455017760844452, 'accumulatedDiscountedReward:', 14.826355062904545)
('number of approximation units:', 8967, 'number of samples:', 21370)
('episode:', 623, 'number of steps:', 170, 'accumulatedReward:', 167.89174652838679, 'accumulatedDiscountedReward:', 48.151966502384852)
('number of approximation units:', 8976, 'number of samples:', 21397)
('episode:', 624, 'number of steps:', 200, 'accumulatedReward:', 199.52634973426711, 'accumulatedDiscountedReward:', 49.008138456889874)
('number of approximation units:', 8978, 'number of samples:', 21410)
('episode:', 625, 'number of steps:', 200, 'accumulatedReward:', 199.35387085293112, 'accumulatedDiscountedReward:', 48.945120764690024)
('number of approximation units:', 8980, 'number of samples:', 21428)
('episode:', 626, 'number of steps:', 200, 'accumulatedReward:', 199.5184534767032, 'accumulatedDiscountedReward:', 49.002087480445518)
('number of approximation units:', 8982, 'number of samples:', 21449)
('episode:', 627, 'number of steps:', 59, 'accumulatedReward:', 57.519691099269956, 'accumulatedDiscountedReward:', 34.322391319849523)
('number of approximation units:', 8985, 'number of samples:', 21458)
('episode:', 628, 'number of steps:', 200, 'accumulatedReward:', 199.5406077032201, 'accumulatedDiscountedReward:', 49.02000751681534)
('number of approximation units:', 8989, 'number of samples:', 21468)
('episode:', 629, 'number of steps:', 106, 'accumulatedReward:', 104.22046175688459, 'accumulatedDiscountedReward:', 43.839870532141298)
('number of approximation units:', 8994, 'number of samples:', 21483)
('episode:', 630, 'number of steps:', 200, 'accumulatedReward:', 199.55329440832242, 'accumulatedDiscountedReward:', 49.003452217764739)
('number of approximation units:', 8998, 'number of samples:', 21495)
('episode:', 631, 'number of steps:', 200, 'accumulatedReward:', 199.52097253820614, 'accumulatedDiscountedReward:', 49.008533738652076)
('number of approximation units:', 9000, 'number of samples:', 21505)
('episode:', 632, 'number of steps:', 43, 'accumulatedReward:', 41.342585406216394, 'accumulatedDiscountedReward:', 28.273258549965668)
('number of approximation units:', 9008, 'number of samples:', 21524)
('episode:', 633, 'number of steps:', 122, 'accumulatedReward:', 120.41481403704655, 'accumulatedDiscountedReward:', 45.531710720046476)
('number of approximation units:', 9016, 'number of samples:', 21545)
('episode:', 634, 'number of steps:', 166, 'accumulatedReward:', 163.65965096947608, 'accumulatedDiscountedReward:', 48.034407433665969)
('number of approximation units:', 9024, 'number of samples:', 21566)
('episode:', 635, 'number of steps:', 200, 'accumulatedReward:', 199.48931991135046, 'accumulatedDiscountedReward:', 49.000131551798304)
('number of approximation units:', 9026, 'number of samples:', 21580)
('episode:', 636, 'number of steps:', 200, 'accumulatedReward:', 199.39919432068385, 'accumulatedDiscountedReward:', 48.981536207983218)
('number of approximation units:', 9028, 'number of samples:', 21595)
('episode:', 637, 'number of steps:', 50, 'accumulatedReward:', 48.540957914417675, 'accumulatedDiscountedReward:', 31.21805535317948)
('number of approximation units:', 9033, 'number of samples:', 21607)
('episode:', 638, 'number of steps:', 12, 'accumulatedReward:', 10.557921131779732, 'accumulatedDiscountedReward:', 9.5884706766823395)
('number of approximation units:', 9041, 'number of samples:', 21618)
('episode:', 639, 'number of steps:', 200, 'accumulatedReward:', 199.55580762276895, 'accumulatedDiscountedReward:', 48.99498659863886)
('number of approximation units:', 9046, 'number of samples:', 21638)
('episode:', 640, 'number of steps:', 58, 'accumulatedReward:', 56.326394403061492, 'accumulatedDiscountedReward:', 33.920163876314319)
('number of approximation units:', 9051, 'number of samples:', 21649)
('episode:', 641, 'number of steps:', 134, 'accumulatedReward:', 132.10128638475658, 'accumulatedDiscountedReward:', 46.45923500011817)
('number of approximation units:', 9060, 'number of samples:', 21670)
('episode:', 642, 'number of steps:', 98, 'accumulatedReward:', 96.309743818461328, 'accumulatedDiscountedReward:', 42.779062307927667)
('number of approximation units:', 9064, 'number of samples:', 21684)
('episode:', 643, 'number of steps:', 200, 'accumulatedReward:', 199.54834073503253, 'accumulatedDiscountedReward:', 49.039204182817855)
('number of approximation units:', 9069, 'number of samples:', 21698)
('episode:', 644, 'number of steps:', 200, 'accumulatedReward:', 199.38800398186655, 'accumulatedDiscountedReward:', 48.99819508203182)
('number of approximation units:', 9076, 'number of samples:', 21723)
('episode:', 645, 'number of steps:', 71, 'accumulatedReward:', 69.364334596935223, 'accumulatedDiscountedReward:', 37.636413293825882)
('number of approximation units:', 9080, 'number of samples:', 21736)
('episode:', 646, 'number of steps:', 200, 'accumulatedReward:', 199.64097490719641, 'accumulatedDiscountedReward:', 49.021837909426118)
('number of approximation units:', 9089, 'number of samples:', 21758)
('episode:', 647, 'number of steps:', 38, 'accumulatedReward:', 36.37535135750641, 'accumulatedDiscountedReward:', 25.988042327213762)
('number of approximation units:', 9092, 'number of samples:', 21767)
('episode:', 648, 'number of steps:', 17, 'accumulatedReward:', 15.735225490465044, 'accumulatedDiscountedReward:', 13.608796768286126)
('number of approximation units:', 9097, 'number of samples:', 21774)
('episode:', 649, 'number of steps:', 72, 'accumulatedReward:', 70.378829089569351, 'accumulatedDiscountedReward:', 37.899409541372471)
('number of approximation units:', 9103, 'number of samples:', 21788)
('episode:', 650, 'number of steps:', 111, 'accumulatedReward:', 109.34506553345747, 'accumulatedDiscountedReward:', 44.440493350505619)
('number of approximation units:', 9107, 'number of samples:', 21802)
('episode:', 651, 'number of steps:', 200, 'accumulatedReward:', 199.47540084344953, 'accumulatedDiscountedReward:', 48.975470244143544)
('number of approximation units:', 9110, 'number of samples:', 21811)
('episode:', 652, 'number of steps:', 200, 'accumulatedReward:', 199.51524116872341, 'accumulatedDiscountedReward:', 48.984781405971006)
('number of approximation units:', 9114, 'number of samples:', 21828)
('episode:', 653, 'number of steps:', 200, 'accumulatedReward:', 199.5455512632663, 'accumulatedDiscountedReward:', 49.030816455512053)
('number of approximation units:', 9118, 'number of samples:', 21846)
('episode:', 654, 'number of steps:', 34, 'accumulatedReward:', 32.439924209227883, 'accumulatedDiscountedReward:', 24.013187791624944)
('number of approximation units:', 9126, 'number of samples:', 21860)
('episode:', 655, 'number of steps:', 69, 'accumulatedReward:', 67.493331309690447, 'accumulatedDiscountedReward:', 37.172429757615816)
('number of approximation units:', 9134, 'number of samples:', 21874)
('episode:', 656, 'number of steps:', 57, 'accumulatedReward:', 55.284249166417354, 'accumulatedDiscountedReward:', 33.588568299500118)
('number of approximation units:', 9141, 'number of samples:', 21888)
('episode:', 657, 'number of steps:', 200, 'accumulatedReward:', 199.25120237774908, 'accumulatedDiscountedReward:', 48.983743594421291)
('number of approximation units:', 9150, 'number of samples:', 21904)
('episode:', 658, 'number of steps:', 200, 'accumulatedReward:', 199.50388081656712, 'accumulatedDiscountedReward:', 48.995352607806034)
('number of approximation units:', 9154, 'number of samples:', 21924)
('episode:', 659, 'number of steps:', 200, 'accumulatedReward:', 199.44035636802349, 'accumulatedDiscountedReward:', 49.035727157967088)
('number of approximation units:', 9159, 'number of samples:', 21937)
('episode:', 660, 'number of steps:', 59, 'accumulatedReward:', 57.338969666703612, 'accumulatedDiscountedReward:', 34.244701606308084)
('number of approximation units:', 9165, 'number of samples:', 21953)
('episode:', 661, 'number of steps:', 28, 'accumulatedReward:', 26.492156912195224, 'accumulatedDiscountedReward:', 20.708005159316421)
('number of approximation units:', 9172, 'number of samples:', 21966)
('episode:', 662, 'number of steps:', 200, 'accumulatedReward:', 199.52598305177088, 'accumulatedDiscountedReward:', 49.013817819971919)
('number of approximation units:', 9176, 'number of samples:', 21977)
('episode:', 663, 'number of steps:', 200, 'accumulatedReward:', 199.54654639823448, 'accumulatedDiscountedReward:', 49.023808088461642)
('number of approximation units:', 9180, 'number of samples:', 21999)
('episode:', 664, 'number of steps:', 200, 'accumulatedReward:', 199.56451822285254, 'accumulatedDiscountedReward:', 49.021910789034081)
('number of approximation units:', 9184, 'number of samples:', 22016)
('episode:', 665, 'number of steps:', 143, 'accumulatedReward:', 141.22534131059857, 'accumulatedDiscountedReward:', 47.0275197285521)
('number of approximation units:', 9196, 'number of samples:', 22039)
('episode:', 666, 'number of steps:', 34, 'accumulatedReward:', 32.334011712459734, 'accumulatedDiscountedReward:', 23.959172096384265)
('number of approximation units:', 9202, 'number of samples:', 22048)
('episode:', 667, 'number of steps:', 200, 'accumulatedReward:', 199.45291571810452, 'accumulatedDiscountedReward:', 49.036794462846593)
('number of approximation units:', 9205, 'number of samples:', 22060)
('episode:', 668, 'number of steps:', 200, 'accumulatedReward:', 199.37713246069052, 'accumulatedDiscountedReward:', 49.016191360200779)
('number of approximation units:', 9212, 'number of samples:', 22083)
('episode:', 669, 'number of steps:', 200, 'accumulatedReward:', 199.52710675365049, 'accumulatedDiscountedReward:', 49.007414555440533)
('number of approximation units:', 9214, 'number of samples:', 22091)
('episode:', 670, 'number of steps:', 200, 'accumulatedReward:', 199.45918884268099, 'accumulatedDiscountedReward:', 48.995182735644605)
('number of approximation units:', 9215, 'number of samples:', 22100)
('episode:', 671, 'number of steps:', 41, 'accumulatedReward:', 39.359177837060514, 'accumulatedDiscountedReward:', 27.391256130664967)
('number of approximation units:', 9222, 'number of samples:', 22114)
('episode:', 672, 'number of steps:', 39, 'accumulatedReward:', 37.452910148703232, 'accumulatedDiscountedReward:', 26.51474421124944)
('number of approximation units:', 9229, 'number of samples:', 22124)
('episode:', 673, 'number of steps:', 200, 'accumulatedReward:', 199.36201978236824, 'accumulatedDiscountedReward:', 48.997324891800076)
('number of approximation units:', 9232, 'number of samples:', 22143)
('episode:', 674, 'number of steps:', 200, 'accumulatedReward:', 199.3455667416199, 'accumulatedDiscountedReward:', 48.919601797077796)
('number of approximation units:', 9239, 'number of samples:', 22171)
('episode:', 675, 'number of steps:', 100, 'accumulatedReward:', 98.249403335997101, 'accumulatedDiscountedReward:', 43.046041534908859)
('number of approximation units:', 9243, 'number of samples:', 22192)
('episode:', 676, 'number of steps:', 200, 'accumulatedReward:', 199.43348528839147, 'accumulatedDiscountedReward:', 48.949776843581816)
('number of approximation units:', 9248, 'number of samples:', 22216)
('episode:', 677, 'number of steps:', 200, 'accumulatedReward:', 199.44902309105686, 'accumulatedDiscountedReward:', 48.985767276239564)
('number of approximation units:', 9253, 'number of samples:', 22231)
('episode:', 678, 'number of steps:', 200, 'accumulatedReward:', 199.46959811812528, 'accumulatedDiscountedReward:', 49.00355439754032)
('number of approximation units:', 9255, 'number of samples:', 22244)
('episode:', 679, 'number of steps:', 200, 'accumulatedReward:', 199.07983997225298, 'accumulatedDiscountedReward:', 49.026124201303958)
('number of approximation units:', 9259, 'number of samples:', 22265)
('episode:', 680, 'number of steps:', 75, 'accumulatedReward:', 73.470127736325367, 'accumulatedDiscountedReward:', 38.630146137608747)
('number of approximation units:', 9273, 'number of samples:', 22285)
('episode:', 681, 'number of steps:', 125, 'accumulatedReward:', 123.2208194654753, 'accumulatedDiscountedReward:', 45.755228426220704)
('number of approximation units:', 9277, 'number of samples:', 22300)
('episode:', 682, 'number of steps:', 75, 'accumulatedReward:', 73.119509398531761, 'accumulatedDiscountedReward:', 38.539835259844324)
('number of approximation units:', 9288, 'number of samples:', 22322)
('episode:', 683, 'number of steps:', 200, 'accumulatedReward:', 199.53059749190078, 'accumulatedDiscountedReward:', 49.009906526324457)
('number of approximation units:', 9293, 'number of samples:', 22344)
('episode:', 684, 'number of steps:', 62, 'accumulatedReward:', 60.198489437469547, 'accumulatedDiscountedReward:', 35.11705143677807)
('number of approximation units:', 9296, 'number of samples:', 22361)
('episode:', 685, 'number of steps:', 32, 'accumulatedReward:', 30.250511816553797, 'accumulatedDiscountedReward:', 22.807027384714946)
('number of approximation units:', 9306, 'number of samples:', 22384)
('episode:', 686, 'number of steps:', 200, 'accumulatedReward:', 199.63113217168581, 'accumulatedDiscountedReward:', 49.023463845588878)
('number of approximation units:', 9312, 'number of samples:', 22397)
('episode:', 687, 'number of steps:', 31, 'accumulatedReward:', 29.33205096745165, 'accumulatedDiscountedReward:', 22.316797648219662)
('number of approximation units:', 9321, 'number of samples:', 22414)
('episode:', 688, 'number of steps:', 200, 'accumulatedReward:', 199.52213130982383, 'accumulatedDiscountedReward:', 49.007246775444671)
('number of approximation units:', 9324, 'number of samples:', 22425)
('episode:', 689, 'number of steps:', 57, 'accumulatedReward:', 55.445770612494037, 'accumulatedDiscountedReward:', 33.656799525206011)
('number of approximation units:', 9332, 'number of samples:', 22437)
('episode:', 690, 'number of steps:', 200, 'accumulatedReward:', 199.60589235892672, 'accumulatedDiscountedReward:', 49.024017537361054)
('number of approximation units:', 9333, 'number of samples:', 22443)
('episode:', 691, 'number of steps:', 11, 'accumulatedReward:', 9.7377508570629896, 'accumulatedDiscountedReward:', 8.9231516280303662)
('number of approximation units:', 9342, 'number of samples:', 22453)
('episode:', 692, 'number of steps:', 194, 'accumulatedReward:', 191.80767871157306, 'accumulatedDiscountedReward:', 48.862755413717593)
('number of approximation units:', 9349, 'number of samples:', 22486)
('episode:', 693, 'number of steps:', 140, 'accumulatedReward:', 138.1061250925714, 'accumulatedDiscountedReward:', 46.840532355957251)
('number of approximation units:', 9355, 'number of samples:', 22503)
('episode:', 694, 'number of steps:', 25, 'accumulatedReward:', 23.51970218847049, 'accumulatedDiscountedReward:', 18.893653964497759)
('number of approximation units:', 9363, 'number of samples:', 22516)
('episode:', 695, 'number of steps:', 9, 'accumulatedReward:', 7.6018610177508998, 'accumulatedDiscountedReward:', 7.1096176084505753)
('number of approximation units:', 9368, 'number of samples:', 22525)
('episode:', 696, 'number of steps:', 46, 'accumulatedReward:', 44.454265088342268, 'accumulatedDiscountedReward:', 29.601244212160942)
('number of approximation units:', 9372, 'number of samples:', 22537)
('episode:', 697, 'number of steps:', 200, 'accumulatedReward:', 199.5405751857663, 'accumulatedDiscountedReward:', 48.991320817423116)
('number of approximation units:', 9375, 'number of samples:', 22546)
('episode:', 698, 'number of steps:', 139, 'accumulatedReward:', 137.27984604669106, 'accumulatedDiscountedReward:', 46.815581532417198)
('number of approximation units:', 9387, 'number of samples:', 22578)
('episode:', 699, 'number of steps:', 200, 'accumulatedReward:', 199.58781998616561, 'accumulatedDiscountedReward:', 49.017417041859943)
('number of approximation units:', 9389, 'number of samples:', 22584)
('episode:', 700, 'number of steps:', 125, 'accumulatedReward:', 123.27671462495834, 'accumulatedDiscountedReward:', 45.728666282898736)
('number of approximation units:', 9396, 'number of samples:', 22602)
('episode:', 701, 'number of steps:', 101, 'accumulatedReward:', 99.400394690304552, 'accumulatedDiscountedReward:', 43.23190705236636)
('number of approximation units:', 9407, 'number of samples:', 22618)
('episode:', 702, 'number of steps:', 90, 'accumulatedReward:', 88.391685971561785, 'accumulatedDiscountedReward:', 41.574019664195802)
('number of approximation units:', 9412, 'number of samples:', 22634)
('episode:', 703, 'number of steps:', 110, 'accumulatedReward:', 108.27258165809322, 'accumulatedDiscountedReward:', 44.309306490695441)
('number of approximation units:', 9418, 'number of samples:', 22656)
('episode:', 704, 'number of steps:', 200, 'accumulatedReward:', 199.28706639733625, 'accumulatedDiscountedReward:', 48.895063057215886)
('number of approximation units:', 9420, 'number of samples:', 22673)
('episode:', 705, 'number of steps:', 131, 'accumulatedReward:', 129.14621240336268, 'accumulatedDiscountedReward:', 46.223188188910186)
('number of approximation units:', 9431, 'number of samples:', 22698)
('episode:', 706, 'number of steps:', 200, 'accumulatedReward:', 199.52712635121699, 'accumulatedDiscountedReward:', 48.996431506192799)
('number of approximation units:', 9432, 'number of samples:', 22703)
('episode:', 707, 'number of steps:', 200, 'accumulatedReward:', 199.61822902115142, 'accumulatedDiscountedReward:', 49.013920321792291)
('number of approximation units:', 9434, 'number of samples:', 22714)
('episode:', 708, 'number of steps:', 200, 'accumulatedReward:', 199.54939035714366, 'accumulatedDiscountedReward:', 49.02717896649721)
('number of approximation units:', 9437, 'number of samples:', 22732)
('episode:', 709, 'number of steps:', 200, 'accumulatedReward:', 199.46562458444936, 'accumulatedDiscountedReward:', 49.008648310171466)
('number of approximation units:', 9443, 'number of samples:', 22747)
('episode:', 710, 'number of steps:', 200, 'accumulatedReward:', 199.48398460709686, 'accumulatedDiscountedReward:', 49.015637621268574)
('number of approximation units:', 9449, 'number of samples:', 22774)
('episode:', 711, 'number of steps:', 200, 'accumulatedReward:', 199.44529211446999, 'accumulatedDiscountedReward:', 48.976200822009908)
('number of approximation units:', 9449, 'number of samples:', 22781)
('episode:', 712, 'number of steps:', 19, 'accumulatedReward:', 17.502598524823487, 'accumulatedDiscountedReward:', 14.872540826939288)
('number of approximation units:', 9454, 'number of samples:', 22792)
('episode:', 713, 'number of steps:', 200, 'accumulatedReward:', 199.5160556777372, 'accumulatedDiscountedReward:', 49.029838303162826)
('number of approximation units:', 9458, 'number of samples:', 22806)
('episode:', 714, 'number of steps:', 200, 'accumulatedReward:', 199.5416169413752, 'accumulatedDiscountedReward:', 49.016579660472416)
('number of approximation units:', 9460, 'number of samples:', 22814)
('episode:', 715, 'number of steps:', 200, 'accumulatedReward:', 199.66563739499853, 'accumulatedDiscountedReward:', 49.034838072750887)
('number of approximation units:', 9469, 'number of samples:', 22833)
('episode:', 716, 'number of steps:', 42, 'accumulatedReward:', 40.553957566182383, 'accumulatedDiscountedReward:', 27.930531000905315)
('number of approximation units:', 9474, 'number of samples:', 22844)
('episode:', 717, 'number of steps:', 200, 'accumulatedReward:', 199.41967738056078, 'accumulatedDiscountedReward:', 48.960968059476819)
('number of approximation units:', 9476, 'number of samples:', 22856)
('episode:', 718, 'number of steps:', 168, 'accumulatedReward:', 166.00512163631893, 'accumulatedDiscountedReward:', 48.120539935763816)
('number of approximation units:', 9488, 'number of samples:', 22884)
('episode:', 719, 'number of steps:', 200, 'accumulatedReward:', 199.26817536343361, 'accumulatedDiscountedReward:', 48.950162248098067)
('number of approximation units:', 9493, 'number of samples:', 22904)
('episode:', 720, 'number of steps:', 200, 'accumulatedReward:', 199.4158712096781, 'accumulatedDiscountedReward:', 48.974506187604412)
('number of approximation units:', 9494, 'number of samples:', 22915)
('episode:', 721, 'number of steps:', 200, 'accumulatedReward:', 199.49253093546645, 'accumulatedDiscountedReward:', 48.997135800719995)
('number of approximation units:', 9494, 'number of samples:', 22917)
('episode:', 722, 'number of steps:', 200, 'accumulatedReward:', 199.51072269833219, 'accumulatedDiscountedReward:', 49.015623476621947)
('number of approximation units:', 9498, 'number of samples:', 22937)
('episode:', 723, 'number of steps:', 200, 'accumulatedReward:', 199.37924247440338, 'accumulatedDiscountedReward:', 48.976187236190903)
('number of approximation units:', 9499, 'number of samples:', 22945)
('episode:', 724, 'number of steps:', 200, 'accumulatedReward:', 199.46620517041063, 'accumulatedDiscountedReward:', 49.001110574877892)
('number of approximation units:', 9501, 'number of samples:', 22955)
('episode:', 725, 'number of steps:', 185, 'accumulatedReward:', 183.14265195941289, 'accumulatedDiscountedReward:', 48.662708672693938)
('number of approximation units:', 9508, 'number of samples:', 22972)
('episode:', 726, 'number of steps:', 27, 'accumulatedReward:', 25.604346496987645, 'accumulatedDiscountedReward:', 20.177470185370531)
('number of approximation units:', 9513, 'number of samples:', 22978)
('episode:', 727, 'number of steps:', 200, 'accumulatedReward:', 199.50679095876364, 'accumulatedDiscountedReward:', 48.98554373475779)
('number of approximation units:', 9517, 'number of samples:', 22987)
('episode:', 728, 'number of steps:', 200, 'accumulatedReward:', 199.48189058407016, 'accumulatedDiscountedReward:', 48.975114272946634)
('number of approximation units:', 9521, 'number of samples:', 23000)
('episode:', 729, 'number of steps:', 12, 'accumulatedReward:', 10.388764219359899, 'accumulatedDiscountedReward:', 9.4480035554424333)
('number of approximation units:', 9527, 'number of samples:', 23010)
('episode:', 730, 'number of steps:', 82, 'accumulatedReward:', 80.201114093526144, 'accumulatedDiscountedReward:', 40.058865989178159)
('number of approximation units:', 9534, 'number of samples:', 23026)
('episode:', 731, 'number of steps:', 169, 'accumulatedReward:', 167.19647717035852, 'accumulatedDiscountedReward:', 48.205127981662152)
('number of approximation units:', 9540, 'number of samples:', 23053)
('episode:', 732, 'number of steps:', 69, 'accumulatedReward:', 67.291967789177619, 'accumulatedDiscountedReward:', 37.121595175921676)
('number of approximation units:', 9547, 'number of samples:', 23077)
('episode:', 733, 'number of steps:', 200, 'accumulatedReward:', 199.5585995590086, 'accumulatedDiscountedReward:', 49.021440046092692)
('number of approximation units:', 9547, 'number of samples:', 23086)
('episode:', 734, 'number of steps:', 200, 'accumulatedReward:', 199.31607925307699, 'accumulatedDiscountedReward:', 48.978344128692463)
('number of approximation units:', 9550, 'number of samples:', 23103)
('episode:', 735, 'number of steps:', 35, 'accumulatedReward:', 33.393803430231173, 'accumulatedDiscountedReward:', 24.509901796693025)
('number of approximation units:', 9553, 'number of samples:', 23113)
('episode:', 736, 'number of steps:', 200, 'accumulatedReward:', 199.40403609297104, 'accumulatedDiscountedReward:', 48.985255366594039)
('number of approximation units:', 9555, 'number of samples:', 23125)
('episode:', 737, 'number of steps:', 200, 'accumulatedReward:', 199.58845692566348, 'accumulatedDiscountedReward:', 49.029920611648912)
('number of approximation units:', 9556, 'number of samples:', 23132)
('episode:', 738, 'number of steps:', 200, 'accumulatedReward:', 199.52581759004642, 'accumulatedDiscountedReward:', 48.969465499115088)
('number of approximation units:', 9557, 'number of samples:', 23146)
('episode:', 739, 'number of steps:', 200, 'accumulatedReward:', 199.43598756438121, 'accumulatedDiscountedReward:', 48.98455631517637)
('number of approximation units:', 9562, 'number of samples:', 23163)
('episode:', 740, 'number of steps:', 58, 'accumulatedReward:', 56.25153217731922, 'accumulatedDiscountedReward:', 33.895008461552038)
('number of approximation units:', 9569, 'number of samples:', 23185)
('episode:', 741, 'number of steps:', 200, 'accumulatedReward:', 199.52359280471109, 'accumulatedDiscountedReward:', 49.017921949068104)
('number of approximation units:', 9572, 'number of samples:', 23198)
('episode:', 742, 'number of steps:', 65, 'accumulatedReward:', 63.255214555836432, 'accumulatedDiscountedReward:', 36.021715769171173)
('number of approximation units:', 9576, 'number of samples:', 23211)
('episode:', 743, 'number of steps:', 71, 'accumulatedReward:', 69.383259786264588, 'accumulatedDiscountedReward:', 37.639819863163154)
('number of approximation units:', 9580, 'number of samples:', 23231)
('episode:', 744, 'number of steps:', 161, 'accumulatedReward:', 159.22210084749517, 'accumulatedDiscountedReward:', 47.905294650244876)
('number of approximation units:', 9584, 'number of samples:', 23242)
('episode:', 745, 'number of steps:', 183, 'accumulatedReward:', 181.24449173118012, 'accumulatedDiscountedReward:', 48.630957593068395)
('number of approximation units:', 9589, 'number of samples:', 23256)
('episode:', 746, 'number of steps:', 200, 'accumulatedReward:', 199.54256326312262, 'accumulatedDiscountedReward:', 49.007112388499245)
('number of approximation units:', 9593, 'number of samples:', 23264)
('episode:', 747, 'number of steps:', 181, 'accumulatedReward:', 178.82942213154794, 'accumulatedDiscountedReward:', 48.507919617485854)
('number of approximation units:', 9602, 'number of samples:', 23298)
('episode:', 748, 'number of steps:', 200, 'accumulatedReward:', 199.3137623484395, 'accumulatedDiscountedReward:', 48.954982440895812)
('number of approximation units:', 9608, 'number of samples:', 23327)
('episode:', 749, 'number of steps:', 177, 'accumulatedReward:', 175.22385612187776, 'accumulatedDiscountedReward:', 48.467872409602961)
('number of approximation units:', 9612, 'number of samples:', 23338)
('episode:', 750, 'number of steps:', 168, 'accumulatedReward:', 166.0002510690241, 'accumulatedDiscountedReward:', 48.169833834662896)
('number of approximation units:', 9623, 'number of samples:', 23362)
('episode:', 751, 'number of steps:', 69, 'accumulatedReward:', 67.231925064119835, 'accumulatedDiscountedReward:', 37.066198537070846)
('number of approximation units:', 9628, 'number of samples:', 23375)
('episode:', 752, 'number of steps:', 200, 'accumulatedReward:', 199.36915100466888, 'accumulatedDiscountedReward:', 48.952580413227878)
('number of approximation units:', 9630, 'number of samples:', 23385)
('episode:', 753, 'number of steps:', 140, 'accumulatedReward:', 138.23989651380003, 'accumulatedDiscountedReward:', 46.808373565509477)
('number of approximation units:', 9636, 'number of samples:', 23405)
('episode:', 754, 'number of steps:', 166, 'accumulatedReward:', 163.98537571637658, 'accumulatedDiscountedReward:', 48.03884185242115)
('number of approximation units:', 9644, 'number of samples:', 23431)
('episode:', 755, 'number of steps:', 200, 'accumulatedReward:', 199.56005677861401, 'accumulatedDiscountedReward:', 49.008578481708675)
('number of approximation units:', 9648, 'number of samples:', 23445)
('episode:', 756, 'number of steps:', 200, 'accumulatedReward:', 199.23187971815565, 'accumulatedDiscountedReward:', 48.967229785165124)
('number of approximation units:', 9652, 'number of samples:', 23463)
('episode:', 757, 'number of steps:', 83, 'accumulatedReward:', 81.286380760090154, 'accumulatedDiscountedReward:', 40.212509233071195)
('number of approximation units:', 9657, 'number of samples:', 23477)
('episode:', 758, 'number of steps:', 200, 'accumulatedReward:', 199.55264771454068, 'accumulatedDiscountedReward:', 49.019591740166703)
('number of approximation units:', 9658, 'number of samples:', 23481)
('episode:', 759, 'number of steps:', 200, 'accumulatedReward:', 199.46982471958327, 'accumulatedDiscountedReward:', 49.009675060938754)
('number of approximation units:', 9662, 'number of samples:', 23492)
('episode:', 760, 'number of steps:', 200, 'accumulatedReward:', 199.55000196428992, 'accumulatedDiscountedReward:', 49.012451755964676)
('number of approximation units:', 9663, 'number of samples:', 23505)
('episode:', 761, 'number of steps:', 15, 'accumulatedReward:', 13.409298000591198, 'accumulatedDiscountedReward:', 11.846158601115789)
('number of approximation units:', 9666, 'number of samples:', 23513)
('episode:', 762, 'number of steps:', 200, 'accumulatedReward:', 199.60019125437685, 'accumulatedDiscountedReward:', 48.972372569708433)
('number of approximation units:', 9674, 'number of samples:', 23532)
('episode:', 763, 'number of steps:', 200, 'accumulatedReward:', 199.59222199053204, 'accumulatedDiscountedReward:', 49.042119430646174)
('number of approximation units:', 9679, 'number of samples:', 23547)
('episode:', 764, 'number of steps:', 200, 'accumulatedReward:', 199.53929018701183, 'accumulatedDiscountedReward:', 49.007524962160417)
('number of approximation units:', 9682, 'number of samples:', 23554)
('episode:', 765, 'number of steps:', 11, 'accumulatedReward:', 9.4956082240886133, 'accumulatedDiscountedReward:', 8.7146284068531656)
('number of approximation units:', 9689, 'number of samples:', 23565)
('episode:', 766, 'number of steps:', 200, 'accumulatedReward:', 199.49526212242267, 'accumulatedDiscountedReward:', 49.022385323521455)
('number of approximation units:', 9692, 'number of samples:', 23572)
('episode:', 767, 'number of steps:', 200, 'accumulatedReward:', 199.45534363463997, 'accumulatedDiscountedReward:', 48.961769007554203)
('number of approximation units:', 9695, 'number of samples:', 23586)
('episode:', 768, 'number of steps:', 83, 'accumulatedReward:', 81.142163447516253, 'accumulatedDiscountedReward:', 40.21426823476525)
('number of approximation units:', 9702, 'number of samples:', 23602)
('episode:', 769, 'number of steps:', 200, 'accumulatedReward:', 199.65341189285408, 'accumulatedDiscountedReward:', 49.060798488470503)
('number of approximation units:', 9706, 'number of samples:', 23618)
('episode:', 770, 'number of steps:', 49, 'accumulatedReward:', 47.378874407211505, 'accumulatedDiscountedReward:', 30.766124655624932)
('number of approximation units:', 9716, 'number of samples:', 23628)
('episode:', 771, 'number of steps:', 14, 'accumulatedReward:', 12.614202050243691, 'accumulatedDiscountedReward:', 11.239023503044125)
('number of approximation units:', 9724, 'number of samples:', 23642)
('episode:', 772, 'number of steps:', 200, 'accumulatedReward:', 199.66387215392385, 'accumulatedDiscountedReward:', 49.041400205991224)
('number of approximation units:', 9724, 'number of samples:', 23650)
('episode:', 773, 'number of steps:', 200, 'accumulatedReward:', 199.49685946994782, 'accumulatedDiscountedReward:', 49.004466921540349)
('number of approximation units:', 9728, 'number of samples:', 23668)
('episode:', 774, 'number of steps:', 175, 'accumulatedReward:', 173.04917309656793, 'accumulatedDiscountedReward:', 48.37648256885835)
('number of approximation units:', 9738, 'number of samples:', 23693)
('episode:', 775, 'number of steps:', 200, 'accumulatedReward:', 199.61718355634204, 'accumulatedDiscountedReward:', 49.034310929128793)
('number of approximation units:', 9746, 'number of samples:', 23713)
('episode:', 776, 'number of steps:', 67, 'accumulatedReward:', 65.398852357065763, 'accumulatedDiscountedReward:', 36.626240260007357)
('number of approximation units:', 9754, 'number of samples:', 23734)
('episode:', 777, 'number of steps:', 200, 'accumulatedReward:', 199.55585863771799, 'accumulatedDiscountedReward:', 49.031487364966736)
('number of approximation units:', 9755, 'number of samples:', 23744)
('episode:', 778, 'number of steps:', 200, 'accumulatedReward:', 199.59480779857373, 'accumulatedDiscountedReward:', 49.041367280691894)
('number of approximation units:', 9761, 'number of samples:', 23760)
('episode:', 779, 'number of steps:', 200, 'accumulatedReward:', 199.47580544240185, 'accumulatedDiscountedReward:', 48.972733542504081)
('number of approximation units:', 9761, 'number of samples:', 23766)
('episode:', 780, 'number of steps:', 200, 'accumulatedReward:', 199.51276693826972, 'accumulatedDiscountedReward:', 48.989824544612645)
('number of approximation units:', 9762, 'number of samples:', 23782)
('episode:', 781, 'number of steps:', 200, 'accumulatedReward:', 199.53351209715859, 'accumulatedDiscountedReward:', 49.04275057918273)
('number of approximation units:', 9765, 'number of samples:', 23795)
('episode:', 782, 'number of steps:', 144, 'accumulatedReward:', 142.11758505736478, 'accumulatedDiscountedReward:', 47.08596818682944)
('number of approximation units:', 9768, 'number of samples:', 23807)
('episode:', 783, 'number of steps:', 50, 'accumulatedReward:', 48.401275383386917, 'accumulatedDiscountedReward:', 31.168899413832822)
('number of approximation units:', 9774, 'number of samples:', 23820)
('episode:', 784, 'number of steps:', 200, 'accumulatedReward:', 199.62066342510715, 'accumulatedDiscountedReward:', 49.033076695233852)
('number of approximation units:', 9779, 'number of samples:', 23833)
('episode:', 785, 'number of steps:', 200, 'accumulatedReward:', 199.61498925997051, 'accumulatedDiscountedReward:', 48.997845820206976)
('number of approximation units:', 9783, 'number of samples:', 23847)
('episode:', 786, 'number of steps:', 200, 'accumulatedReward:', 199.47278178650708, 'accumulatedDiscountedReward:', 49.00901584656205)
('number of approximation units:', 9783, 'number of samples:', 23856)
('episode:', 787, 'number of steps:', 200, 'accumulatedReward:', 199.30547456630575, 'accumulatedDiscountedReward:', 48.995787854207435)
('number of approximation units:', 9790, 'number of samples:', 23874)
('episode:', 788, 'number of steps:', 200, 'accumulatedReward:', 199.58985817448416, 'accumulatedDiscountedReward:', 49.022068750249431)
('number of approximation units:', 9792, 'number of samples:', 23883)
('episode:', 789, 'number of steps:', 200, 'accumulatedReward:', 199.39755459989993, 'accumulatedDiscountedReward:', 49.013444859960721)
('number of approximation units:', 9793, 'number of samples:', 23887)
('episode:', 790, 'number of steps:', 200, 'accumulatedReward:', 199.45051811075047, 'accumulatedDiscountedReward:', 49.005938859640274)
('number of approximation units:', 9798, 'number of samples:', 23905)
('episode:', 791, 'number of steps:', 48, 'accumulatedReward:', 46.345466755026926, 'accumulatedDiscountedReward:', 30.367950877470985)
('number of approximation units:', 9805, 'number of samples:', 23915)
('episode:', 792, 'number of steps:', 200, 'accumulatedReward:', 199.58218727286598, 'accumulatedDiscountedReward:', 49.021861086501069)
('number of approximation units:', 9807, 'number of samples:', 23925)
('episode:', 793, 'number of steps:', 200, 'accumulatedReward:', 199.46934904347603, 'accumulatedDiscountedReward:', 49.01128083738282)
('number of approximation units:', 9811, 'number of samples:', 23936)
('episode:', 794, 'number of steps:', 113, 'accumulatedReward:', 111.21514735244601, 'accumulatedDiscountedReward:', 44.636671354385186)
('number of approximation units:', 9817, 'number of samples:', 23948)
('episode:', 795, 'number of steps:', 41, 'accumulatedReward:', 39.520322392232771, 'accumulatedDiscountedReward:', 27.464622660382204)
('number of approximation units:', 9821, 'number of samples:', 23958)
('episode:', 796, 'number of steps:', 200, 'accumulatedReward:', 199.50618326961703, 'accumulatedDiscountedReward:', 48.9888666561652)
('number of approximation units:', 9825, 'number of samples:', 23978)
('episode:', 797, 'number of steps:', 200, 'accumulatedReward:', 199.39837942250225, 'accumulatedDiscountedReward:', 48.978486647443034)
('number of approximation units:', 9829, 'number of samples:', 23998)
('episode:', 798, 'number of steps:', 151, 'accumulatedReward:', 149.24256531769419, 'accumulatedDiscountedReward:', 47.414400761240117)
('number of approximation units:', 9833, 'number of samples:', 24006)
('episode:', 799, 'number of steps:', 35, 'accumulatedReward:', 33.499230525383865, 'accumulatedDiscountedReward:', 24.56356968862319)
('number of approximation units:', 9838, 'number of samples:', 24012)
('episode:', 800, 'number of steps:', 200, 'accumulatedReward:', 199.45797880313773, 'accumulatedDiscountedReward:', 48.97495410679489)
('number of approximation units:', 9838, 'number of samples:', 24017)
('episode:', 801, 'number of steps:', 200, 'accumulatedReward:', 199.63742618179847, 'accumulatedDiscountedReward:', 49.053996750631825)
('number of approximation units:', 9841, 'number of samples:', 24030)
('episode:', 802, 'number of steps:', 109, 'accumulatedReward:', 107.02505949249206, 'accumulatedDiscountedReward:', 44.065965194847642)
('number of approximation units:', 9847, 'number of samples:', 24052)
('episode:', 803, 'number of steps:', 200, 'accumulatedReward:', 199.5159034779538, 'accumulatedDiscountedReward:', 49.006568228174821)
('number of approximation units:', 9850, 'number of samples:', 24062)
('episode:', 804, 'number of steps:', 200, 'accumulatedReward:', 199.41290588251655, 'accumulatedDiscountedReward:', 48.994682814874459)
('number of approximation units:', 9853, 'number of samples:', 24073)
('episode:', 805, 'number of steps:', 200, 'accumulatedReward:', 199.60558227482565, 'accumulatedDiscountedReward:', 49.019095781911055)
('number of approximation units:', 9861, 'number of samples:', 24091)
('episode:', 806, 'number of steps:', 200, 'accumulatedReward:', 199.48383597519611, 'accumulatedDiscountedReward:', 49.02054540799719)
('number of approximation units:', 9866, 'number of samples:', 24106)
('episode:', 807, 'number of steps:', 200, 'accumulatedReward:', 199.47922509718185, 'accumulatedDiscountedReward:', 49.014586937072693)
('number of approximation units:', 9867, 'number of samples:', 24113)
('episode:', 808, 'number of steps:', 200, 'accumulatedReward:', 199.56945617432797, 'accumulatedDiscountedReward:', 49.027191234679307)
('number of approximation units:', 9871, 'number of samples:', 24121)
('episode:', 809, 'number of steps:', 200, 'accumulatedReward:', 199.46597524590621, 'accumulatedDiscountedReward:', 48.961818450397359)
('number of approximation units:', 9874, 'number of samples:', 24129)
('episode:', 810, 'number of steps:', 200, 'accumulatedReward:', 199.63308825104798, 'accumulatedDiscountedReward:', 49.02620136249368)
('number of approximation units:', 9876, 'number of samples:', 24137)
('episode:', 811, 'number of steps:', 200, 'accumulatedReward:', 199.50443084772161, 'accumulatedDiscountedReward:', 49.003518749853491)
('number of approximation units:', 9879, 'number of samples:', 24142)
('episode:', 812, 'number of steps:', 101, 'accumulatedReward:', 99.413349603556924, 'accumulatedDiscountedReward:', 43.246844100559841)
('number of approximation units:', 9887, 'number of samples:', 24155)
('episode:', 813, 'number of steps:', 27, 'accumulatedReward:', 25.180100956176663, 'accumulatedDiscountedReward:', 19.890356339043599)
('number of approximation units:', 9894, 'number of samples:', 24171)
('episode:', 814, 'number of steps:', 200, 'accumulatedReward:', 199.48907901529464, 'accumulatedDiscountedReward:', 49.003332615900959)
('number of approximation units:', 9896, 'number of samples:', 24184)
('episode:', 815, 'number of steps:', 200, 'accumulatedReward:', 199.59933167685989, 'accumulatedDiscountedReward:', 49.010737390954787)
('number of approximation units:', 9902, 'number of samples:', 24200)
('episode:', 816, 'number of steps:', 147, 'accumulatedReward:', 145.38376169829314, 'accumulatedDiscountedReward:', 47.295271621283327)
('number of approximation units:', 9908, 'number of samples:', 24215)
('episode:', 817, 'number of steps:', 86, 'accumulatedReward:', 84.316294293627379, 'accumulatedDiscountedReward:', 40.850864630550305)
('number of approximation units:', 9912, 'number of samples:', 24228)
('episode:', 818, 'number of steps:', 11, 'accumulatedReward:', 9.5493312330592008, 'accumulatedDiscountedReward:', 8.7595712602891052)
('number of approximation units:', 9916, 'number of samples:', 24238)
('episode:', 819, 'number of steps:', 200, 'accumulatedReward:', 199.53600350183649, 'accumulatedDiscountedReward:', 49.012816333798256)
('number of approximation units:', 9918, 'number of samples:', 24246)
('episode:', 820, 'number of steps:', 174, 'accumulatedReward:', 171.99589418715246, 'accumulatedDiscountedReward:', 48.362330952429822)
('number of approximation units:', 9921, 'number of samples:', 24260)
('episode:', 821, 'number of steps:', 200, 'accumulatedReward:', 199.52125243282234, 'accumulatedDiscountedReward:', 49.014672466151197)
('number of approximation units:', 9925, 'number of samples:', 24278)
('episode:', 822, 'number of steps:', 200, 'accumulatedReward:', 199.38027187397643, 'accumulatedDiscountedReward:', 48.900709716397209)
('number of approximation units:', 9927, 'number of samples:', 24288)
('episode:', 823, 'number of steps:', 200, 'accumulatedReward:', 199.48186550520285, 'accumulatedDiscountedReward:', 49.004600600885482)
('number of approximation units:', 9933, 'number of samples:', 24309)
('episode:', 824, 'number of steps:', 43, 'accumulatedReward:', 41.504195622407124, 'accumulatedDiscountedReward:', 28.355548605778818)
('number of approximation units:', 9938, 'number of samples:', 24319)
('episode:', 825, 'number of steps:', 69, 'accumulatedReward:', 67.531467234860258, 'accumulatedDiscountedReward:', 37.197016802540219)
('number of approximation units:', 9943, 'number of samples:', 24331)
('episode:', 826, 'number of steps:', 138, 'accumulatedReward:', 136.43220843255807, 'accumulatedDiscountedReward:', 46.763876419977848)
('number of approximation units:', 9950, 'number of samples:', 24350)
('episode:', 827, 'number of steps:', 29, 'accumulatedReward:', 27.324765921218667, 'accumulatedDiscountedReward:', 21.179386050218646)
('number of approximation units:', 9954, 'number of samples:', 24361)
('episode:', 828, 'number of steps:', 200, 'accumulatedReward:', 199.42750802761839, 'accumulatedDiscountedReward:', 48.971446965528607)
('number of approximation units:', 9959, 'number of samples:', 24375)
('episode:', 829, 'number of steps:', 56, 'accumulatedReward:', 54.348862946508341, 'accumulatedDiscountedReward:', 33.276757489735161)
('number of approximation units:', 9964, 'number of samples:', 24386)
('episode:', 830, 'number of steps:', 200, 'accumulatedReward:', 199.57065873174977, 'accumulatedDiscountedReward:', 49.03108730964798)
('number of approximation units:', 9964, 'number of samples:', 24393)
('episode:', 831, 'number of steps:', 112, 'accumulatedReward:', 110.05077062099954, 'accumulatedDiscountedReward:', 44.511049951341775)
('number of approximation units:', 9973, 'number of samples:', 24416)
('episode:', 832, 'number of steps:', 200, 'accumulatedReward:', 199.68806846924755, 'accumulatedDiscountedReward:', 49.062057827942581)
('number of approximation units:', 9975, 'number of samples:', 24431)
('episode:', 833, 'number of steps:', 34, 'accumulatedReward:', 32.419146727623115, 'accumulatedDiscountedReward:', 24.003316242523312)
('number of approximation units:', 9981, 'number of samples:', 24440)
('episode:', 834, 'number of steps:', 200, 'accumulatedReward:', 199.51269867597892, 'accumulatedDiscountedReward:', 48.977484364169513)
('number of approximation units:', 9982, 'number of samples:', 24449)
('episode:', 835, 'number of steps:', 28, 'accumulatedReward:', 26.569981663207688, 'accumulatedDiscountedReward:', 20.749120496746208)
('number of approximation units:', 9984, 'number of samples:', 24457)
('episode:', 836, 'number of steps:', 200, 'accumulatedReward:', 199.43233396335802, 'accumulatedDiscountedReward:', 48.997283721009893)
('number of approximation units:', 9986, 'number of samples:', 24465)
('episode:', 837, 'number of steps:', 142, 'accumulatedReward:', 140.17654658817605, 'accumulatedDiscountedReward:', 46.956283271424915)
('number of approximation units:', 9991, 'number of samples:', 24478)
('episode:', 838, 'number of steps:', 200, 'accumulatedReward:', 199.38123340911361, 'accumulatedDiscountedReward:', 48.976890290373909)
('number of approximation units:', 9995, 'number of samples:', 24493)
('episode:', 839, 'number of steps:', 200, 'accumulatedReward:', 199.51747195973633, 'accumulatedDiscountedReward:', 49.012623796095284)
('number of approximation units:', 9999, 'number of samples:', 24505)
('episode:', 840, 'number of steps:', 102, 'accumulatedReward:', 100.31128624578409, 'accumulatedDiscountedReward:', 43.347689677380103)
('number of approximation units:', 10008, 'number of samples:', 24520)
('episode:', 841, 'number of steps:', 89, 'accumulatedReward:', 87.464616421320102, 'accumulatedDiscountedReward:', 41.412013771257499)
('number of approximation units:', 10014, 'number of samples:', 24537)
('episode:', 842, 'number of steps:', 200, 'accumulatedReward:', 199.63996102813417, 'accumulatedDiscountedReward:', 49.044069547065369)
('number of approximation units:', 10014, 'number of samples:', 24542)
('episode:', 843, 'number of steps:', 160, 'accumulatedReward:', 158.08650540795875, 'accumulatedDiscountedReward:', 47.828188217128613)
('number of approximation units:', 10021, 'number of samples:', 24565)
('episode:', 844, 'number of steps:', 200, 'accumulatedReward:', 199.48259372312444, 'accumulatedDiscountedReward:', 48.954438090144968)
('number of approximation units:', 10023, 'number of samples:', 24574)
('episode:', 845, 'number of steps:', 117, 'accumulatedReward:', 115.24503405318953, 'accumulatedDiscountedReward:', 45.039207820487988)
('number of approximation units:', 10027, 'number of samples:', 24584)
('episode:', 846, 'number of steps:', 200, 'accumulatedReward:', 197.9179145277883, 'accumulatedDiscountedReward:', 48.973295214359659)
('number of approximation units:', 10034, 'number of samples:', 24604)
('episode:', 847, 'number of steps:', 38, 'accumulatedReward:', 36.673996182349988, 'accumulatedDiscountedReward:', 26.146568485730164)
('number of approximation units:', 10041, 'number of samples:', 24615)
('episode:', 848, 'number of steps:', 200, 'accumulatedReward:', 199.45802899482942, 'accumulatedDiscountedReward:', 48.996025628011729)
('number of approximation units:', 10044, 'number of samples:', 24631)
('episode:', 849, 'number of steps:', 200, 'accumulatedReward:', 199.54557187306634, 'accumulatedDiscountedReward:', 49.015594692648911)
('number of approximation units:', 10048, 'number of samples:', 24637)
('episode:', 850, 'number of steps:', 136, 'accumulatedReward:', 134.31534941104997, 'accumulatedDiscountedReward:', 46.594029134467675)
('number of approximation units:', 10053, 'number of samples:', 24648)
('episode:', 851, 'number of steps:', 200, 'accumulatedReward:', 199.57025540764698, 'accumulatedDiscountedReward:', 48.998049192907025)
('number of approximation units:', 10053, 'number of samples:', 24660)
('episode:', 852, 'number of steps:', 11, 'accumulatedReward:', 9.5539459729684744, 'accumulatedDiscountedReward:', 8.7642897039885135)
('number of approximation units:', 10061, 'number of samples:', 24671)
('episode:', 853, 'number of steps:', 200, 'accumulatedReward:', 199.38546844536248, 'accumulatedDiscountedReward:', 48.972148464329706)
('number of approximation units:', 10068, 'number of samples:', 24685)
('episode:', 854, 'number of steps:', 15, 'accumulatedReward:', 13.509177950350848, 'accumulatedDiscountedReward:', 11.923115758304972)
('number of approximation units:', 10074, 'number of samples:', 24698)
('episode:', 855, 'number of steps:', 109, 'accumulatedReward:', 107.11311044172405, 'accumulatedDiscountedReward:', 44.179286456695515)
('number of approximation units:', 10081, 'number of samples:', 24712)
('episode:', 856, 'number of steps:', 16, 'accumulatedReward:', 14.377695990935017, 'accumulatedDiscountedReward:', 12.578498962027869)
('number of approximation units:', 10088, 'number of samples:', 24728)
('episode:', 857, 'number of steps:', 200, 'accumulatedReward:', 199.40647013127548, 'accumulatedDiscountedReward:', 48.993405262650001)
('number of approximation units:', 10091, 'number of samples:', 24739)
('episode:', 858, 'number of steps:', 175, 'accumulatedReward:', 172.99895710242686, 'accumulatedDiscountedReward:', 48.368027160346855)
('number of approximation units:', 10101, 'number of samples:', 24759)
('episode:', 859, 'number of steps:', 200, 'accumulatedReward:', 199.47281695030784, 'accumulatedDiscountedReward:', 49.034317235967947)
('number of approximation units:', 10103, 'number of samples:', 24772)
('episode:', 860, 'number of steps:', 200, 'accumulatedReward:', 199.42229183564561, 'accumulatedDiscountedReward:', 48.994731177271241)
('number of approximation units:', 10110, 'number of samples:', 24793)
('episode:', 861, 'number of steps:', 142, 'accumulatedReward:', 140.07415311179707, 'accumulatedDiscountedReward:', 46.956908694724994)
('number of approximation units:', 10113, 'number of samples:', 24807)
('episode:', 862, 'number of steps:', 200, 'accumulatedReward:', 199.46268121667944, 'accumulatedDiscountedReward:', 48.999002196417734)
('number of approximation units:', 10117, 'number of samples:', 24820)
('episode:', 863, 'number of steps:', 200, 'accumulatedReward:', 199.52655768930757, 'accumulatedDiscountedReward:', 49.011914010646855)
('number of approximation units:', 10121, 'number of samples:', 24833)
('episode:', 864, 'number of steps:', 146, 'accumulatedReward:', 144.2391041795874, 'accumulatedDiscountedReward:', 47.209130055963051)
('number of approximation units:', 10126, 'number of samples:', 24842)
('episode:', 865, 'number of steps:', 200, 'accumulatedReward:', 199.47925985457491, 'accumulatedDiscountedReward:', 49.025363846532727)
('number of approximation units:', 10126, 'number of samples:', 24847)
('episode:', 866, 'number of steps:', 132, 'accumulatedReward:', 130.34041664299886, 'accumulatedDiscountedReward:', 46.343262596241594)
('number of approximation units:', 10130, 'number of samples:', 24862)
('episode:', 867, 'number of steps:', 200, 'accumulatedReward:', 199.45504222767042, 'accumulatedDiscountedReward:', 49.007027505621302)
('number of approximation units:', 10132, 'number of samples:', 24871)
('episode:', 868, 'number of steps:', 200, 'accumulatedReward:', 199.51694771725622, 'accumulatedDiscountedReward:', 49.004036979637462)
('number of approximation units:', 10134, 'number of samples:', 24880)
('episode:', 869, 'number of steps:', 57, 'accumulatedReward:', 55.230726016886244, 'accumulatedDiscountedReward:', 33.56908694277179)
('number of approximation units:', 10139, 'number of samples:', 24895)
('episode:', 870, 'number of steps:', 197, 'accumulatedReward:', 194.972879845542, 'accumulatedDiscountedReward:', 48.925886376693583)
('number of approximation units:', 10144, 'number of samples:', 24924)
('episode:', 871, 'number of steps:', 200, 'accumulatedReward:', 199.60368665248271, 'accumulatedDiscountedReward:', 49.040244648440748)
('number of approximation units:', 10150, 'number of samples:', 24940)
('episode:', 872, 'number of steps:', 200, 'accumulatedReward:', 199.60150949266179, 'accumulatedDiscountedReward:', 49.014964323431464)
('number of approximation units:', 10153, 'number of samples:', 24953)
('episode:', 873, 'number of steps:', 200, 'accumulatedReward:', 199.53370381546421, 'accumulatedDiscountedReward:', 49.007196698380703)
('number of approximation units:', 10157, 'number of samples:', 24963)
('episode:', 874, 'number of steps:', 94, 'accumulatedReward:', 92.316099726730343, 'accumulatedDiscountedReward:', 42.194909268279361)
('number of approximation units:', 10165, 'number of samples:', 24975)
('episode:', 875, 'number of steps:', 200, 'accumulatedReward:', 199.30622177391081, 'accumulatedDiscountedReward:', 48.977847651618447)
('number of approximation units:', 10169, 'number of samples:', 24994)
('episode:', 876, 'number of steps:', 200, 'accumulatedReward:', 199.22408726160759, 'accumulatedDiscountedReward:', 48.896933387881866)
('number of approximation units:', 10178, 'number of samples:', 25020)
('episode:', 877, 'number of steps:', 200, 'accumulatedReward:', 199.42873369982192, 'accumulatedDiscountedReward:', 48.962739709863129)
('number of approximation units:', 10182, 'number of samples:', 25031)
('episode:', 878, 'number of steps:', 200, 'accumulatedReward:', 199.60013532159024, 'accumulatedDiscountedReward:', 49.051802835353421)
('number of approximation units:', 10185, 'number of samples:', 25040)
('episode:', 879, 'number of steps:', 200, 'accumulatedReward:', 199.61308698383795, 'accumulatedDiscountedReward:', 49.054384160186402)
('number of approximation units:', 10186, 'number of samples:', 25048)
('episode:', 880, 'number of steps:', 200, 'accumulatedReward:', 199.49554627132733, 'accumulatedDiscountedReward:', 48.919672158805589)
('number of approximation units:', 10186, 'number of samples:', 25062)
('episode:', 881, 'number of steps:', 200, 'accumulatedReward:', 199.5699542974838, 'accumulatedDiscountedReward:', 49.023879664386548)
('number of approximation units:', 10187, 'number of samples:', 25068)
('episode:', 882, 'number of steps:', 200, 'accumulatedReward:', 199.54415912045221, 'accumulatedDiscountedReward:', 48.997031406293011)
('number of approximation units:', 10192, 'number of samples:', 25080)
('episode:', 883, 'number of steps:', 80, 'accumulatedReward:', 78.330918924666221, 'accumulatedDiscountedReward:', 39.674432528529245)
('number of approximation units:', 10199, 'number of samples:', 25098)
('episode:', 884, 'number of steps:', 200, 'accumulatedReward:', 199.65685428020277, 'accumulatedDiscountedReward:', 49.032997934018006)
('number of approximation units:', 10200, 'number of samples:', 25099)
('episode:', 885, 'number of steps:', 200, 'accumulatedReward:', 199.54956746629998, 'accumulatedDiscountedReward:', 48.998044627460771)
('number of approximation units:', 10200, 'number of samples:', 25103)
('episode:', 886, 'number of steps:', 11, 'accumulatedReward:', 9.5799254858567444, 'accumulatedDiscountedReward:', 8.7844140887794158)
('number of approximation units:', 10205, 'number of samples:', 25114)
('episode:', 887, 'number of steps:', 200, 'accumulatedReward:', 199.62981628679901, 'accumulatedDiscountedReward:', 49.032748711694303)
('number of approximation units:', 10210, 'number of samples:', 25122)
('episode:', 888, 'number of steps:', 154, 'accumulatedReward:', 152.26892773893775, 'accumulatedDiscountedReward:', 47.617901322220838)
('number of approximation units:', 10217, 'number of samples:', 25139)
('episode:', 889, 'number of steps:', 200, 'accumulatedReward:', 199.55728304352724, 'accumulatedDiscountedReward:', 49.021351995476955)
('number of approximation units:', 10218, 'number of samples:', 25145)
('episode:', 890, 'number of steps:', 31, 'accumulatedReward:', 29.474285930311229, 'accumulatedDiscountedReward:', 22.416770136085383)
('number of approximation units:', 10223, 'number of samples:', 25152)
('episode:', 891, 'number of steps:', 200, 'accumulatedReward:', 199.5445001139492, 'accumulatedDiscountedReward:', 49.018066002868949)
('number of approximation units:', 10225, 'number of samples:', 25161)
('episode:', 892, 'number of steps:', 166, 'accumulatedReward:', 164.08365842543611, 'accumulatedDiscountedReward:', 48.062725283868538)
('number of approximation units:', 10231, 'number of samples:', 25176)
('Total Steps: ', 100134)
