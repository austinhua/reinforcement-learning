('dKnown', 0.1, 'epsilonA', 0.001, 'epsilonB', 0.1, 'normOrder', 2, 'regularizer', array([  1.,   1.,  10.,  50.]), 'maxStepsPerEpisode:', 200, 'episodeStepsRemaining:', 200, 'maxNumberOfEpisodes:', 128)
('episode:', 1, 'number of steps:', 6, 'accumulatedReward:', 5.0, 'accumulatedDiscountedReward:', 4.80396016)
('number of approximation units:', 7, 'number of samples:', 6)
('episode:', 2, 'number of steps:', 10, 'accumulatedReward:', 9.0, 'accumulatedDiscountedReward:', 8.312611893492505)
('number of approximation units:', 17, 'number of samples:', 16)
('episode:', 3, 'number of steps:', 6, 'accumulatedReward:', 5.0, 'accumulatedDiscountedReward:', 4.80396016)
('number of approximation units:', 21, 'number of samples:', 22)
('episode:', 4, 'number of steps:', 6, 'accumulatedReward:', 5.0, 'accumulatedDiscountedReward:', 4.80396016)
('number of approximation units:', 26, 'number of samples:', 28)
('episode:', 5, 'number of steps:', 7, 'accumulatedReward:', 6.0, 'accumulatedDiscountedReward:', 5.7078809567999995)
('number of approximation units:', 32, 'number of samples:', 35)
('episode:', 6, 'number of steps:', 9, 'accumulatedReward:', 8.0, 'accumulatedDiscountedReward:', 7.461848870910719)
('number of approximation units:', 41, 'number of samples:', 44)
('episode:', 7, 'number of steps:', 12, 'accumulatedReward:', 11.0, 'accumulatedDiscountedReward:', 9.963432462510202)
('number of approximation units:', 52, 'number of samples:', 56)
('episode:', 8, 'number of steps:', 13, 'accumulatedReward:', 12.0, 'accumulatedDiscountedReward:', 10.764163813259998)
('number of approximation units:', 63, 'number of samples:', 68)
('episode:', 9, 'number of steps:', 12, 'accumulatedReward:', 11.0, 'accumulatedDiscountedReward:', 9.963432462510202)
('number of approximation units:', 73, 'number of samples:', 79)
('episode:', 10, 'number of steps:', 18, 'accumulatedReward:', 17.0, 'accumulatedDiscountedReward:', 14.533911690967702)
('number of approximation units:', 86, 'number of samples:', 97)
('episode:', 11, 'number of steps:', 16, 'accumulatedReward:', 15.0, 'accumulatedDiscountedReward:', 13.071544867729804)
('number of approximation units:', 98, 'number of samples:', 113)
('episode:', 12, 'number of steps:', 18, 'accumulatedReward:', 17.0, 'accumulatedDiscountedReward:', 14.533911690967702)
('number of approximation units:', 111, 'number of samples:', 131)
('episode:', 13, 'number of steps:', 83, 'accumulatedReward:', 82.0, 'accumulatedDiscountedReward:', 40.46088221906037)
('number of approximation units:', 147, 'number of samples:', 212)
('episode:', 14, 'number of steps:', 22, 'accumulatedReward:', 21.0, 'accumulatedDiscountedReward:', 17.287209384000366)
('number of approximation units:', 157, 'number of samples:', 234)
('episode:', 15, 'number of steps:', 11, 'accumulatedReward:', 10.0, 'accumulatedDiscountedReward:', 9.146359655622655)
('number of approximation units:', 163, 'number of samples:', 245)
('episode:', 16, 'number of steps:', 18, 'accumulatedReward:', 17.0, 'accumulatedDiscountedReward:', 14.533911690967702)
('number of approximation units:', 169, 'number of samples:', 262)
('episode:', 17, 'number of steps:', 13, 'accumulatedReward:', 12.0, 'accumulatedDiscountedReward:', 10.764163813259998)
('number of approximation units:', 173, 'number of samples:', 273)
('episode:', 18, 'number of steps:', 24, 'accumulatedReward:', 23.0, 'accumulatedDiscountedReward:', 18.582635892393952)
('number of approximation units:', 183, 'number of samples:', 291)
('episode:', 19, 'number of steps:', 62, 'accumulatedReward:', 61.0, 'accumulatedDiscountedReward:', 35.41989600808607)
('number of approximation units:', 192, 'number of samples:', 323)
('episode:', 20, 'number of steps:', 12, 'accumulatedReward:', 11.0, 'accumulatedDiscountedReward:', 9.963432462510202)
('number of approximation units:', 197, 'number of samples:', 333)
('episode:', 21, 'number of steps:', 11, 'accumulatedReward:', 10.0, 'accumulatedDiscountedReward:', 9.146359655622655)
('number of approximation units:', 200, 'number of samples:', 339)
('episode:', 22, 'number of steps:', 34, 'accumulatedReward:', 33.0, 'accumulatedDiscountedReward:', 24.329726123590248)
('number of approximation units:', 207, 'number of samples:', 366)
('episode:', 23, 'number of steps:', 40, 'accumulatedReward:', 39.0, 'accumulatedDiscountedReward:', 27.26018347189024)
('number of approximation units:', 213, 'number of samples:', 382)
('episode:', 24, 'number of steps:', 146, 'accumulatedReward:', 145.0, 'accumulatedDiscountedReward:', 47.32852582801154)
('number of approximation units:', 232, 'number of samples:', 448)
('episode:', 25, 'number of steps:', 85, 'accumulatedReward:', 84.0, 'accumulatedDiscountedReward:', 40.838631283185585)
('number of approximation units:', 239, 'number of samples:', 470)
('episode:', 26, 'number of steps:', 200, 'accumulatedReward:', 200.0, 'accumulatedDiscountedReward:', 49.120602669713875)
('number of approximation units:', 249, 'number of samples:', 521)
('episode:', 27, 'number of steps:', 23, 'accumulatedReward:', 22.0, 'accumulatedDiscountedReward:', 17.941465196320358)
('number of approximation units:', 256, 'number of samples:', 531)
('episode:', 28, 'number of steps:', 31, 'accumulatedReward:', 30.0, 'accumulatedDiscountedReward:', 22.725784030878135)
('number of approximation units:', 263, 'number of samples:', 546)
('episode:', 29, 'number of steps:', 48, 'accumulatedReward:', 47.0, 'accumulatedDiscountedReward:', 30.65380495759009)
('number of approximation units:', 272, 'number of samples:', 569)
('episode:', 30, 'number of steps:', 55, 'accumulatedReward:', 54.0, 'accumulatedDiscountedReward:', 33.20507411251285)
('number of approximation units:', 279, 'number of samples:', 585)
('episode:', 31, 'number of steps:', 93, 'accumulatedReward:', 92.0, 'accumulatedDiscountedReward:', 42.20584625949675)
('number of approximation units:', 286, 'number of samples:', 610)
('episode:', 32, 'number of steps:', 50, 'accumulatedReward:', 49.0, 'accumulatedDiscountedReward:', 31.419914281269524)
('number of approximation units:', 288, 'number of samples:', 626)
('episode:', 33, 'number of steps:', 19, 'accumulatedReward:', 18.0, 'accumulatedDiscountedReward:', 15.243233457148348)
('number of approximation units:', 291, 'number of samples:', 632)
('episode:', 34, 'number of steps:', 41, 'accumulatedReward:', 40.0, 'accumulatedDiscountedReward:', 27.714979802452437)
('number of approximation units:', 297, 'number of samples:', 645)
('episode:', 35, 'number of steps:', 12, 'accumulatedReward:', 11.0, 'accumulatedDiscountedReward:', 9.963432462510202)
('number of approximation units:', 304, 'number of samples:', 653)
('episode:', 36, 'number of steps:', 104, 'accumulatedReward:', 103.0, 'accumulatedDiscountedReward:', 43.758976747415254)
('number of approximation units:', 310, 'number of samples:', 673)
('episode:', 37, 'number of steps:', 27, 'accumulatedReward:', 26.0, 'accumulatedDiscountedReward:', 20.430228240834047)
('number of approximation units:', 312, 'number of samples:', 678)
('episode:', 38, 'number of steps:', 12, 'accumulatedReward:', 11.0, 'accumulatedDiscountedReward:', 9.963432462510202)
('number of approximation units:', 317, 'number of samples:', 684)
('episode:', 39, 'number of steps:', 84, 'accumulatedReward:', 83.0, 'accumulatedDiscountedReward:', 40.65166457467917)
('number of approximation units:', 322, 'number of samples:', 701)
('episode:', 40, 'number of steps:', 34, 'accumulatedReward:', 33.0, 'accumulatedDiscountedReward:', 24.329726123590248)
('number of approximation units:', 324, 'number of samples:', 714)
('episode:', 41, 'number of steps:', 75, 'accumulatedReward:', 74.0, 'accumulatedDiscountedReward:', 38.78757359247756)
('number of approximation units:', 330, 'number of samples:', 727)
('episode:', 42, 'number of steps:', 86, 'accumulatedReward:', 85.0, 'accumulatedDiscountedReward:', 41.021858657521875)
('number of approximation units:', 336, 'number of samples:', 745)
('episode:', 43, 'number of steps:', 27, 'accumulatedReward:', 26.0, 'accumulatedDiscountedReward:', 20.430228240834047)
('number of approximation units:', 342, 'number of samples:', 755)
('episode:', 44, 'number of steps:', 49, 'accumulatedReward:', 48.0, 'accumulatedDiscountedReward:', 31.04072885843829)
('number of approximation units:', 349, 'number of samples:', 765)
('episode:', 45, 'number of steps:', 77, 'accumulatedReward:', 76.0, 'accumulatedDiscountedReward:', 39.231585678215446)
('number of approximation units:', 354, 'number of samples:', 781)
('episode:', 46, 'number of steps:', 200, 'accumulatedReward:', 200.0, 'accumulatedDiscountedReward:', 49.120602669713875)
('number of approximation units:', 358, 'number of samples:', 796)
('episode:', 47, 'number of steps:', 24, 'accumulatedReward:', 23.0, 'accumulatedDiscountedReward:', 18.582635892393952)
('number of approximation units:', 361, 'number of samples:', 805)
('episode:', 48, 'number of steps:', 55, 'accumulatedReward:', 54.0, 'accumulatedDiscountedReward:', 33.20507411251285)
('number of approximation units:', 363, 'number of samples:', 816)
('episode:', 49, 'number of steps:', 12, 'accumulatedReward:', 11.0, 'accumulatedDiscountedReward:', 9.963432462510202)
('number of approximation units:', 367, 'number of samples:', 823)
('episode:', 50, 'number of steps:', 200, 'accumulatedReward:', 200.0, 'accumulatedDiscountedReward:', 49.120602669713875)
('number of approximation units:', 368, 'number of samples:', 833)
('episode:', 51, 'number of steps:', 14, 'accumulatedReward:', 13.0, 'accumulatedDiscountedReward:', 11.548880536994798)
('number of approximation units:', 373, 'number of samples:', 843)
('episode:', 52, 'number of steps:', 70, 'accumulatedReward:', 69.0, 'accumulatedDiscountedReward:', 37.595786658282535)
('number of approximation units:', 377, 'number of samples:', 853)
('episode:', 53, 'number of steps:', 200, 'accumulatedReward:', 200.0, 'accumulatedDiscountedReward:', 49.120602669713875)
('number of approximation units:', 377, 'number of samples:', 856)
('episode:', 54, 'number of steps:', 165, 'accumulatedReward:', 164.0, 'accumulatedDiscountedReward:', 48.180104639227196)
('number of approximation units:', 381, 'number of samples:', 870)
('episode:', 55, 'number of steps:', 105, 'accumulatedReward:', 104.0, 'accumulatedDiscountedReward:', 43.883797212466945)
('number of approximation units:', 383, 'number of samples:', 877)
('episode:', 56, 'number of steps:', 72, 'accumulatedReward:', 71.0, 'accumulatedDiscountedReward:', 38.08699350661454)
('number of approximation units:', 383, 'number of samples:', 883)
('episode:', 57, 'number of steps:', 22, 'accumulatedReward:', 21.0, 'accumulatedDiscountedReward:', 17.287209384000366)
('number of approximation units:', 385, 'number of samples:', 890)
('episode:', 58, 'number of steps:', 25, 'accumulatedReward:', 24.0, 'accumulatedDiscountedReward:', 19.210983174546072)
('number of approximation units:', 387, 'number of samples:', 894)
('episode:', 59, 'number of steps:', 200, 'accumulatedReward:', 200.0, 'accumulatedDiscountedReward:', 49.120602669713875)
('number of approximation units:', 388, 'number of samples:', 895)
('episode:', 60, 'number of steps:', 18, 'accumulatedReward:', 17.0, 'accumulatedDiscountedReward:', 14.533911690967702)
('number of approximation units:', 390, 'number of samples:', 899)
('episode:', 61, 'number of steps:', 176, 'accumulatedReward:', 175.0, 'accumulatedDiscountedReward:', 48.5427527295451)
('number of approximation units:', 392, 'number of samples:', 908)
('episode:', 62, 'number of steps:', 200, 'accumulatedReward:', 200.0, 'accumulatedDiscountedReward:', 49.120602669713875)
('number of approximation units:', 392, 'number of samples:', 911)
('episode:', 63, 'number of steps:', 62, 'accumulatedReward:', 61.0, 'accumulatedDiscountedReward:', 35.41989600808607)
('number of approximation units:', 394, 'number of samples:', 916)
('episode:', 64, 'number of steps:', 82, 'accumulatedReward:', 81.0, 'accumulatedDiscountedReward:', 40.266206345979974)
('number of approximation units:', 400, 'number of samples:', 923)
('episode:', 65, 'number of steps:', 148, 'accumulatedReward:', 147.0, 'accumulatedDiscountedReward:', 47.43431620522229)
('number of approximation units:', 401, 'number of samples:', 928)
('episode:', 66, 'number of steps:', 54, 'accumulatedReward:', 53.0, 'accumulatedDiscountedReward:', 32.86232052297229)
('number of approximation units:', 401, 'number of samples:', 930)
('episode:', 67, 'number of steps:', 66, 'accumulatedReward:', 65.0, 'accumulatedDiscountedReward:', 36.55177630836969)
('number of approximation units:', 401, 'number of samples:', 933)
('episode:', 68, 'number of steps:', 48, 'accumulatedReward:', 47.0, 'accumulatedDiscountedReward:', 30.65380495759009)
('number of approximation units:', 403, 'number of samples:', 942)
('episode:', 69, 'number of steps:', 81, 'accumulatedReward:', 80.0, 'accumulatedDiscountedReward:', 40.06755749589794)
('number of approximation units:', 403, 'number of samples:', 947)
('episode:', 70, 'number of steps:', 43, 'accumulatedReward:', 42.0, 'accumulatedDiscountedReward:', 28.59746660227532)
('number of approximation units:', 406, 'number of samples:', 952)
('episode:', 71, 'number of steps:', 191, 'accumulatedReward:', 190.0, 'accumulatedDiscountedReward:', 48.923722191127645)
('number of approximation units:', 411, 'number of samples:', 970)
('episode:', 72, 'number of steps:', 118, 'accumulatedReward:', 117.0, 'accumulatedDiscountedReward:', 45.29650311913202)
('number of approximation units:', 415, 'number of samples:', 978)
('episode:', 73, 'number of steps:', 31, 'accumulatedReward:', 30.0, 'accumulatedDiscountedReward:', 22.725784030878135)
('number of approximation units:', 417, 'number of samples:', 984)
('episode:', 74, 'number of steps:', 76, 'accumulatedReward:', 75.0, 'accumulatedDiscountedReward:', 39.011822120628004)
('number of approximation units:', 418, 'number of samples:', 988)
('episode:', 75, 'number of steps:', 200, 'accumulatedReward:', 200.0, 'accumulatedDiscountedReward:', 49.120602669713875)
('number of approximation units:', 418, 'number of samples:', 989)
('episode:', 76, 'number of steps:', 51, 'accumulatedReward:', 50.0, 'accumulatedDiscountedReward:', 31.791515995644133)
('number of approximation units:', 422, 'number of samples:', 996)
('episode:', 77, 'number of steps:', 155, 'accumulatedReward:', 154.0, 'accumulatedDiscountedReward:', 47.77266438751612)
('number of approximation units:', 423, 'number of samples:', 1001)
('episode:', 78, 'number of steps:', 102, 'accumulatedReward:', 101.0, 'accumulatedDiscountedReward:', 43.501641761157074)
('number of approximation units:', 428, 'number of samples:', 1009)
('episode:', 79, 'number of steps:', 98, 'accumulatedReward:', 97.0, 'accumulatedDiscountedReward:', 42.9547023405026)
('number of approximation units:', 428, 'number of samples:', 1014)
('episode:', 80, 'number of steps:', 138, 'accumulatedReward:', 137.0, 'accumulatedDiscountedReward:', 46.85990798720729)
('number of approximation units:', 429, 'number of samples:', 1020)
('episode:', 81, 'number of steps:', 122, 'accumulatedReward:', 121.0, 'accumulatedDiscountedReward:', 45.66164423642806)
('number of approximation units:', 430, 'number of samples:', 1023)
('episode:', 82, 'number of steps:', 31, 'accumulatedReward:', 30.0, 'accumulatedDiscountedReward:', 22.725784030878135)
('number of approximation units:', 433, 'number of samples:', 1030)
('episode:', 83, 'number of steps:', 200, 'accumulatedReward:', 200.0, 'accumulatedDiscountedReward:', 49.120602669713875)
('number of approximation units:', 434, 'number of samples:', 1033)
('episode:', 84, 'number of steps:', 200, 'accumulatedReward:', 200.0, 'accumulatedDiscountedReward:', 49.120602669713875)
('number of approximation units:', 435, 'number of samples:', 1035)
('episode:', 85, 'number of steps:', 200, 'accumulatedReward:', 200.0, 'accumulatedDiscountedReward:', 49.120602669713875)
('number of approximation units:', 435, 'number of samples:', 1041)
('episode:', 86, 'number of steps:', 200, 'accumulatedReward:', 200.0, 'accumulatedDiscountedReward:', 49.120602669713875)
('number of approximation units:', 435, 'number of samples:', 1043)
('episode:', 87, 'number of steps:', 169, 'accumulatedReward:', 168.0, 'accumulatedDiscountedReward:', 48.32138646469145)
('number of approximation units:', 436, 'number of samples:', 1046)
('episode:', 88, 'number of steps:', 22, 'accumulatedReward:', 21.0, 'accumulatedDiscountedReward:', 17.287209384000366)
('number of approximation units:', 436, 'number of samples:', 1049)
('episode:', 89, 'number of steps:', 135, 'accumulatedReward:', 134.0, 'accumulatedDiscountedReward:', 46.66370728523755)
('number of approximation units:', 437, 'number of samples:', 1052)
('episode:', 90, 'number of steps:', 60, 'accumulatedReward:', 59.0, 'accumulatedDiscountedReward:', 34.81871720958566)
('number of approximation units:', 438, 'number of samples:', 1056)
('episode:', 91, 'number of steps:', 200, 'accumulatedReward:', 200.0, 'accumulatedDiscountedReward:', 49.120602669713875)
('number of approximation units:', 438, 'number of samples:', 1057)
('episode:', 92, 'number of steps:', 200, 'accumulatedReward:', 200.0, 'accumulatedDiscountedReward:', 49.120602669713875)
('number of approximation units:', 438, 'number of samples:', 1057)
('episode:', 93, 'number of steps:', 26, 'accumulatedReward:', 25.0, 'accumulatedDiscountedReward:', 19.82676351105515)
('number of approximation units:', 438, 'number of samples:', 1059)
('episode:', 94, 'number of steps:', 140, 'accumulatedReward:', 139.0, 'accumulatedDiscountedReward:', 46.98425563091388)
('number of approximation units:', 438, 'number of samples:', 1062)
('episode:', 95, 'number of steps:', 200, 'accumulatedReward:', 200.0, 'accumulatedDiscountedReward:', 49.120602669713875)
('number of approximation units:', 438, 'number of samples:', 1064)
('episode:', 96, 'number of steps:', 33, 'accumulatedReward:', 32.0, 'accumulatedDiscountedReward:', 23.805842983255356)
('number of approximation units:', 439, 'number of samples:', 1067)
('episode:', 97, 'number of steps:', 157, 'accumulatedReward:', 156.0, 'accumulatedDiscountedReward:', 47.86086687777048)
('number of approximation units:', 439, 'number of samples:', 1072)
('episode:', 98, 'number of steps:', 145, 'accumulatedReward:', 144.0, 'accumulatedDiscountedReward:', 47.27400594695055)
('number of approximation units:', 440, 'number of samples:', 1075)
('episode:', 99, 'number of steps:', 41, 'accumulatedReward:', 40.0, 'accumulatedDiscountedReward:', 27.714979802452437)
('number of approximation units:', 442, 'number of samples:', 1081)
('episode:', 100, 'number of steps:', 26, 'accumulatedReward:', 25.0, 'accumulatedDiscountedReward:', 19.82676351105515)
('number of approximation units:', 448, 'number of samples:', 1091)
('episode:', 101, 'number of steps:', 31, 'accumulatedReward:', 30.0, 'accumulatedDiscountedReward:', 22.725784030878135)
('number of approximation units:', 450, 'number of samples:', 1095)
('episode:', 102, 'number of steps:', 105, 'accumulatedReward:', 104.0, 'accumulatedDiscountedReward:', 43.883797212466945)
('number of approximation units:', 451, 'number of samples:', 1100)
('episode:', 103, 'number of steps:', 200, 'accumulatedReward:', 200.0, 'accumulatedDiscountedReward:', 49.120602669713875)
('number of approximation units:', 452, 'number of samples:', 1101)
('episode:', 104, 'number of steps:', 32, 'accumulatedReward:', 31.0, 'accumulatedDiscountedReward:', 23.27126835026057)
('number of approximation units:', 453, 'number of samples:', 1104)
('episode:', 105, 'number of steps:', 13, 'accumulatedReward:', 12.0, 'accumulatedDiscountedReward:', 10.764163813259998)
('number of approximation units:', 457, 'number of samples:', 1112)
('episode:', 106, 'number of steps:', 200, 'accumulatedReward:', 200.0, 'accumulatedDiscountedReward:', 49.120602669713875)
('number of approximation units:', 458, 'number of samples:', 1116)
('episode:', 107, 'number of steps:', 187, 'accumulatedReward:', 186.0, 'accumulatedDiscountedReward:', 48.833136424752176)
('number of approximation units:', 461, 'number of samples:', 1124)
('episode:', 108, 'number of steps:', 40, 'accumulatedReward:', 39.0, 'accumulatedDiscountedReward:', 27.26018347189024)
('number of approximation units:', 462, 'number of samples:', 1127)
('episode:', 109, 'number of steps:', 13, 'accumulatedReward:', 12.0, 'accumulatedDiscountedReward:', 10.764163813259998)
('number of approximation units:', 465, 'number of samples:', 1130)
('episode:', 110, 'number of steps:', 200, 'accumulatedReward:', 200.0, 'accumulatedDiscountedReward:', 49.120602669713875)
('number of approximation units:', 465, 'number of samples:', 1131)
('episode:', 111, 'number of steps:', 58, 'accumulatedReward:', 57.0, 'accumulatedDiscountedReward:', 34.192750114104186)
('number of approximation units:', 465, 'number of samples:', 1133)
('episode:', 112, 'number of steps:', 112, 'accumulatedReward:', 111.0, 'accumulatedDiscountedReward:', 44.69036819362778)
('number of approximation units:', 466, 'number of samples:', 1135)
('episode:', 113, 'number of steps:', 48, 'accumulatedReward:', 47.0, 'accumulatedDiscountedReward:', 30.65380495759009)
('number of approximation units:', 471, 'number of samples:', 1142)
('episode:', 114, 'number of steps:', 56, 'accumulatedReward:', 55.0, 'accumulatedDiscountedReward:', 33.54097263026259)
('number of approximation units:', 472, 'number of samples:', 1145)
('episode:', 115, 'number of steps:', 197, 'accumulatedReward:', 196.0, 'accumulatedDiscountedReward:', 49.04658750331741)
('number of approximation units:', 472, 'number of samples:', 1149)
('episode:', 116, 'number of steps:', 113, 'accumulatedReward:', 112.0, 'accumulatedDiscountedReward:', 44.79656082975523)
('number of approximation units:', 474, 'number of samples:', 1153)
('episode:', 117, 'number of steps:', 110, 'accumulatedReward:', 109.0, 'accumulatedDiscountedReward:', 44.47143710290273)
('number of approximation units:', 475, 'number of samples:', 1157)
('episode:', 118, 'number of steps:', 27, 'accumulatedReward:', 26.0, 'accumulatedDiscountedReward:', 20.430228240834047)
('number of approximation units:', 475, 'number of samples:', 1159)
('episode:', 119, 'number of steps:', 112, 'accumulatedReward:', 111.0, 'accumulatedDiscountedReward:', 44.69036819362778)
('number of approximation units:', 475, 'number of samples:', 1164)
('episode:', 120, 'number of steps:', 98, 'accumulatedReward:', 97.0, 'accumulatedDiscountedReward:', 42.9547023405026)
('number of approximation units:', 477, 'number of samples:', 1167)
('episode:', 121, 'number of steps:', 39, 'accumulatedReward:', 38.0, 'accumulatedDiscountedReward:', 26.79610558356147)
('number of approximation units:', 478, 'number of samples:', 1169)
('episode:', 122, 'number of steps:', 83, 'accumulatedReward:', 82.0, 'accumulatedDiscountedReward:', 40.46088221906037)
('number of approximation units:', 479, 'number of samples:', 1170)
('episode:', 123, 'number of steps:', 61, 'accumulatedReward:', 60.0, 'accumulatedDiscountedReward:', 35.12234286539395)
('number of approximation units:', 479, 'number of samples:', 1174)
('episode:', 124, 'number of steps:', 200, 'accumulatedReward:', 200.0, 'accumulatedDiscountedReward:', 49.120602669713875)
('number of approximation units:', 479, 'number of samples:', 1177)
('episode:', 125, 'number of steps:', 200, 'accumulatedReward:', 200.0, 'accumulatedDiscountedReward:', 49.120602669713875)
('number of approximation units:', 479, 'number of samples:', 1177)
('episode:', 126, 'number of steps:', 109, 'accumulatedReward:', 108.0, 'accumulatedDiscountedReward:', 44.358609288676256)
('number of approximation units:', 479, 'number of samples:', 1179)
('episode:', 127, 'number of steps:', 69, 'accumulatedReward:', 68.0, 'accumulatedDiscountedReward:', 37.34263944722708)
('number of approximation units:', 479, 'number of samples:', 1181)
('episode:', 128, 'number of steps:', 187, 'accumulatedReward:', 186.0, 'accumulatedDiscountedReward:', 48.833136424752176)
('number of approximation units:', 479, 'number of samples:', 1182)
('episode:', 129, 'number of steps:', 200, 'accumulatedReward:', 200.0, 'accumulatedDiscountedReward:', 49.120602669713875)
('number of approximation units:', 480, 'number of samples:', 1188)
('episode:', 130, 'number of steps:', 58, 'accumulatedReward:', 57.0, 'accumulatedDiscountedReward:', 34.192750114104186)
('number of approximation units:', 480, 'number of samples:', 1190)
('episode:', 131, 'number of steps:', 169, 'accumulatedReward:', 168.0, 'accumulatedDiscountedReward:', 48.32138646469145)
('number of approximation units:', 480, 'number of samples:', 1191)
('episode:', 132, 'number of steps:', 85, 'accumulatedReward:', 84.0, 'accumulatedDiscountedReward:', 40.838631283185585)
('number of approximation units:', 480, 'number of samples:', 1194)
('episode:', 133, 'number of steps:', 200, 'accumulatedReward:', 200.0, 'accumulatedDiscountedReward:', 49.120602669713875)
('number of approximation units:', 481, 'number of samples:', 1196)
('episode:', 134, 'number of steps:', 200, 'accumulatedReward:', 200.0, 'accumulatedDiscountedReward:', 49.120602669713875)
('number of approximation units:', 481, 'number of samples:', 1197)
('episode:', 135, 'number of steps:', 200, 'accumulatedReward:', 200.0, 'accumulatedDiscountedReward:', 49.120602669713875)
('number of approximation units:', 481, 'number of samples:', 1200)
('episode:', 136, 'number of steps:', 191, 'accumulatedReward:', 190.0, 'accumulatedDiscountedReward:', 48.923722191127645)
('number of approximation units:', 483, 'number of samples:', 1205)
('episode:', 137, 'number of steps:', 37, 'accumulatedReward:', 36.0, 'accumulatedDiscountedReward:', 25.83934358971415)
('number of approximation units:', 483, 'number of samples:', 1206)
('episode:', 138, 'number of steps:', 31, 'accumulatedReward:', 30.0, 'accumulatedDiscountedReward:', 22.725784030878135)
('number of approximation units:', 483, 'number of samples:', 1208)
('episode:', 139, 'number of steps:', 177, 'accumulatedReward:', 176.0, 'accumulatedDiscountedReward:', 48.571897674954194)
('number of approximation units:', 484, 'number of samples:', 1210)
('episode:', 140, 'number of steps:', 109, 'accumulatedReward:', 108.0, 'accumulatedDiscountedReward:', 44.358609288676256)
('number of approximation units:', 484, 'number of samples:', 1212)
('episode:', 141, 'number of steps:', 41, 'accumulatedReward:', 40.0, 'accumulatedDiscountedReward:', 27.714979802452437)
('number of approximation units:', 486, 'number of samples:', 1215)
('episode:', 142, 'number of steps:', 144, 'accumulatedReward:', 143.0, 'accumulatedDiscountedReward:', 47.21837341525567)
('number of approximation units:', 486, 'number of samples:', 1216)
('episode:', 143, 'number of steps:', 200, 'accumulatedReward:', 200.0, 'accumulatedDiscountedReward:', 49.120602669713875)
('number of approximation units:', 486, 'number of samples:', 1217)
('episode:', 144, 'number of steps:', 124, 'accumulatedReward:', 123.0, 'accumulatedDiscountedReward:', 45.83344312466551)
('number of approximation units:', 487, 'number of samples:', 1221)
('episode:', 145, 'number of steps:', 200, 'accumulatedReward:', 200.0, 'accumulatedDiscountedReward:', 49.120602669713875)
('number of approximation units:', 487, 'number of samples:', 1221)
('episode:', 146, 'number of steps:', 167, 'accumulatedReward:', 166.0, 'accumulatedDiscountedReward:', 48.2521724955138)
('number of approximation units:', 487, 'number of samples:', 1226)
('episode:', 147, 'number of steps:', 200, 'accumulatedReward:', 200.0, 'accumulatedDiscountedReward:', 49.120602669713875)
('number of approximation units:', 487, 'number of samples:', 1227)
('episode:', 148, 'number of steps:', 200, 'accumulatedReward:', 200.0, 'accumulatedDiscountedReward:', 49.120602669713875)
('number of approximation units:', 487, 'number of samples:', 1227)
('episode:', 149, 'number of steps:', 124, 'accumulatedReward:', 123.0, 'accumulatedDiscountedReward:', 45.83344312466551)
('number of approximation units:', 487, 'number of samples:', 1229)
('episode:', 150, 'number of steps:', 200, 'accumulatedReward:', 200.0, 'accumulatedDiscountedReward:', 49.120602669713875)
('number of approximation units:', 487, 'number of samples:', 1229)
('episode:', 151, 'number of steps:', 155, 'accumulatedReward:', 154.0, 'accumulatedDiscountedReward:', 47.77266438751612)
('number of approximation units:', 487, 'number of samples:', 1233)
('episode:', 152, 'number of steps:', 100, 'accumulatedReward:', 99.0, 'accumulatedDiscountedReward:', 43.233696127818696)
('number of approximation units:', 489, 'number of samples:', 1237)
('episode:', 153, 'number of steps:', 122, 'accumulatedReward:', 121.0, 'accumulatedDiscountedReward:', 45.66164423642806)
('number of approximation units:', 489, 'number of samples:', 1238)
('episode:', 154, 'number of steps:', 41, 'accumulatedReward:', 40.0, 'accumulatedDiscountedReward:', 27.714979802452437)
('number of approximation units:', 490, 'number of samples:', 1239)
('episode:', 155, 'number of steps:', 42, 'accumulatedReward:', 41.0, 'accumulatedDiscountedReward:', 28.160680206403388)
('number of approximation units:', 490, 'number of samples:', 1241)
('episode:', 156, 'number of steps:', 107, 'accumulatedReward:', 106.0, 'accumulatedDiscountedReward:', 44.12599884285325)
('number of approximation units:', 494, 'number of samples:', 1246)
('episode:', 157, 'number of steps:', 36, 'accumulatedReward:', 35.0, 'accumulatedDiscountedReward:', 25.346268969096073)
('number of approximation units:', 494, 'number of samples:', 1250)
('episode:', 158, 'number of steps:', 21, 'accumulatedReward:', 20.0, 'accumulatedDiscountedReward:', 16.619601412245274)
('number of approximation units:', 494, 'number of samples:', 1252)
('episode:', 159, 'number of steps:', 116, 'accumulatedReward:', 115.0, 'accumulatedDiscountedReward:', 45.10256468047899)
('number of approximation units:', 495, 'number of samples:', 1256)
('episode:', 160, 'number of steps:', 40, 'accumulatedReward:', 39.0, 'accumulatedDiscountedReward:', 27.26018347189024)
('number of approximation units:', 496, 'number of samples:', 1258)
('episode:', 161, 'number of steps:', 104, 'accumulatedReward:', 103.0, 'accumulatedDiscountedReward:', 43.758976747415254)
('number of approximation units:', 496, 'number of samples:', 1263)
('episode:', 162, 'number of steps:', 200, 'accumulatedReward:', 200.0, 'accumulatedDiscountedReward:', 49.120602669713875)
('number of approximation units:', 497, 'number of samples:', 1268)
('episode:', 163, 'number of steps:', 25, 'accumulatedReward:', 24.0, 'accumulatedDiscountedReward:', 19.210983174546072)
('number of approximation units:', 497, 'number of samples:', 1269)
('episode:', 164, 'number of steps:', 92, 'accumulatedReward:', 91.0, 'accumulatedDiscountedReward:', 42.04678189744567)
('number of approximation units:', 499, 'number of samples:', 1276)
('episode:', 165, 'number of steps:', 200, 'accumulatedReward:', 200.0, 'accumulatedDiscountedReward:', 49.120602669713875)
('number of approximation units:', 499, 'number of samples:', 1280)
('episode:', 166, 'number of steps:', 21, 'accumulatedReward:', 20.0, 'accumulatedDiscountedReward:', 16.619601412245274)
('number of approximation units:', 501, 'number of samples:', 1284)
('episode:', 167, 'number of steps:', 85, 'accumulatedReward:', 84.0, 'accumulatedDiscountedReward:', 40.838631283185585)
('number of approximation units:', 501, 'number of samples:', 1287)
('episode:', 168, 'number of steps:', 200, 'accumulatedReward:', 200.0, 'accumulatedDiscountedReward:', 49.120602669713875)
('number of approximation units:', 501, 'number of samples:', 1287)
('episode:', 169, 'number of steps:', 200, 'accumulatedReward:', 200.0, 'accumulatedDiscountedReward:', 49.120602669713875)
('number of approximation units:', 502, 'number of samples:', 1288)
('episode:', 170, 'number of steps:', 200, 'accumulatedReward:', 200.0, 'accumulatedDiscountedReward:', 49.120602669713875)
('number of approximation units:', 502, 'number of samples:', 1289)
('episode:', 171, 'number of steps:', 46, 'accumulatedReward:', 45.0, 'accumulatedDiscountedReward:', 29.85610678632871)
('number of approximation units:', 503, 'number of samples:', 1293)
('episode:', 172, 'number of steps:', 196, 'accumulatedReward:', 195.0, 'accumulatedDiscountedReward:', 49.02713010542593)
('number of approximation units:', 503, 'number of samples:', 1294)
('episode:', 173, 'number of steps:', 107, 'accumulatedReward:', 106.0, 'accumulatedDiscountedReward:', 44.12599884285325)
('number of approximation units:', 503, 'number of samples:', 1297)
('episode:', 174, 'number of steps:', 185, 'accumulatedReward:', 184.0, 'accumulatedDiscountedReward:', 48.78502334938794)
('number of approximation units:', 503, 'number of samples:', 1301)
('episode:', 175, 'number of steps:', 45, 'accumulatedReward:', 44.0, 'accumulatedDiscountedReward:', 29.445006924825215)
('number of approximation units:', 507, 'number of samples:', 1308)
('episode:', 176, 'number of steps:', 200, 'accumulatedReward:', 200.0, 'accumulatedDiscountedReward:', 49.120602669713875)
('number of approximation units:', 508, 'number of samples:', 1313)
('episode:', 177, 'number of steps:', 27, 'accumulatedReward:', 26.0, 'accumulatedDiscountedReward:', 20.430228240834047)
('number of approximation units:', 509, 'number of samples:', 1315)
('episode:', 178, 'number of steps:', 41, 'accumulatedReward:', 40.0, 'accumulatedDiscountedReward:', 27.714979802452437)
('number of approximation units:', 510, 'number of samples:', 1317)
('episode:', 179, 'number of steps:', 200, 'accumulatedReward:', 200.0, 'accumulatedDiscountedReward:', 49.120602669713875)
('number of approximation units:', 510, 'number of samples:', 1317)
('episode:', 180, 'number of steps:', 200, 'accumulatedReward:', 200.0, 'accumulatedDiscountedReward:', 49.120602669713875)
('number of approximation units:', 510, 'number of samples:', 1317)
('episode:', 181, 'number of steps:', 200, 'accumulatedReward:', 200.0, 'accumulatedDiscountedReward:', 49.120602669713875)
('number of approximation units:', 511, 'number of samples:', 1322)
('episode:', 182, 'number of steps:', 76, 'accumulatedReward:', 75.0, 'accumulatedDiscountedReward:', 39.011822120628004)
('number of approximation units:', 511, 'number of samples:', 1324)
('episode:', 183, 'number of steps:', 66, 'accumulatedReward:', 65.0, 'accumulatedDiscountedReward:', 36.55177630836969)
('number of approximation units:', 513, 'number of samples:', 1327)
('episode:', 184, 'number of steps:', 49, 'accumulatedReward:', 48.0, 'accumulatedDiscountedReward:', 31.04072885843829)
('number of approximation units:', 516, 'number of samples:', 1331)
('episode:', 185, 'number of steps:', 90, 'accumulatedReward:', 89.0, 'accumulatedDiscountedReward:', 41.71884828971852)
('number of approximation units:', 516, 'number of samples:', 1336)
('episode:', 186, 'number of steps:', 55, 'accumulatedReward:', 54.0, 'accumulatedDiscountedReward:', 33.20507411251285)
('number of approximation units:', 516, 'number of samples:', 1339)
('episode:', 187, 'number of steps:', 111, 'accumulatedReward:', 110.0, 'accumulatedDiscountedReward:', 44.582008360844675)
('number of approximation units:', 516, 'number of samples:', 1344)
('episode:', 188, 'number of steps:', 82, 'accumulatedReward:', 81.0, 'accumulatedDiscountedReward:', 40.266206345979974)
('number of approximation units:', 516, 'number of samples:', 1346)
('episode:', 189, 'number of steps:', 14, 'accumulatedReward:', 13.0, 'accumulatedDiscountedReward:', 11.548880536994798)
('number of approximation units:', 516, 'number of samples:', 1348)
('episode:', 190, 'number of steps:', 188, 'accumulatedReward:', 187.0, 'accumulatedDiscountedReward:', 48.85647369625713)
('number of approximation units:', 518, 'number of samples:', 1350)
('episode:', 191, 'number of steps:', 200, 'accumulatedReward:', 200.0, 'accumulatedDiscountedReward:', 49.120602669713875)
('number of approximation units:', 518, 'number of samples:', 1350)
('episode:', 192, 'number of steps:', 200, 'accumulatedReward:', 200.0, 'accumulatedDiscountedReward:', 49.120602669713875)
('number of approximation units:', 518, 'number of samples:', 1350)
('episode:', 193, 'number of steps:', 200, 'accumulatedReward:', 200.0, 'accumulatedDiscountedReward:', 49.120602669713875)
('number of approximation units:', 518, 'number of samples:', 1350)
('episode:', 194, 'number of steps:', 200, 'accumulatedReward:', 200.0, 'accumulatedDiscountedReward:', 49.120602669713875)
('number of approximation units:', 518, 'number of samples:', 1350)
('episode:', 195, 'number of steps:', 200, 'accumulatedReward:', 200.0, 'accumulatedDiscountedReward:', 49.120602669713875)
('number of approximation units:', 519, 'number of samples:', 1354)
('episode:', 196, 'number of steps:', 200, 'accumulatedReward:', 200.0, 'accumulatedDiscountedReward:', 49.120602669713875)
('number of approximation units:', 519, 'number of samples:', 1354)
('episode:', 197, 'number of steps:', 88, 'accumulatedReward:', 87.0, 'accumulatedDiscountedReward:', 41.377393054684006)
('number of approximation units:', 519, 'number of samples:', 1355)
('episode:', 198, 'number of steps:', 125, 'accumulatedReward:', 124.0, 'accumulatedDiscountedReward:', 45.9167742621722)
('number of approximation units:', 519, 'number of samples:', 1356)
('episode:', 199, 'number of steps:', 196, 'accumulatedReward:', 195.0, 'accumulatedDiscountedReward:', 49.02713010542593)
('number of approximation units:', 519, 'number of samples:', 1357)
('episode:', 200, 'number of steps:', 200, 'accumulatedReward:', 200.0, 'accumulatedDiscountedReward:', 49.120602669713875)
('number of approximation units:', 519, 'number of samples:', 1357)
('episode:', 201, 'number of steps:', 68, 'accumulatedReward:', 67.0, 'accumulatedDiscountedReward:', 37.08432596655825)
('number of approximation units:', 520, 'number of samples:', 1359)
('episode:', 202, 'number of steps:', 16, 'accumulatedReward:', 15.0, 'accumulatedDiscountedReward:', 13.071544867729804)
('number of approximation units:', 520, 'number of samples:', 1360)
('episode:', 203, 'number of steps:', 200, 'accumulatedReward:', 200.0, 'accumulatedDiscountedReward:', 49.120602669713875)
('number of approximation units:', 520, 'number of samples:', 1361)
('episode:', 204, 'number of steps:', 200, 'accumulatedReward:', 200.0, 'accumulatedDiscountedReward:', 49.120602669713875)
('number of approximation units:', 520, 'number of samples:', 1361)
('episode:', 205, 'number of steps:', 51, 'accumulatedReward:', 50.0, 'accumulatedDiscountedReward:', 31.791515995644133)
('number of approximation units:', 520, 'number of samples:', 1363)
('episode:', 206, 'number of steps:', 94, 'accumulatedReward:', 93.0, 'accumulatedDiscountedReward:', 42.361729334306816)
('number of approximation units:', 521, 'number of samples:', 1364)
('episode:', 207, 'number of steps:', 27, 'accumulatedReward:', 26.0, 'accumulatedDiscountedReward:', 20.430228240834047)
('number of approximation units:', 521, 'number of samples:', 1366)
('episode:', 208, 'number of steps:', 83, 'accumulatedReward:', 82.0, 'accumulatedDiscountedReward:', 40.46088221906037)
('number of approximation units:', 522, 'number of samples:', 1369)
('episode:', 209, 'number of steps:', 200, 'accumulatedReward:', 200.0, 'accumulatedDiscountedReward:', 49.120602669713875)
('number of approximation units:', 522, 'number of samples:', 1369)
('episode:', 210, 'number of steps:', 172, 'accumulatedReward:', 171.0, 'accumulatedDiscountedReward:', 48.42010236947588)
('number of approximation units:', 522, 'number of samples:', 1371)
('episode:', 211, 'number of steps:', 90, 'accumulatedReward:', 89.0, 'accumulatedDiscountedReward:', 41.71884828971852)
('number of approximation units:', 523, 'number of samples:', 1374)
('episode:', 212, 'number of steps:', 200, 'accumulatedReward:', 200.0, 'accumulatedDiscountedReward:', 49.120602669713875)
('number of approximation units:', 523, 'number of samples:', 1374)
('episode:', 213, 'number of steps:', 144, 'accumulatedReward:', 143.0, 'accumulatedDiscountedReward:', 47.21837341525567)
('number of approximation units:', 524, 'number of samples:', 1376)
('episode:', 214, 'number of steps:', 200, 'accumulatedReward:', 200.0, 'accumulatedDiscountedReward:', 49.120602669713875)
('number of approximation units:', 524, 'number of samples:', 1376)
('episode:', 215, 'number of steps:', 40, 'accumulatedReward:', 39.0, 'accumulatedDiscountedReward:', 27.26018347189024)
('number of approximation units:', 525, 'number of samples:', 1377)
('episode:', 216, 'number of steps:', 200, 'accumulatedReward:', 200.0, 'accumulatedDiscountedReward:', 49.120602669713875)
('number of approximation units:', 525, 'number of samples:', 1377)
('episode:', 217, 'number of steps:', 105, 'accumulatedReward:', 104.0, 'accumulatedDiscountedReward:', 43.883797212466945)
('number of approximation units:', 525, 'number of samples:', 1380)
('episode:', 218, 'number of steps:', 28, 'accumulatedReward:', 27.0, 'accumulatedDiscountedReward:', 21.021623676017366)
('number of approximation units:', 528, 'number of samples:', 1385)
('episode:', 219, 'number of steps:', 52, 'accumulatedReward:', 51.0, 'accumulatedDiscountedReward:', 32.15568567573125)
('number of approximation units:', 530, 'number of samples:', 1388)
('episode:', 220, 'number of steps:', 138, 'accumulatedReward:', 137.0, 'accumulatedDiscountedReward:', 46.85990798720729)
('number of approximation units:', 531, 'number of samples:', 1389)
('episode:', 221, 'number of steps:', 96, 'accumulatedReward:', 95.0, 'accumulatedDiscountedReward:', 42.66420485266827)
('number of approximation units:', 531, 'number of samples:', 1390)
('episode:', 222, 'number of steps:', 200, 'accumulatedReward:', 200.0, 'accumulatedDiscountedReward:', 49.120602669713875)
('number of approximation units:', 531, 'number of samples:', 1390)
('episode:', 223, 'number of steps:', 71, 'accumulatedReward:', 70.0, 'accumulatedDiscountedReward:', 37.84387092511688)
('number of approximation units:', 531, 'number of samples:', 1393)
('episode:', 224, 'number of steps:', 44, 'accumulatedReward:', 43.0, 'accumulatedDiscountedReward:', 29.025517270229813)
('number of approximation units:', 531, 'number of samples:', 1394)
('episode:', 225, 'number of steps:', 50, 'accumulatedReward:', 49.0, 'accumulatedDiscountedReward:', 31.419914281269524)
('number of approximation units:', 533, 'number of samples:', 1397)
('episode:', 226, 'number of steps:', 200, 'accumulatedReward:', 200.0, 'accumulatedDiscountedReward:', 49.120602669713875)
('number of approximation units:', 534, 'number of samples:', 1400)
('episode:', 227, 'number of steps:', 40, 'accumulatedReward:', 39.0, 'accumulatedDiscountedReward:', 27.26018347189024)
('number of approximation units:', 534, 'number of samples:', 1400)
('episode:', 228, 'number of steps:', 165, 'accumulatedReward:', 164.0, 'accumulatedDiscountedReward:', 48.180104639227196)
('number of approximation units:', 534, 'number of samples:', 1402)
('episode:', 229, 'number of steps:', 162, 'accumulatedReward:', 161.0, 'accumulatedDiscountedReward:', 48.06639308369301)
('number of approximation units:', 536, 'number of samples:', 1407)
('episode:', 230, 'number of steps:', 17, 'accumulatedReward:', 16.0, 'accumulatedDiscountedReward:', 13.810113970375207)
('number of approximation units:', 536, 'number of samples:', 1408)
('episode:', 231, 'number of steps:', 200, 'accumulatedReward:', 200.0, 'accumulatedDiscountedReward:', 49.120602669713875)
('number of approximation units:', 536, 'number of samples:', 1409)
('episode:', 232, 'number of steps:', 187, 'accumulatedReward:', 186.0, 'accumulatedDiscountedReward:', 48.833136424752176)
('number of approximation units:', 538, 'number of samples:', 1414)
('episode:', 233, 'number of steps:', 200, 'accumulatedReward:', 200.0, 'accumulatedDiscountedReward:', 49.120602669713875)
('number of approximation units:', 538, 'number of samples:', 1414)
('episode:', 234, 'number of steps:', 200, 'accumulatedReward:', 200.0, 'accumulatedDiscountedReward:', 49.120602669713875)
('number of approximation units:', 538, 'number of samples:', 1415)
('episode:', 235, 'number of steps:', 200, 'accumulatedReward:', 200.0, 'accumulatedDiscountedReward:', 49.120602669713875)
('number of approximation units:', 538, 'number of samples:', 1415)
('episode:', 236, 'number of steps:', 91, 'accumulatedReward:', 90.0, 'accumulatedDiscountedReward:', 41.88447132392415)
('number of approximation units:', 538, 'number of samples:', 1417)
('episode:', 237, 'number of steps:', 143, 'accumulatedReward:', 142.0, 'accumulatedDiscountedReward:', 47.161605525771094)
('number of approximation units:', 538, 'number of samples:', 1417)
('episode:', 238, 'number of steps:', 175, 'accumulatedReward:', 174.0, 'accumulatedDiscountedReward:', 48.513012989331735)
('number of approximation units:', 538, 'number of samples:', 1419)
('episode:', 239, 'number of steps:', 100, 'accumulatedReward:', 99.0, 'accumulatedDiscountedReward:', 43.233696127818696)
('number of approximation units:', 538, 'number of samples:', 1421)
('episode:', 240, 'number of steps:', 173, 'accumulatedReward:', 172.0, 'accumulatedDiscountedReward:', 48.45170032208636)
('number of approximation units:', 539, 'number of samples:', 1423)
('episode:', 241, 'number of steps:', 196, 'accumulatedReward:', 195.0, 'accumulatedDiscountedReward:', 49.02713010542593)
('number of approximation units:', 539, 'number of samples:', 1424)
('episode:', 242, 'number of steps:', 200, 'accumulatedReward:', 200.0, 'accumulatedDiscountedReward:', 49.120602669713875)
('number of approximation units:', 539, 'number of samples:', 1424)
('episode:', 243, 'number of steps:', 70, 'accumulatedReward:', 69.0, 'accumulatedDiscountedReward:', 37.595786658282535)
('number of approximation units:', 540, 'number of samples:', 1425)
('episode:', 244, 'number of steps:', 84, 'accumulatedReward:', 83.0, 'accumulatedDiscountedReward:', 40.65166457467917)
('number of approximation units:', 540, 'number of samples:', 1426)
('Total Steps: ', 25673)
